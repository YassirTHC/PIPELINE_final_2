import sys
from pathlib import Path

# ensure project-root is first
PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(1, str(PROJECT_ROOT / 'AI-B-roll'))
sys.path.insert(2, str(PROJECT_ROOT / 'AI-B-roll' / 'src'))

if 'utils' in sys.modules:
    del sys.modules['utils']

import logging
import concurrent.futures
import subprocess
import shlex
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Sequence, Set
import gc

# ðŸš€ NOUVEAU: Configuration des logs temps rÃ©el + suppression warnings non-critiques
import warnings
warnings.filterwarnings("ignore", message="SymbolDatabase.GetPrototype() is deprecated")
warnings.filterwarnings("ignore", message="FP16 is not supported on CPU")
warnings.filterwarnings("ignore", message="`clean_up_tokenization_spaces` was not set")
warnings.filterwarnings("ignore", message="Warning: in file.*bytes wanted but.*bytes read")

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(message)s',
    datefmt='%H:%M:%S',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# ðŸš€ NOUVEAU: Fonction print temps rÃ©el
def print_realtime(message):
    """Print avec flush immÃ©diat pour logs temps rÃ©el"""
    print(message, flush=True)
    logger.info(message)

SEEN_URLS: Set[str] = set()
SEEN_PHASHES: List[int] = []
PHASH_DISTANCE = 6


def run_with_timeout(fn, timeout_s: float, *args, **kwargs):
    if timeout_s <= 0:
        return fn(*args, **kwargs)
    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        future = executor.submit(fn, *args, **kwargs)
        try:
            return future.result(timeout=timeout_s)
        except concurrent.futures.TimeoutError:
            return None


def dedupe_by_url(candidates):
    unique = []
    hits = 0
    for candidate in candidates or []:
        url = getattr(candidate, 'url', None)
        if url and url in SEEN_URLS:
            hits += 1
            continue
        unique.append(candidate)
    return unique, hits


def dedupe_by_phash(candidates):
    unique = []
    hits = 0
    for candidate in candidates or []:
        preview = getattr(candidate, 'thumb_url', None)
        media_url = getattr(candidate, 'url', None)
        phash = compute_phash(preview, media_url=media_url)
        if phash is None:
            unique.append(candidate)
            continue
        if any(hamming_distance(phash, seen) <= PHASH_DISTANCE for seen in SEEN_PHASHES):
            hits += 1
            continue
        setattr(candidate, '_phash', phash)
        unique.append(candidate)
    return unique, hits


def _try_overlay_http_direct(broll_url: str, t0: float, t1: float, render_cfg, base_cmd: list[str]) -> bool:
    duration = max(0.1, float(t1 - t0))
    cmd = base_cmd + [
        '-ss', f"{max(0.0, t0):.3f}",
        '-to', f"{max(0.0, t0 + duration):.3f}",
        '-i', broll_url,
    ]
    try:
        proc = subprocess.run(cmd, check=True)
        return proc.returncode == 0
    except Exception:
        return False


def _overlay_via_pipe(broll_url: str, t0: float, t1: float, render_cfg, base_cmd: list[str]) -> bool:
    duration = max(0.1, float(t1 - t0))
    extract_cmd = f'ffmpeg -hide_banner -loglevel error -ss {t0:.3f} -i "{broll_url}" -t {duration:.3f} -an -c:v libx264 -preset veryfast -f mpegts -'
    try:
        extractor = subprocess.Popen(shlex.split(extract_cmd), stdout=subprocess.PIPE)
    except Exception:
        return False

    try:
        import tempfile, os
        with tempfile.NamedTemporaryFile(suffix='.ts', delete=False) as tmp:
            tmp_path = tmp.name
            while True:
                chunk = extractor.stdout.read(65536)
                if not chunk:
                    break
                tmp.write(chunk)
        extractor.wait(timeout=30)
        cmd = base_cmd + ['-i', tmp_path]
        try:
            proc = subprocess.run(cmd, check=True)
            return proc.returncode == 0
        finally:
            try:
                os.remove(tmp_path)
            except Exception:
                pass
    except Exception:
        try:
            extractor.kill()
        except Exception:
            pass
    return False


def overlay_http_or_pipe(broll_url: str, t0: float, t1: float, render_cfg, base_cmd: list[str]) -> bool:
    if _try_overlay_http_direct(broll_url, t0, t1, render_cfg, base_cmd):
        return True
    return _overlay_via_pipe(broll_url, t0, t1, render_cfg, base_cmd)


import os
import json
import random
import numpy as np
import shutil
from datetime import datetime  # NEW: pour mÃ©tadonnÃ©es intelligentes
from temp_function import _llm_generate_caption_hashtags_fixed
import whisper
import requests
import cv2

from pipeline_core.configuration import PipelineConfigBundle
from pipeline_core.fetchers import FetcherOrchestrator
from pipeline_core.dedupe import compute_phash, hamming_distance
from pipeline_core.logging import JsonlLogger, log_broll_decision
from pipeline_core.llm_service import LLMMetadataGeneratorService

# ðŸš€ NOUVEAU: Cache global pour Ã©viter le rechargement des modÃ¨les
_MODEL_CACHE = {}

def get_sentence_transformer_model(model_name: str):
    """RÃ©cupÃ¨re un modÃ¨le SentenceTransformer depuis le cache ou le charge"""
    # ðŸš€ OPTIMISATION: Normaliser le nom du modÃ¨le pour Ã©viter les doublons
    normalized_name = model_name.replace('sentence-transformers/', '')
    
    if normalized_name not in _MODEL_CACHE:
        print(f"    ðŸ”„ Chargement initial du modÃ¨le: {model_name}")
        try:
            from sentence_transformers import SentenceTransformer
            _MODEL_CACHE[normalized_name] = SentenceTransformer(model_name)
            print(f"    âœ… ModÃ¨le {model_name} chargÃ© et mis en cache")
        except Exception as e:
            print(f"    âŒ Erreur chargement modÃ¨le {model_name}: {e}")
            return None
    else:
        print(f"    â™»ï¸ ModÃ¨le {model_name} rÃ©cupÃ©rÃ© du cache")
    
    return _MODEL_CACHE[normalized_name]

def safe_remove_tree(directory: Path, max_retries: int = 3, delay: float = 1.0) -> bool:
    """
    Supprime un dossier de faÃ§on sÃ©curisÃ©e avec retry et gestion des handles Windows
    
    Args:
        directory: Dossier Ã  supprimer
        max_retries: Nombre maximum de tentatives
        delay: DÃ©lai entre les tentatives (secondes)
    
    Returns:
        True si la suppression a rÃ©ussi, False sinon
    """
    if not directory.exists():
        return True
    
    for attempt in range(max_retries):
        try:
            # Forcer la libÃ©ration des handles
            gc.collect()
            
            # Tentative de suppression rÃ©cursive
            shutil.rmtree(directory, ignore_errors=False)
            
            # VÃ©rifier que c'est vraiment supprimÃ©
            if not directory.exists():
                return True
                
        except PermissionError as e:
            if "WinError 32" in str(e) or "being used by another process" in str(e):
                print(f"    âš ï¸ Tentative {attempt + 1}/{max_retries}: Fichier en cours d'utilisation, retry dans {delay}s...")
                time.sleep(delay)
                delay *= 1.5  # Backoff exponentiel
                continue
            else:
                print(f"    âŒ Erreur de permission: {e}")
                break
        except Exception as e:
            print(f"    âŒ Erreur inattendue lors de la suppression: {e}")
            break
    
    # Si on arrive ici, toutes les tentatives ont Ã©chouÃ©
    try:
        # Tentative finale avec ignore_errors=True
        shutil.rmtree(directory, ignore_errors=True)
        if not directory.exists():
            print(f"    âœ… Suppression rÃ©ussie avec ignore_errors")
            return True
        else:
            print(f"    âš ï¸ Dossier partiellement supprimÃ©, rÃ©sidu: {directory}")
            return False
    except Exception as e:
        print(f"    âŒ Ã‰chec final de suppression: {e}")
        return False

# Gestion optionnelle de Mediapipe avec fallback
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
    print("âœ… Mediapipe disponible - Utilisation des fonctionnalitÃ©s IA avancÃ©es")
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    mp = None
    print("âš ï¸ Mediapipe non disponible - Utilisation du fallback OpenCV (fonctionnalitÃ©s rÃ©duites)")

# ðŸš€ NOUVEAU: Import du sÃ©lecteur B-roll gÃ©nÃ©rique
try:
    from broll_selector import BrollSelector, Asset, ScoringFeatures, BrollCandidate
    BROLL_SELECTOR_AVAILABLE = True
    print("âœ… SÃ©lecteur B-roll gÃ©nÃ©rique disponible - Scoring mixte activÃ©")
except ImportError as e:
    BROLL_SELECTOR_AVAILABLE = False
    print(f"âš ï¸ SÃ©lecteur B-roll gÃ©nÃ©rique non disponible: {e}")
    print("   ðŸ”„ Utilisation du systÃ¨me de scoring existant")

from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from tqdm import tqdm  # NEW: console progress
import re # NEW: for caption/hashtag generation
from hormozi_subtitles import add_hormozi_subtitles


def _format_srt_timestamp(total_seconds: float) -> str:
    """Format seconds to SRT timestamp HH:MM:SS,mmm"""
    if total_seconds < 0:
        total_seconds = 0.0
    hours = int(total_seconds // 3600)
    minutes = int((total_seconds % 3600) // 60)
    seconds = int(total_seconds % 60)
    milliseconds = int(round((total_seconds - int(total_seconds)) * 1000))
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"


def write_srt(segments: List[Dict], srt_path: Path) -> None:
    """Write segments [{'start','end','text'}] to SRT file."""
    srt_path = Path(srt_path)
    srt_path.parent.mkdir(parents=True, exist_ok=True)
    lines: List[str] = []
    index = 1
    for seg in segments:
        text = (seg.get('text') or '').strip()
        if not text:
            continue
        start = float(seg.get('start') or 0.0)
        end = float(seg.get('end') or max(0.0, start + 0.01))
        start_ts = _format_srt_timestamp(start)
        end_ts = _format_srt_timestamp(end)
        lines.append(str(index))
        lines.append(f"{start_ts} --> {end_ts}")
        lines.append(text)
        lines.append("")
        index += 1
    with open(srt_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))

def write_vtt(segments: List[Dict], vtt_path: Path) -> None:
    """Write segments to WebVTT file."""
    vtt_path = Path(vtt_path)
    vtt_path.parent.mkdir(parents=True, exist_ok=True)
    def to_vtt_ts(total_seconds: float) -> str:
        if total_seconds < 0:
            total_seconds = 0.0
        hours = int(total_seconds // 3600)
        minutes = int((total_seconds % 3600) // 60)
        seconds = int(total_seconds % 60)
        milliseconds = int(round((total_seconds - int(total_seconds)) * 1000))
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}"
    lines: List[str] = ["WEBVTT",""]
    for seg in segments:
        text = (seg.get('text') or '').strip()
        if not text:
            continue
        start = float(seg.get('start') or 0.0)
        end = float(seg.get('end') or max(0.0, start + 0.01))
        lines.append(f"{to_vtt_ts(start)} --> {to_vtt_ts(end)}")
        lines.append(text)
        lines.append("")
    with open(vtt_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))


def _read_ui_settings() -> Dict:
    """Read optional UI settings from config/ui_settings.json."""
    try:
        cfg_path = Path('config/ui_settings.json')
        if cfg_path.exists():
            with open(cfg_path, 'r', encoding='utf-8') as f:
                return json.load(f) or {}
    except Exception:
        pass
    return {}


def _to_bool(v, default=False) -> bool:
    if v is None:
        return bool(default)
    if isinstance(v, bool):
        return v
    s = str(v).strip().lower()
    return s in {"1","true","yes","on"}


# Load optional UI overrides once
_UI_SETTINGS = _read_ui_settings()

# Configuration automatique d'ImageMagick pour MoviePy
def configure_imagemagick():
    """Configure automatiquement ImageMagick pour MoviePy"""
    try:
        import moviepy.config as cfg
        
        # Chemins possibles pour ImageMagick sur Windows
        possible_paths = [
            r"C:\Program Files\ImageMagick-7.1.2-Q16-HDRI\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.2-Q16\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.1-Q16\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.0-Q16-HDRI\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.0-Q16\magick.exe",
        ]
        
        # Chercher ImageMagick
        for path in possible_paths:
            if os.path.exists(path):
                cfg.change_settings({"IMAGEMAGICK_BINARY": path})
                print(f"âœ… ImageMagick configurÃ©: {path}")
                return True
        
        print("âš ï¸ ImageMagick non trouvÃ©, utilisation du mode fallback")
        return False
        
    except Exception as e:
        print(f"âš ï¸ Erreur configuration ImageMagick: {e}")
        return False

# Configuration automatique au dÃ©marrage
configure_imagemagick()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Config:
    """Configuration centralisÃ©e du pipeline"""
    CLIPS_FOLDER = Path("./clips")
    OUTPUT_FOLDER = Path("./output") 
    TEMP_FOLDER = Path("./temp")
    
    # RÃ©solution cible pour les rÃ©seaux sociaux
    TARGET_WIDTH = 720
    TARGET_HEIGHT = 1280  # Format 9:16
    
    # ParamÃ¨tres Whisper
    WHISPER_MODEL = "tiny"  # ou "small", "medium", "large"
    
    # ParamÃ¨tres sous-titres
    SUBTITLE_FONT_SIZE = 85
    SUBTITLE_COLOR = 'yellow'
    SUBTITLE_STROKE_COLOR = 'black'
    SUBTITLE_STROKE_WIDTH = 3
    # Biais global (en secondes) pour corriger un lÃ©ger dÃ©calage systÃ©matique
    # 0.0 par dÃ©faut pour Ã©viter tout dÃ©calage si non nÃ©cessaire
    SUBTITLE_TIMING_BIAS_S = 0.0

    # Activation B-roll: UI > ENV > dÃ©faut(off)
    # Si fetchers cochÃ©s, activer automatiquement l'insertion B-roll, sauf si explicitement dÃ©sactivÃ© cÃ´tÃ© UI
    _UI_ENABLE_BROLL = _UI_SETTINGS.get('enable_broll') if 'enable_broll' in _UI_SETTINGS else None
    _ENV_ENABLE_BROLL = os.getenv('ENABLE_BROLL') or os.getenv('AI_BROLL_ENABLED')
    _AUTO_ENABLE = _to_bool(_UI_SETTINGS.get('broll_fetch_enable'), default=True) if 'broll_fetch_enable' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ENABLE') or os.getenv('AI_BROLL_ENABLE_FETCHER'), default=True)
    ENABLE_BROLL = (
        _to_bool(_UI_ENABLE_BROLL, default=False) if _UI_ENABLE_BROLL is not None
        else (_to_bool(_ENV_ENABLE_BROLL, default=False) or _AUTO_ENABLE)
    )

    # === Options fetcher B-roll (stock) ===
    # Active le fetch automatique: UI > ENV > dÃ©faut(on)
    BROLL_FETCH_ENABLE = _to_bool(_UI_SETTINGS.get('broll_fetch_enable'), default=True) if 'broll_fetch_enable' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ENABLE') or os.getenv('AI_BROLL_ENABLE_FETCHER'), default=True)
    # Fournisseur: UI > ENV > dÃ©faut pexels
    BROLL_FETCH_PROVIDER = (_UI_SETTINGS.get('broll_fetch_provider') or os.getenv('AI_BROLL_FETCH_PROVIDER') or 'pexels')
    # ClÃ©s API
    PEXELS_API_KEY = _UI_SETTINGS.get('PEXELS_API_KEY') or os.getenv('PEXELS_API_KEY')
    PIXABAY_API_KEY = _UI_SETTINGS.get('PIXABAY_API_KEY') or os.getenv('PIXABAY_API_KEY')
    # ContrÃ´les de fetch
    BROLL_FETCH_MAX_PER_KEYWORD = int(_UI_SETTINGS.get('broll_fetch_max_per_keyword') or os.getenv('BROLL_FETCH_MAX_PER_KEYWORD') or 25)  # CORRIGÃ‰: 12 â†’ 25
    BROLL_FETCH_ALLOW_VIDEOS = _to_bool(_UI_SETTINGS.get('broll_fetch_allow_videos'), default=True) if 'broll_fetch_allow_videos' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ALLOW_VIDEOS'), default=True)
    BROLL_FETCH_ALLOW_IMAGES = _to_bool(_UI_SETTINGS.get('broll_fetch_allow_images'), default=False) if 'broll_fetch_allow_images' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ALLOW_IMAGES'), default=False)
    # Ã‰largir le pool par dÃ©faut: activer les images si non prÃ©cisÃ©
    if 'broll_fetch_allow_images' not in _UI_SETTINGS and os.getenv('BROLL_FETCH_ALLOW_IMAGES') is None:
        BROLL_FETCH_ALLOW_IMAGES = True
    # Embeddings pour matching sÃ©mantique
    BROLL_USE_EMBEDDINGS = _to_bool(_UI_SETTINGS.get('broll_use_embeddings'), default=True) if 'broll_use_embeddings' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_USE_EMBEDDINGS'), default=True)
    BROLL_EMBEDDING_MODEL = (_UI_SETTINGS.get('broll_embedding_model') or os.getenv('BROLL_EMBEDDING_MODEL') or 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    # Config contextuelle
    CONTEXTUAL_CONFIG_PATH = Path(_UI_SETTINGS.get('contextual_broll_yml') or os.getenv('CONTEXTUAL_BROLL_YML') or 'config/contextual_broll.yml')

    # Sortie et nettoyage
    USE_HARDLINKS = _to_bool(_UI_SETTINGS.get('use_hardlinks'), default=True) if 'use_hardlinks' in _UI_SETTINGS else _to_bool(os.getenv('USE_HARDLINKS'), default=True)
    BROLL_DELETE_AFTER_USE = _to_bool(_UI_SETTINGS.get('broll_delete_after_use'), default=True) if 'broll_delete_after_use' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_DELETE_AFTER_USE') or os.getenv('AI_BROLL_PURGE_AFTER_USE'), default=True)
    # ðŸš€ NOUVEAU: Forcer le nettoyage aprÃ¨s chaque vidÃ©o pour Ã©conomiser l'espace
    BROLL_CLEANUP_PER_VIDEO = True  # Toujours activÃ© pour Ã©viter l'accumulation
    BROLL_PURGE_AFTER_RUN = _to_bool(_UI_SETTINGS.get('broll_purge_after_run'), default=True) if 'broll_purge_after_run' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_PURGE_AFTER_RUN') or os.getenv('AI_BROLL_PURGE_AFTER_RUN'), default=True)
    # Brand kit
    BRAND_KIT_ID = _UI_SETTINGS.get('brand_kit_id') or os.getenv('BRAND_KIT_ID') or 'default'
    # Experimental FX (wipes/zoom/LUT etc.)
    ENABLE_EXPERIMENTAL_FX = _to_bool(_UI_SETTINGS.get('enable_experimental_fx'), default=False) if 'enable_experimental_fx' in _UI_SETTINGS else _to_bool(os.getenv('ENABLE_EXPERIMENTAL_FX'), default=False)

    # ðŸš€ NOUVEAU: Configuration du sÃ©lecteur B-roll gÃ©nÃ©rique
    BROLL_SELECTOR_CONFIG_PATH = Path(_UI_SETTINGS.get('broll_selector_config') or os.getenv('BROLL_SELECTOR_CONFIG') or 'config/broll_selector_config.yaml')
    BROLL_SELECTOR_ENABLED = _to_bool(_UI_SETTINGS.get('broll_selector_enabled'), default=True) if 'broll_selector_enabled' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_SELECTOR_ENABLED') or os.getenv('AI_BROLL_SELECTOR_ENABLED'), default=True)

# ðŸš€ SUPPRIMÃ‰: Fonction _detect_local_llm obsolÃ¨te
# RemplacÃ©e par le systÃ¨me LLM industriel qui gÃ¨re automatiquement la dÃ©tection

# ðŸš€ SUPPRIMÃ‰: Ancien systÃ¨me LLM obsolÃ¨te remplacÃ© par le systÃ¨me industriel
# Cette fonction utilisait l'ancien prompt complexe et causait des timeouts
# Maintenant remplacÃ©e par le systÃ¨me LLM industriel dans generate_caption_and_hashtags
# ðŸš€ SUPPRIMÃ‰: Reste de l'ancien systÃ¨me LLM obsolÃ¨te
# Toute cette logique complexe est maintenant remplacÃ©e par le systÃ¨me industriel

# === IA: Analyse mots-clÃ©s et prompts visuels pour guider le B-roll ===

def extract_keywords_from_transcript_ai(transcript_segments: List[Dict]) -> Dict:
    """Analyse simple: thÃ¨mes, occurrences et timestamps pour B-roll contextuel."""
    keyword_categories = {
        'money': ['money', 'cash', 'dollars', 'profit', 'revenue', 'income', 'wealth'],
        'business': ['business', 'company', 'startup', 'entrepreneur', 'strategy'],
        'technology': ['tech', 'software', 'app', 'digital', 'online', 'ai', 'automation'],
        'success': ['success', 'win', 'achievement', 'goal', 'growth', 'scale', 'unstoppable', 'beast'],
        'people': ['team', 'customer', 'client', 'person', 'human', 'community'],
        'emotion_positive': ['amazing', 'incredible', 'fantastic', 'awesome', 'fire'],
        'emotion_negative': ['problem', 'issue', 'difficult', 'challenge', 'fail'],
        'action': ['build', 'create', 'launch', 'start', 'implement', 'execute'],
        # ðŸš€ NOUVELLES CATÃ‰GORIES pour contenu cerveau/mental/neurosciences
        'brain_mind': ['brain', 'mind', 'mental', 'neuroscience', 'neural', 'cognitive', 'psychology'],
        'health_wellness': ['health', 'wellness', 'nutrition', 'nutrients', 'supplements', 'fitness', 'energy'],
        'learning_growth': ['learn', 'learning', 'growth', 'development', 'improvement', 'potential', 'capability'],
        'internal_dialogue': ['dialogue', 'conversation', 'thoughts', 'thinking', 'mindset', 'beliefs', 'circuit']
    }
    full_text = ' '.join([(seg.get('text') or '').lower() for seg in transcript_segments])
    detected_keywords: Dict[str, List[str]] = {}
    timestamps_by_category: Dict[str, List[Dict]] = {}
    for category, kws in keyword_categories.items():
        detected_keywords[category] = []
        timestamps_by_category[category] = []
        for kw in kws:
            if kw in full_text:
                detected_keywords[category].append(kw)
                for seg in transcript_segments:
                    text = (seg.get('text') or '').lower()
                    if kw in text:
                        # ðŸš€ CORRECTION: Gestion robuste des timestamps avec slice objects
                        start_val = seg.get('start', 0.0)
                        end_val = seg.get('end', 0.0)
                        
                        # Convertir slice objects en float si nÃ©cessaire
                        if hasattr(start_val, 'start'):  # Si c'est un slice
                            start_val = start_val.start or 0.0
                        if hasattr(end_val, 'start'):  # Si c'est un slice
                            end_val = end_val.start or 0.0
                            
                        timestamps_by_category[category].append({
                            'start': float(start_val),
                            'end': float(end_val),
                            'keyword': kw,
                            'context': seg.get('text') or ''
                        })
    dominant_theme = 'business'
    try:
        dominant_theme = max(detected_keywords.items(), key=lambda x: len(x[1]))[0]
    except Exception:
        pass
    # ðŸš€ CORRECTION CRITIQUE: Gestion robuste du timestamp final
    total_duration = 0.0
    if transcript_segments:
        try:
            last_end = transcript_segments[-1].get('end', 0.0)
            # Convertir slice object en float si nÃ©cessaire
            if hasattr(last_end, 'start'):  # Si c'est un slice
                last_end = last_end.start or 0.0
            total_duration = float(last_end)
        except (ValueError, TypeError, AttributeError, KeyError):
            total_duration = 0.0
    
    return {
        'keywords': detected_keywords,
        'timestamps': timestamps_by_category,
        'dominant_theme': dominant_theme,
        'total_duration': total_duration
    }


def generate_broll_prompts_ai(keyword_analysis: Dict) -> List[Dict]:
    """Generate B-roll prompts using AI analysis."""
    try:
        # Extract main theme and keywords
        main_theme = keyword_analysis.get('dominant_theme', 'general')  # ðŸš€ CORRECTION: ClÃ© correcte
        keywords = keyword_analysis.get('keywords', {})
        sentiment = keyword_analysis.get('sentiment', 0.0)
        
        # Generate context-aware prompts
        prompts = []
        
        # Base prompts from main theme
        if main_theme == 'technology':
            prompts.extend([
                'artificial intelligence neural network',
                'computer vision algorithm',
                'tech innovation future',
                'digital transformation',
                'machine learning data'
            ])
        elif main_theme == 'medical':
            prompts.extend([
                'medical research laboratory',
                'healthcare innovation hospital',
                'microscope scientific discovery',
                'medical technology',
                'healthcare professionals'
            ])
        elif main_theme == 'business':
            prompts.extend([
                'business success growth',
                'entrepreneurship motivation',
                'professional development office',
                'team collaboration',
                'business strategy'
            ])
        elif main_theme == 'neuroscience':
            prompts.extend([
                'neuroscience brain neurons synapse',
                'brain reflexes nervous system',
                'brain scan mri eeg lab',
                'cognitive science',
                'mental health awareness'
            ])
        else:
            # Generic prompts for other themes  
            # ðŸš€ CORRECTION: keywords est un dict, pas une liste
            if keywords and isinstance(keywords, dict):
                # Extraire les premiers mots-clÃ©s de toutes les catÃ©gories
                all_kws = []
                for category_kws in keywords.values():
                    if isinstance(category_kws, list):
                        all_kws.extend(category_kws[:2])  # 2 par catÃ©gorie
                base_keywords = all_kws[:3] if all_kws else [main_theme]
            else:
                base_keywords = [main_theme]
                
            for kw in base_keywords:
                prompts.append(f"{main_theme} {kw}")
        
        # Add sentiment-based prompts
        if sentiment > 0.3:
            prompts.extend(['positive energy', 'success achievement', 'happy people'])
        elif sentiment < -0.3:
            prompts.extend(['serious focus', 'determination', 'overcoming challenges'])
        
        # Limit and deduplicate
        unique_prompts = list(dict.fromkeys(prompts))[:8]
        
        return unique_prompts
        
    except Exception as e:
        print(f"âš ï¸ Erreur gÃ©nÃ©ration prompts AI: {e}")
        # Fallback prompts
        return ['general content', 'people working', 'modern technology']

class VideoProcessor:
    _shared_llm_service = None

    """Classe principale pour traiter les vidÃ©os"""
    
    def __init__(self):
        self.whisper_model = whisper.load_model(Config.WHISPER_MODEL)
        self._setup_directories()
        # Cache Ã©ventuel pour spaCy
        self._spacy_model = None

        if VideoProcessor._shared_llm_service is None:
            try:
                VideoProcessor._shared_llm_service = LLMMetadataGeneratorService()
            except Exception as exc:
                logger.warning("LLM service initialisation failed: %s", exc)
        self._llm_service = VideoProcessor._shared_llm_service
        self._pipeline_config = PipelineConfigBundle()
        self._broll_event_logger = None



def _setup_directories(self):
    for folder in [Config.CLIPS_FOLDER, Config.OUTPUT_FOLDER, Config.TEMP_FOLDER]:
        folder.mkdir(parents=True, exist_ok=True)

def _get_broll_event_logger(self):
    if self._broll_event_logger is None:
        log_file = Config.OUTPUT_FOLDER / 'meta' / 'broll_pipeline_events.jsonl'
        self._broll_event_logger = JsonlLogger(log_file)
    return self._broll_event_logger

def _insert_brolls_pipeline_core(self, segments, broll_keywords, *, subtitles, input_path: Path) -> None:
    global SEEN_URLS, SEEN_PHASHES
    SEEN_URLS.clear()
    SEEN_PHASHES.clear()
    logger.info("[BROLL] pipeline_core orchestrator engaged")
    config_bundle = self._pipeline_config
    orchestrator = FetcherOrchestrator(config_bundle.fetcher)
    selection_cfg = config_bundle.selection
    timeboxing_cfg = config_bundle.timeboxing
    event_logger = self._get_broll_event_logger()

    fetch_timeout = max((timeboxing_cfg.fetch_rank_ms or 0) / 1000.0, 0.0)

    for idx, segment in enumerate(segments):
        seg_duration = max(0.0, segment.end - segment.start)
        llm_hints = None
        llm_healthy = True
        if getattr(self, '_llm_service', None):
            try:
                llm_hints = self._llm_service.generate_hints_for_segment(segment.text, segment.start, segment.end)
            except Exception:
                llm_hints = None
                llm_healthy = False

        segment_keywords = self._derive_segment_keywords(segment, broll_keywords)
        queries: List[str] = []
        if llm_hints and isinstance(llm_hints.get('queries'), list):
            queries = [q.strip() for q in llm_hints['queries'] if isinstance(q, str) and q.strip()]
        if not queries:
            queries = segment_keywords[:4]
        if not queries:
            log_broll_decision(
                event_logger,
                segment_idx=idx,
                start=segment.start,
                end=segment.end,
                query_count=0,
                candidate_count=0,
                unique_candidates=0,
                url_dedup_hits=0,
                phash_dedup_hits=0,
                selected_url=None,
                selected_score=None,
                provider=None,
                latency_ms=0,
                llm_healthy=llm_healthy,
                reject_reasons=['no_keywords'],
            )
            continue

        filters = {}
        if llm_hints and isinstance(llm_hints.get('filters'), dict):
            filters = llm_hints['filters'] or {}

        start_time = time.perf_counter()

        def _do_fetch():
            return orchestrator.fetch_candidates(
                queries,
                duration_hint=seg_duration,
                filters=filters,
            )

        candidates = run_with_timeout(_do_fetch, fetch_timeout) if fetch_timeout else _do_fetch()
        if candidates is None:
            candidates = []

        unique_candidates, url_hits = dedupe_by_url(candidates)
        unique_candidates, phash_hits = dedupe_by_phash(unique_candidates)

        best_candidate = None
        best_score = -1.0
        best_provider = None
        reject_reasons: List[str] = []

        for candidate in unique_candidates:
            score = self._rank_candidate(segment.text, candidate, selection_cfg, seg_duration)
            if score < selection_cfg.min_score:
                reject_reasons.append('low_score')
                continue
            if score > best_score:
                best_candidate = candidate
                best_score = score
                best_provider = getattr(candidate, 'provider', None)

        if best_candidate is None:
            if not candidates:
                reject_reasons.append('timeout' if fetch_timeout else 'no_candidates')
            elif url_hits or phash_hits:
                reject_reasons.append('deduped')
            elif not reject_reasons:
                reject_reasons.append('no_candidates')
        else:
            url = getattr(best_candidate, 'url', None)
            if url:
                SEEN_URLS.add(url)
            ph = getattr(best_candidate, '_phash', None)
            if ph is not None:
                SEEN_PHASHES.append(ph)

        latency_ms = int((time.perf_counter() - start_time) * 1000)
        log_broll_decision(
            event_logger,
            segment_idx=idx,
            start=segment.start,
            end=segment.end,
            query_count=len(queries),
            candidate_count=len(candidates),
            unique_candidates=len(unique_candidates),
            url_dedup_hits=url_hits,
            phash_dedup_hits=phash_hits,
            selected_url=getattr(best_candidate, 'url', None) if best_candidate else None,
            selected_score=best_score if best_candidate else None,
            provider=best_provider if best_candidate else None,
            latency_ms=latency_ms,
            llm_healthy=llm_healthy,
            reject_reasons=sorted(set(reject_reasons)),
        )

    log_broll_decision(
        event_logger,
        segment_idx=-1,
        start=0.0,
        end=0.0,
        query_count=0,
        candidate_count=0,
        unique_candidates=0,
        url_dedup_hits=0,
        phash_dedup_hits=0,
        selected_url=None,
        selected_score=None,
        provider=None,
        latency_ms=0,
        llm_healthy=True,
        reject_reasons=['summary'],
    )

def _derive_segment_keywords(self, segment, global_keywords: Sequence[str]) -> List[str]:
    keywords: List[str] = []
    if global_keywords:
        keywords.extend(global_keywords[:4])
    segment_words = [w.strip().lower() for w in segment.text.split() if len(w.strip()) > 3]
    unique_segment_words: List[str] = []
    for word in segment_words:
        if word not in unique_segment_words:
            unique_segment_words.append(word)
    keywords.extend(unique_segment_words[:3])
    result: List[str] = []
    for word in keywords:
        if word and word not in result:
            result.append(word)
    return result

def _estimate_candidate_score(self, candidate, selection_cfg, segment_duration: float) -> float:
    base_score = 0.6
    width = getattr(candidate, 'width', 0) or 0
    height = getattr(candidate, 'height', 0) or 0
    duration = getattr(candidate, 'duration', None)

    if selection_cfg.prefer_landscape and width and height and width < height:
        return 0.0
    if not selection_cfg.prefer_landscape and width and height and height < width:
        base_score -= 0.1

    if duration is not None:
        if duration < max(selection_cfg.min_duration_s, 0.0):
            base_score -= 0.2
        elif duration >= selection_cfg.min_duration_s:
            base_score += 0.05
        if segment_duration > 0:
            ratio = duration / max(segment_duration, 1e-3)
            if ratio < 0.6:
                base_score -= 0.1
            elif ratio > 1.4:
                base_score -= 0.05
            else:
                base_score += 0.05

    tags = getattr(candidate, 'tags', None) or ()
    keyword_hits = sum(1 for t in tags if isinstance(t, str) and t)
    if keyword_hits:
        base_score += min(0.1, keyword_hits * 0.02)

    return max(0.0, min(1.0, base_score))

def _rank_candidate(self, segment_text: str, candidate, selection_cfg, segment_duration: float) -> float:
    base_score = self._estimate_candidate_score(candidate, selection_cfg, segment_duration)
    title = (getattr(candidate, 'title', '') or '').lower()
    tokens = {tok for tok in segment_text.lower().split() if len(tok) > 2}
    if title and tokens:
        overlap = sum(1 for tok in tokens if tok in title)
        if overlap:
            base_score += min(0.1, overlap * 0.02)
    return max(0.0, min(1.0, base_score))


    def insert_brolls_if_enabled(self, input_path: Path, subtitles: List[Dict], broll_keywords: List[str]) -> Path:
        """Point d'extension B-roll: retourne le chemin vidÃ©o aprÃ¨s insertion si activÃ©e."""
        if not getattr(Config, 'ENABLE_BROLL', False):
            print("    â­ï¸ B-roll dÃ©sactivÃ©s: aucune insertion")
            return input_path
        
        try:
            # VÃ©rifier la librairie B-roll
            broll_root = Path("AI-B-roll")
            broll_library = broll_root / "broll_library"
            if not broll_library.exists():
                print("    âš ï¸ Librairie B-roll introuvable, saut de l'insertion")
                return input_path
            # PrÃ©parer chemins (Ã©crire directement dans le dossier du clip si possible)
            clip_dir = (Path(input_path).parent if (Path(input_path).name == 'reframed.mp4') else Config.TEMP_FOLDER)
            # Si input_path est dÃ©jÃ  dans un dossier clip (reframed.mp4), sortir with_broll.mp4 Ã  cÃ´tÃ©
            if Path(input_path).name == 'reframed.mp4':
                output_with_broll = clip_dir / 'with_broll.mp4'
            else:
                output_with_broll = Config.TEMP_FOLDER / f"with_broll_{Path(input_path).name}"
            output_with_broll.parent.mkdir(parents=True, exist_ok=True)
            
            # Assurer l'import du pipeline local (src/*)
            if str(broll_root.resolve()) not in sys.path:
                sys.path.insert(0, str(broll_root.resolve()))
            
            # ðŸš€ NOUVEAUX IMPORTS INTELLIGENTS SYNCHRONES (DÃ‰SACTIVÃ‰S POUR PROMPT OPTIMISÃ‰)
            try:
                from sync_context_analyzer import SyncContextAnalyzer
                from broll_diversity_manager import BrollDiversityManager
                # ðŸš¨ DÃ‰SACTIVATION TEMPORAIRE: Le systÃ¨me intelligent interfÃ¨re avec notre prompt optimisÃ© LLM
                INTELLIGENT_BROLL_AVAILABLE = False
                print("    âš ï¸  SystÃ¨me intelligent DÃ‰SACTIVÃ‰ pour laisser le prompt optimisÃ© LLM fonctionner")
                print("    ðŸŽ¯ Utilisation exclusive du prompt optimisÃ©: 25-35 keywords + structure hiÃ©rarchique")
            except ImportError as e:
                print(f"    âš ï¸  SystÃ¨me intelligent non disponible: {e}")
                print("    ðŸ”„ Fallback vers ancien systÃ¨me...")
                INTELLIGENT_BROLL_AVAILABLE = False
            
            # Imports B-roll dans tous les cas
            from src.pipeline.config import BrollConfig  # type: ignore
            from src.pipeline.keyword_extraction import extract_keywords_for_segment  # type: ignore
            from src.pipeline.timeline_legacy import plan_broll_insertions, normalize_timeline, enrich_keywords  # type: ignore
            from src.pipeline.renderer import render_video  # type: ignore
            from src.pipeline.transcription import TranscriptSegment  # type: ignore
            
            from moviepy.editor import VideoFileClip as _VFC
            # Optionnel: indexation FAISS/CLIP
            try:
                from src.pipeline.indexer import build_index  # type: ignore
                index_handle = None
            except Exception:
                build_index = None  # type: ignore
                index_handle = None
            
            # ðŸ§  ANALYSE INTELLIGENTE AVANCÃ‰E
            if INTELLIGENT_BROLL_AVAILABLE:
                print("    ðŸ§  Utilisation du systÃ¨me B-roll intelligent...")
                try:
                    # Initialiser l'analyseur contextuel intelligent SYNCHRONE
                    context_analyzer = SyncContextAnalyzer()
                    
                    # Analyser le contexte global de la vidÃ©o
                    transcript_text = " ".join([s.get('text', '') for s in subtitles])
                    global_analysis = context_analyzer.analyze_context(transcript_text)
                    
                    print(f"    ðŸŽ¯ Contexte dÃ©tectÃ©: {global_analysis.main_theme}")
                    print(f"    ðŸ§¬ Sujets: {', '.join(global_analysis.key_topics[:3])}")
                    print(f"    ðŸ˜Š Sentiment: {global_analysis.sentiment}")
                    print(f"    ðŸ“Š ComplexitÃ©: {global_analysis.complexity}")
                    print(f"    ðŸ”‘ Mots-clÃ©s: {', '.join(global_analysis.keywords[:5])}")
                    
                    # Persister l'analyse intelligente
                    try:
                        meta_dir = Config.OUTPUT_FOLDER / 'meta'
                        meta_dir.mkdir(parents=True, exist_ok=True)
                        meta_path = meta_dir / f"{Path(input_path).stem}_intelligent_broll_metadata.json"
                        with open(meta_path, 'w', encoding='utf-8') as f:
                            json.dump({
                                'intelligent_analysis': {
                                    'main_theme': global_analysis.main_theme,
                                    'key_topics': global_analysis.key_topics,
                                    'sentiment': global_analysis.sentiment,
                                    'complexity': global_analysis.complexity,
                                    'keywords': global_analysis.keywords,
                                    'context_score': global_analysis.context_score
                                },
                                'timestamp': str(datetime.now())
                            }, f, ensure_ascii=False, indent=2)
                        print(f"    ðŸ’¾ MÃ©tadonnÃ©es intelligentes sauvegardÃ©es: {meta_path}")
                        
                        # ðŸŽ¬ INSÃ‰RATION INTELLIGENTE DES B-ROLLS
                        print("    ðŸŽ¬ Insertion intelligente des B-rolls...")
                        try:
                            # CrÃ©er un dossier unique pour ce clip
                            clip_id = input_path.stem
                            unique_broll_dir = broll_library / f"clip_intelligent_{clip_id}_{int(time.time())}"
                            unique_broll_dir.mkdir(parents=True, exist_ok=True)
                            
                            # GÃ©nÃ©rer des prompts intelligents basÃ©s sur l'analyse
                            intelligent_prompts = []
                            main_theme = global_analysis.main_theme
                            kws = _filter_prompt_terms(global_analysis.keywords[:6]) if hasattr(global_analysis, 'keywords') else []
                            if main_theme == 'technology':
                                intelligent_prompts.extend([
                                    'artificial intelligence neural network',
                                    'computer vision algorithm',
                                    'tech innovation future'
                                ])
                            elif main_theme == 'medical':
                                intelligent_prompts.extend([
                                    'medical research laboratory',
                                    'healthcare innovation hospital',
                                    'microscope scientific discovery'
                                ])
                            elif main_theme == 'business':
                                intelligent_prompts.extend([
                                    'business success growth',
                                    'entrepreneurship motivation',
                                    'professional development office'
                                ])
                            elif main_theme == 'neuroscience':
                                intelligent_prompts.extend([
                                    'neuroscience brain neurons synapse',
                                    'brain reflexes nervous system',
                                    'brain scan mri eeg lab'
                                ])
                            else:
                                base = _filter_prompt_terms([main_theme] + kws)
                                intelligent_prompts.extend([f"{main_theme} {kw}" for kw in base[:3]])

                            # Ajouter variantes from cleaned keywords
                            for kw in kws[:3]:
                                intelligent_prompts.append(f"{main_theme} {kw}")

                            # Dedup and trim
                            seen_ip = set()
                            intelligent_prompts = [p for p in intelligent_prompts if not (p in seen_ip or seen_ip.add(p))][:8]

                            print(f"    ðŸŽ¯ Prompts intelligents gÃ©nÃ©rÃ©s: {', '.join(intelligent_prompts[:3])}")
                            
                            # Utiliser l'ancien systÃ¨me mais avec les prompts intelligents
                            # (temporaire en attendant l'intÃ©gration complÃ¨te)
                            print("    ðŸ”„ Utilisation du systÃ¨me B-roll avec prompts intelligents...")
                            
                        except Exception as e:
                            print(f"    âš ï¸  Erreur insertion intelligente: {e}")
                            print("    ðŸ”„ Fallback vers ancien systÃ¨me...")
                            INTELLIGENT_BROLL_AVAILABLE = False
                            
                    except Exception as e:
                        print(f"    âš ï¸  Erreur systÃ¨me intelligent: {e}")
                        print("    ðŸ”„ Fallback vers ancien systÃ¨me...")
                        INTELLIGENT_BROLL_AVAILABLE = False
                except Exception as e:
                    print(f"    âš ï¸  Erreur systÃ¨me intelligent: {e}")
                    print("    ðŸ”„ Fallback vers ancien systÃ¨me...")
                    INTELLIGENT_BROLL_AVAILABLE = False
            
            # ðŸš€ CORRECTION: PrÃ©parer l'analyse des mots-clÃ©s pour tous les systÃ¨mes
            analysis = None
            try:
                analysis = extract_keywords_from_transcript_ai(subtitles)
                print(f"    ðŸ§  Analyse des mots-clÃ©s prÃ©parÃ©e: {analysis.get('dominant_theme', 'N/A')}")
            except Exception as e:
                print(f"    âš ï¸ Erreur prÃ©paration analyse: {e}")
                    
            # Fallback: ancienne analyse si systÃ¨me intelligent indisponible
            if not INTELLIGENT_BROLL_AVAILABLE:
                print("    ðŸ”„ Utilisation de l'ancien systÃ¨me B-roll...")
                # analysis dÃ©jÃ  prÃ©parÃ© plus haut
                prompts = generate_broll_prompts_ai(analysis) if analysis else []
                # Filtrer les prompts fallback
                try:
                    cleaned_prompts = []
                    for p in prompts:
                        tokens = _filter_prompt_terms(str(p).split())
                        if tokens:
                            cleaned_prompts.append(' '.join(tokens))
                    if cleaned_prompts:
                        prompts = cleaned_prompts
                except Exception:
                    pass
                # Persiste metadata dans un dossier clip dÃ©diÃ© si possible
                try:
                    meta_dir = Config.OUTPUT_FOLDER / 'meta'
                    meta_dir.mkdir(parents=True, exist_ok=True)
                    meta_path = meta_dir / f"{Path(input_path).stem}_broll_metadata.json"
                    with open(meta_path, 'w', encoding='utf-8') as f:
                        json.dump({'analysis': analysis, 'prompts': prompts}, f, ensure_ascii=False, indent=2)
                except Exception:
                    pass
            else:
                # ðŸŽ¯ UTILISER LES PROMPTS INTELLIGENTS
                print("    ðŸŽ¯ Utilisation des prompts intelligents pour B-rolls...")
                try:
                    # CrÃ©er une analyse basÃ©e sur l'analyse intelligente
                    analysis = {
                        'main_theme': global_analysis.main_theme,
                        'key_topics': global_analysis.key_topics,
                        'sentiment': global_analysis.sentiment,
                        'keywords': global_analysis.keywords
                    }
                    
                    # Utiliser les prompts intelligents gÃ©nÃ©rÃ©s
                    prompts = intelligent_prompts if 'intelligent_prompt' in locals() else [
                        f"{global_analysis.main_theme} {kw}" for kw in global_analysis.keywords[:3]
                    ]
                    
                    print(f"    ðŸŽ¯ Prompts utilisÃ©s: {', '.join(prompts[:3])}")
                    
                except Exception as e:
                    print(f"    âš ï¸  Erreur prompts intelligents: {e}")
                    # Fallback vers prompts gÃ©nÃ©riques (analysis dÃ©jÃ  prÃ©parÃ©)
                    prompts = generate_broll_prompts_ai(analysis) if analysis else []
            
            # ðŸš€ CORRECTION: Utiliser directement le paramÃ¨tre broll_keywords du LLM
            llm_broll_keywords = []
            try:
                # Utiliser les mots-clÃ©s B-roll passÃ©s en paramÃ¨tre (gÃ©nÃ©rÃ©s par le LLM)
                if broll_keywords and len(broll_keywords) > 0:
                    llm_broll_keywords = broll_keywords
                    print(f"    ðŸ§  Mots-clÃ©s B-roll LLM intÃ©grÃ©s: {len(llm_broll_keywords)} termes")
                    print(f"    ðŸŽ¯ Exemples: {', '.join(llm_broll_keywords[:5])}")
                else:
                    print("    âš ï¸ Mots-clÃ©s B-roll LLM non disponibles, utilisation extraction basique")
            except Exception as e:
                print(f"    âš ï¸ Erreur rÃ©cupÃ©ration mots-clÃ©s B-roll LLM: {e}")
            
            # Combiner les mots-clÃ©s LLM avec les prompts existants
            if llm_broll_keywords:
                # Enrichir les prompts avec les mots-clÃ©s LLM
                enhanced_prompts = []
                for kw in llm_broll_keywords[:8]:  # Limiter Ã  8 mots-clÃ©s principaux
                    enhanced_prompts.append(kw)
                    # CrÃ©er des combinaisons avec le thÃ¨me principal
                    if 'global_analysis' in globals() and 'global_analysis' in locals() and hasattr(global_analysis, 'main_theme'):
                        enhanced_prompts.append(f"{getattr(global_analysis, 'main_theme', 'general')} {kw}")
                
                # Ajouter les prompts existants
                enhanced_prompts.extend(prompts)
                
                # DÃ©dupliquer et limiter
                seen_prompts = set()
                final_prompts = []
                for p in enhanced_prompts:
                    if p not in seen_prompts and len(p) > 2:
                        final_prompts.append(p)
                        seen_prompts.add(p)
                
                prompts = final_prompts[:12]  # Limiter Ã  12 prompts finaux
                print(f"    ðŸš€ Prompts enrichis avec LLM: {len(prompts)} termes")
                print(f"    ðŸŽ¯ Prompts finaux: {', '.join(prompts[:5])}...")
            
            # Convertir nos sous-titres en segments attendus par le pipeline
            segments = [
                TranscriptSegment(start=float(s.get('start', 0.0)), end=float(s.get('end', 0.0)), text=str(s.get('text', '')).strip())
                for s in subtitles if (s.get('text') and (s.get('end', 0.0) >= s.get('start', 0.0)))
            ]
            if not segments:
                print("    âš ï¸ Aucun segment de transcription valide, saut B-roll")
                return input_path

            if getattr(Config, 'ENABLE_PIPELINE_CORE_FETCHER', False):
                self._insert_brolls_pipeline_core(segments, broll_keywords, subtitles=subtitles, input_path=input_path)

            
            # Construire la config du pipeline (fetch + embeddings activÃ©s, pas de limites)
            cfg = BrollConfig(
                input_video=str(input_path),
                output_video=output_with_broll,
                broll_library=broll_library,
                srt_path=None,
                render_subtitles=False,
                            max_broll_ratio=0.65,           # CORRIGÃ‰: 90% â†’ 65% pour Ã©quilibre optimal
            min_gap_between_broll_s=1.5,    # CORRIGÃ‰: 0.2s â†’ 1.5s pour respiration visuelle
                            max_broll_clip_s=4.0,           # CORRIGÃ‰: 8.0s â†’ 4.0s pour B-rolls Ã©quilibrÃ©s
            min_broll_clip_s=1.5,           # ðŸš€ OPTIMISÃ‰: 0.8s â†’ 1.5s pour B-rolls plus visibles sur TikTok
                use_whisper=False,
                ffmpeg_preset="fast",
                crf=23,
                threads=0,
                # Fetchers (stock)
                enable_fetcher=getattr(Config, 'BROLL_FETCH_ENABLE', False),
                fetch_provider=getattr(Config, 'BROLL_FETCH_PROVIDER', 'pexels'),
                pexels_api_key=getattr(Config, 'PEXELS_API_KEY', None),
                pixabay_api_key=getattr(Config, 'PIXABAY_API_KEY', None),
                fetch_max_per_keyword=getattr(Config, 'BROLL_FETCH_MAX_PER_KEYWORD', 15),  # CORRIGÃ‰: 25 â†’ 15 pour vitesse optimale
                fetch_allow_videos=getattr(Config, 'BROLL_FETCH_ALLOW_VIDEOS', True),
                fetch_allow_images=getattr(Config, 'BROLL_FETCH_ALLOW_IMAGES', True),  # ActivÃ©: images animÃ©es + Ken Burns
                # Embeddings
                use_embeddings=getattr(Config, 'BROLL_USE_EMBEDDINGS', True),
                embedding_model_name=getattr(Config, 'BROLL_EMBEDDING_MODEL', 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'),
                contextual_config_path=getattr(Config, 'CONTEXTUAL_CONFIG_PATH', Path('config/contextual_broll.yml')),
                # Experimental FX toggle
                enable_experimental_fx=getattr(Config, 'ENABLE_EXPERIMENTAL_FX', False),
            )
            # FETCH DYNAMIQUE PAR CLIP: CrÃ©er un dossier unique et forcer le fetch Ã  chaque fois
            try:
                from src.pipeline.fetchers import ensure_assets_for_keywords  # type: ignore
                
                # ðŸš€ NOUVEAU: Dossier temporaire unique - sera nettoyÃ© aprÃ¨s traitement
                clip_id = input_path.stem  # Nom du fichier sans extension
                clip_broll_dir = broll_library / f"temp_clip_{clip_id}_{int(time.time())}"
                
                # Toujours crÃ©er un nouveau dossier temporaire
                clip_broll_dir.mkdir(parents=True, exist_ok=True)
                print(f"    ðŸ“ Dossier B-roll temporaire crÃ©Ã©: {clip_broll_dir.name}")
                print(f"    ðŸ—‘ï¸ Sera automatiquement nettoyÃ© aprÃ¨s traitement")
                
                # Forcer l'activation du fetcher pour chaque clip
                setattr(cfg, 'enable_fetcher', True)
                setattr(cfg, 'broll_library', str(clip_broll_dir))  # Utiliser le dossier unique
                
                print(f"    ðŸ”„ Fetch B-roll personnalisÃ© pour clip: {clip_id}")
                print(f"    ðŸ“ Dossier B-roll unique: {clip_broll_dir.name}")
                
                # ðŸš€ NOUVEAU: IntÃ©gration du sÃ©lecteur B-roll gÃ©nÃ©rique
                if BROLL_SELECTOR_AVAILABLE and getattr(Config, 'BROLL_SELECTOR_ENABLED', True):
                    try:
                        print("    ðŸŽ¯ SÃ©lecteur B-roll gÃ©nÃ©rique activÃ© - Scoring mixte intelligent")
                        
                        # Initialiser le sÃ©lecteur avec la configuration
                        selector_config = None
                        if getattr(Config, 'BROLL_SELECTOR_CONFIG_PATH', None):
                            try:
                                import yaml
                                with open(Config.BROLL_SELECTOR_CONFIG_PATH, 'r', encoding='utf-8') as f:
                                    selector_config = yaml.safe_load(f)
                                print(f"    âš™ï¸ Configuration chargÃ©e: {Config.BROLL_SELECTOR_CONFIG_PATH}")
                            except Exception as e:
                                print(f"    âš ï¸ Erreur chargement config: {e}")
                        
                        # CrÃ©er le sÃ©lecteur
                        from broll_selector import BrollSelector
                        broll_selector = BrollSelector(selector_config)
                        
                        # ðŸš€ CORRECTION: Utiliser les mots-clÃ©s LLM intelligents au lieu du fallback basique
                        context_keywords = []
                        
                        # ðŸŽ¯ PRIORITÃ‰ 0: Utiliser les VRAIS mots-clÃ©s LLM du systÃ¨me industriel
                        if llm_broll_keywords and len(llm_broll_keywords) > 0:
                            context_keywords = llm_broll_keywords[:15]  # Prendre les 15 meilleurs
                            print(f"    ðŸš€ Mots-clÃ©s LLM INDUSTRIELS utilisÃ©s: {len(context_keywords)} termes")
                            print(f"    ðŸŽ¯ Mots-clÃ©s: {', '.join(context_keywords[:5])}")
                        
                        # PrioritÃ© 1: Utiliser l'analyse intelligente si disponible
                        elif 'global_analysis' in locals():
                            context_keywords = global_analysis.keywords[:10] if hasattr(global_analysis, 'keywords') else []
                        
                        # PrioritÃ© 2: Utiliser les mots-clÃ©s LLM corrigÃ©s (notre extraction amÃ©liorÃ©e)
                        if not context_keywords and 'analysis' in locals():
                            # Extraire les meilleurs mots-clÃ©s de notre systÃ¨me LLM
                            llm_keywords = []
                            if isinstance(analysis, dict) and 'keywords' in analysis:
                                for category, kws in analysis['keywords'].items():
                                    if isinstance(kws, list):
                                        llm_keywords.extend(kws[:3])  # 3 meilleurs par catÃ©gorie
                            
                            # Ajouter le thÃ¨me dominant
                            if analysis.get('dominant_theme'):
                                llm_keywords.insert(0, analysis['dominant_theme'])
                            
                            context_keywords = llm_keywords[:15] if llm_keywords else []
                            print(f"    ðŸ§  Mots-clÃ©s LLM intelligents utilisÃ©s: {len(context_keywords)} termes")
                        
                        # PrioritÃ© 3: Fallback basique seulement si aucun autre systÃ¨me
                        if not context_keywords:
                            # Extraction basique amÃ©liorÃ©e - mots significatifs seulement
                            significant_words = []
                            for s in subtitles:
                                text = s.get('text', '')
                                if text:
                                    words = text.lower().split()
                                    # Filtrer les mots vides et garder les mots significatifs
                                    meaningful_words = [w for w in words if len(w) > 4 and w.isalpha() 
                                                      and w not in ['that', 'this', 'they', 'there', 'where', 'when', 'what', 'with', 'have', 'your', 'once', 'figure']]
                                    significant_words.extend(meaningful_words)
                            
                            # DÃ©duplication et limitation
                            context_keywords = list(dict.fromkeys(significant_words))[:10]
                            print(f"    âš ï¸ Fallback vers extraction basique amÃ©liorÃ©e: {len(context_keywords)} termes")
                        
                        # DÃ©tecter le domaine
                        detected_domain = None
                        if 'global_analysis' in locals() and hasattr(global_analysis, 'main_theme'):
                            detected_domain = global_analysis.main_theme
                        
                        print(f"    ðŸŽ¯ Contexte: {detected_domain or 'gÃ©nÃ©ral'}")
                        print(f"    ðŸ”‘ Mots-clÃ©s contextuels: {', '.join(context_keywords[:5])}")
                        
                        # Utiliser le sÃ©lecteur pour la planification
                        selection_report = broll_selector.select_brolls(
                            keywords=context_keywords,
                            domain=detected_domain,
                            min_delay=self._load_broll_selector_config().get('thresholds', {}).get('min_delay_seconds', 4.0),
                            desired_count=self._load_broll_selector_config().get('desired_broll_count', 3)
                        )
                        
                        # Sauvegarder le rapport de sÃ©lection
                        try:
                            meta_dir = Config.OUTPUT_FOLDER / 'meta'
                            meta_dir.mkdir(parents=True, exist_ok=True)
                            selection_report_path = meta_dir / f"{Path(input_path).stem}_broll_selection_report.json"
                            with open(selection_report_path, 'w', encoding='utf-8') as f:
                                json.dump(selection_report, f, ensure_ascii=False, indent=2)
                            print(f"    ðŸ’¾ Rapport de sÃ©lection sauvegardÃ©: {selection_report_path}")
                        except Exception as e:
                            print(f"    âš ï¸ Erreur sauvegarde rapport: {e}")
                        
                        # Afficher les statistiques de sÃ©lection
                        if 'diagnostics' in selection_report:
                            diag = selection_report['diagnostics']
                            print(f"    ðŸ“Š SÃ©lection: {diag.get('num_selected', 0)}/{diag.get('num_candidates', 0)} B-rolls")
                            print(f"    ðŸŽ¯ Top score: {diag.get('top_score', 0):.3f}")
                            print(f"    ðŸ“ Seuil appliquÃ©: {diag.get('min_score', 0):.3f}")
                        
                        if selection_report.get('fallback_used'):
                            print(f"    ðŸ†˜ Fallback activÃ©: Tier {selection_report.get('fallback_tier', '?')}")
                        
                    except Exception as e:
                        print(f"    âš ï¸ Erreur sÃ©lecteur gÃ©nÃ©rique: {e}")
                        print("    ðŸ”„ Fallback vers systÃ¨me existant")
                
                # ðŸš€ CORRECTION: IntÃ©gration des mots-clÃ©s LLM pour le fetch
                # SÃ‰LECTION INTELLIGENTE: Mots-clÃ©s contextuels + concepts associÃ©s
                from collections import Counter as _Counter
                kw_pool: list[str] = []
                
                # ðŸ§  PRIORITÃ‰ 1: Mots-clÃ©s LLM si disponibles
                if broll_keywords:
                    try:
                        if not isinstance(broll_keywords, (list, tuple)):
                            print(f"    âŒ Format invalide broll_keywords: {type(broll_keywords)}")
                            broll_keywords = []
                        else:
                            # Normalisation/filtrage
                            broll_keywords = [
                                (kw.strip() if isinstance(kw, str) else "")
                                for kw in broll_keywords
                                if isinstance(kw, str) and kw and kw.strip()
                            ]
                    except (TypeError, AttributeError):
                        broll_keywords = []
                    
                    if broll_keywords:
                        print(f"    ðŸš€ Utilisation des mots-clÃ©s LLM pour le fetch: {len(broll_keywords)} termes")
                        # Ajouter TOUS les mots-clÃ©s LLM en prioritÃ©
                        for kw in broll_keywords:
                            low = (kw or '').strip().lower()
                            if low and len(low) >= 3:
                                kw_pool.append(low)
                                # Ajouter des variations pour enrichir
                                if ' ' in low:  # Mots composÃ©s
                                    parts = low.split()
                                    kw_pool.extend(parts)
                        print(f"    ðŸŽ¯ Mots-clÃ©s LLM ajoutÃ©s: {', '.join(broll_keywords[:8])}")
                    else:
                        print("    âš ï¸ Mots-clÃ©s LLM indisponibles aprÃ¨s validation, fallback basique")
                
                # ðŸ”„ PRIORITÃ‰ 2: Extraction des mots-clÃ©s du transcript
                for s in subtitles:
                    base_kws = extract_keywords_for_segment(s.get('text','')) or []
                    spacy_kws = self._extract_keywords_for_segment_spacy(s.get('text','')) or []
                    for kw in (base_kws + spacy_kws):
                        low = (kw or '').strip().lower()
                        if low and len(low) >= 3:
                            kw_pool.append(low)
                
                # ðŸš€ CONCEPTS ASSOCIÃ‰S ENRICHIS (50+ concepts)
                concept_mapping = {
                    # ðŸ§  Cerveau & Intelligence
                    'brain': ['neuroscience', 'mind', 'thinking', 'intelligence', 'cognitive', 'mental', 'psychology', 'consciousness'],
                    'mind': ['brain', 'thinking', 'thought', 'intelligence', 'cognitive', 'mental', 'psychology'],
                    'thinking': ['brain', 'mind', 'thought', 'intelligence', 'cognitive', 'mental', 'logic'],
                    
                    # ðŸ’° Argent & Finance
                    'money': ['finance', 'business', 'success', 'wealth', 'investment', 'cash', 'profit', 'revenue'],
                    'argent': ['finance', 'business', 'success', 'wealth', 'investment', 'cash', 'profit', 'revenue'],
                    'finance': ['money', 'business', 'investment', 'wealth', 'profit', 'revenue', 'budget'],
                    
                    # ðŸŽ¯ Focus & Concentration
                    'focus': ['concentration', 'productivity', 'attention', 'mindfulness', 'clarity', 'precision'],
                    'concentration': ['focus', 'attention', 'mindfulness', 'clarity', 'precision', 'dedication'],
                    'attention': ['focus', 'concentration', 'mindfulness', 'awareness', 'observation'],
                    
                    # ðŸ† SuccÃ¨s & RÃ©ussite
                    'success': ['achievement', 'goal', 'victory', 'winning', 'growth', 'accomplishment', 'triumph'],
                    'succÃ¨s': ['achievement', 'goal', 'victory', 'winning', 'growth', 'accomplishment', 'triumph'],
                    'victory': ['success', 'achievement', 'winning', 'triumph', 'conquest', 'domination'],
                    
                    # â¤ï¸ SantÃ© & Bien-Ãªtre
                    'health': ['wellness', 'fitness', 'medical', 'lifestyle', 'nutrition', 'vitality', 'strength'],
                    'santÃ©': ['wellness', 'fitness', 'medical', 'lifestyle', 'nutrition', 'vitality', 'strength'],
                    'fitness': ['health', 'wellness', 'exercise', 'training', 'strength', 'endurance'],
                    
                    # ðŸ¤– Technologie & Innovation
                    'technology': ['digital', 'innovation', 'future', 'ai', 'automation', 'tech', 'modern'],
                    'technologie': ['digital', 'innovation', 'future', 'ai', 'automation', 'tech', 'modern'],
                    'innovation': ['technology', 'digital', 'future', 'ai', 'automation', 'creativity', 'progress'],
                    
                    # ðŸ’¼ Business & Entreprise
                    'business': ['entrepreneur', 'startup', 'strategy', 'leadership', 'growth', 'company', 'enterprise'],
                    'entreprise': ['entrepreneur', 'startup', 'strategy', 'leadership', 'growth', 'company', 'enterprise'],
                    'strategy': ['business', 'planning', 'tactics', 'approach', 'method', 'system'],
                    
                    # ðŸš€ Action & Dynamisme
                    'action': ['movement', 'energy', 'power', 'vitality', 'dynamism', 'activity', 'motion'],
                    'action': ['movement', 'energy', 'power', 'vitality', 'dynamism', 'activity', 'motion'],
                    'energy': ['power', 'vitality', 'strength', 'force', 'intensity', 'enthusiasm'],
                    
                    # ðŸ”¥ Ã‰motion & Passion
                    'emotion': ['feeling', 'passion', 'excitement', 'inspiration', 'motivation', 'enthusiasm'],
                    'Ã©motion': ['feeling', 'passion', 'excitement', 'inspiration', 'motivation', 'enthusiasm'],
                    'passion': ['emotion', 'feeling', 'excitement', 'inspiration', 'motivation', 'enthusiasm'],
                    
                    # ðŸ§  DÃ©veloppement Personnel
                    'growth': ['development', 'improvement', 'progress', 'advancement', 'evolution', 'maturity'],
                    'croissance': ['development', 'improvement', 'progress', 'advancement', 'evolution', 'maturity'],
                    'development': ['growth', 'improvement', 'progress', 'advancement', 'evolution', 'maturity'],
                    
                    # âœ… Solutions & RÃ©solution
                    'solution': ['resolution', 'fix', 'answer', 'remedy', 'cure', 'treatment'],
                    'solution': ['resolution', 'fix', 'answer', 'remedy', 'cure', 'treatment'],
                    'resolution': ['solution', 'fix', 'answer', 'remedy', 'cure', 'treatment'],
                    
                    # âš ï¸ ProblÃ¨mes & DÃ©fis
                    'problem': ['challenge', 'difficulty', 'obstacle', 'barrier', 'issue', 'trouble'],
                    'problÃ¨me': ['challenge', 'difficulty', 'obstacle', 'barrier', 'issue', 'trouble'],
                    'challenge': ['problem', 'difficulty', 'obstacle', 'barrier', 'issue', 'trouble'],
                    
                    # ðŸŒŸ QualitÃ© & Excellence
                    'quality': ['excellence', 'perfection', 'superiority', 'premium', 'best', 'optimal'],
                    'qualitÃ©': ['excellence', 'perfection', 'superiority', 'premium', 'best', 'optimal'],
                    'excellence': ['quality', 'perfection', 'superiority', 'premium', 'best', 'optimal']
                }
                
                # Enrichir avec des concepts associÃ©s
                for kw in kw_pool[:]:
                    for concept, related in concept_mapping.items():
                        if concept in kw or any(r in kw for r in related):
                            kw_pool.extend(related[:2])  # Ajouter 2 concepts max
                
                counts = _Counter(kw_pool)
                
                # ðŸš¨ CORRECTION CRITIQUE: PRIORISER les mots-clÃ©s LLM sur les mots-clÃ©s gÃ©nÃ©riques
                if 'broll_keywords' in locals() and broll_keywords:
                    # Utiliser DIRECTEMENT les mots-clÃ©s LLM comme requÃªte principale
                    llm_keywords = [kw.strip().lower() for kw in broll_keywords if kw and len(kw.strip()) >= 3]
                    if llm_keywords:
                        # Prendre les 8 premiers mots-clÃ©s LLM + 2 concepts associÃ©s
                        top_kws = llm_keywords[:8]
                        # Ajouter quelques concepts associÃ©s pour enrichir
                        for kw in top_kws[:3]:  # Pour les 3 premiers mots-clÃ©s LLM
                            for concept, related in concept_mapping.items():
                                if concept in kw or any(r in kw for r in related):
                                    top_kws.extend(related[:1])  # 1 concept max par mot-clÃ© LLM
                                    break
                        print(f"    ðŸš€ REQUÃŠTE LLM PRIORITAIRE: {' '.join(top_kws[:5])}")
                    else:
                        top_kws = [w for w,_n in counts.most_common(15)]
                        print(f"    ðŸ”„ Fallback vers mots-clÃ©s gÃ©nÃ©riques: {' '.join(top_kws[:5])}")
                else:
                    top_kws = [w for w,_n in counts.most_common(15)]
                    print(f"    ðŸ”„ Mots-clÃ©s gÃ©nÃ©riques: {' '.join(top_kws[:5])}")
                
                # Fallback intelligent selon le contexte
                if not top_kws:
                    top_kws = ["focus","concentration","study","brain","mind","productivity","success"]
                print(f"    ðŸ”Ž Fetch B-roll sur requÃªte: {' '.join(top_kws[:5])}")
                # Provider auto-fallback si pas de clÃ©s -> archive
                import os as _os
                pex = getattr(Config, 'PEXELS_API_KEY', None) or _os.getenv('PEXELS_API_KEY')
                pixa = getattr(Config, 'PIXABAY_API_KEY', None) or _os.getenv('PIXABAY_API_KEY')
                uns = getattr(Config, 'UNSPLASH_ACCESS_KEY', None) or _os.getenv('UNSPLASH_ACCESS_KEY')
                giphy = _os.getenv('GIPHY_API_KEY')  # ðŸŽ­ GIPHY pour GIFs animÃ©s
                # Exposer l'accÃ¨s Unsplash dans la cfg si dispo
                try:
                    if uns:
                        setattr(cfg, 'unsplash_access_key', uns)
                except Exception:
                    pass
                if not any([pex, pixa, uns]):
                    try:
                        setattr(cfg, 'fetch_provider', 'archive')
                        print("    ðŸŒ Providers: archive (aucune clÃ© API dÃ©tectÃ©e)")
                    except Exception:
                        pass
                else:
                    # ðŸš€ AMÃ‰LIORATION: Construire une liste de providers optimisÃ©e
                    prov = []
                    if pex:
                        prov.append('pexels')
                    if pixa:
                        prov.append('pixabay')
                    if uns:
                        prov.append('unsplash')
                    if giphy:
                        prov.append('giphy')  # ðŸŽ­ GIPHY pour GIFs animÃ©s
                    
                    # ðŸŽ¯ AJOUT SÃ‰CURISÃ‰: Archive.org comme source supplÃ©mentaire
                    try:
                        if prov:  # Si on a des providers avec clÃ©s API
                            prov.append('archive')  # Ajouter Archive.org
                            print(f"    ðŸŒ Providers: {','.join(prov)} (Archive.org + Giphy ajoutÃ©s pour variÃ©tÃ©)")
                        else:
                            prov = ['archive']  # Seulement Archive.org si pas de clÃ©s
                            print(f"    ðŸŒ Providers: {','.join(prov)} (Archive.org uniquement)")
                        
                        setattr(cfg, 'fetch_provider', ",".join(prov))
                    except Exception as e:
                        # Fallback sÃ©curisÃ©
                        try:
                            if prov:
                                setattr(cfg, 'fetch_provider', ",".join(prov))
                                print(f"    ðŸŒ Providers: {','.join(prov)} (fallback sÃ©curisÃ©)")
                            else:
                                setattr(cfg, 'fetch_provider', 'archive')
                                print(f"    ðŸŒ Providers: archive (fallback ultime)")
                        except Exception:
                            pass
                
                try:
                    setattr(cfg, 'fetch_allow_images', True)
                    # ðŸš€ OPTIMISATION MULTI-SOURCES: QualitÃ© optimale (CORRIGÃ‰)
                    if uns and giphy:  # Si Unsplash ET Giphy sont disponibles
                        setattr(cfg, 'fetch_max_per_keyword', 35)  # CORRIGÃ‰: 125 â†’ 35 pour qualitÃ© maximale
                        print("    ðŸ“Š Configuration optimisÃ©e: 35 assets max + images activÃ©es (Unsplash + Giphy + Archive)")
                    elif uns:  # Si seulement Unsplash est disponible
                        setattr(cfg, 'fetch_max_per_keyword', 30)  # CORRIGÃ‰: 100 â†’ 30 pour qualitÃ© maximale
                        print("    ðŸ“Š Configuration optimisÃ©e: 30 assets max + images activÃ©es (Unsplash + Archive)")
                    elif giphy:  # Si seulement Giphy est disponible
                        setattr(cfg, 'fetch_max_per_keyword', 30)  # CORRIGÃ‰: 100 â†’ 30 pour qualitÃ© avec GIFs
                        print("    ðŸ“Š Configuration optimisÃ©e: 30 assets max + images activÃ©es (Giphy + Archive)")
                    else:
                        setattr(cfg, 'fetch_max_per_keyword', 25)  # CORRIGÃ‰: 75 â†’ 25 pour Archive.org
                        print("    ðŸ“Š Configuration optimisÃ©e: 25 assets max + images activÃ©es (Archive.org)")
                except Exception:
                    pass
                
                # DÃ©clencher le fetch par mot-clÃ© avec limites dynamiques (5 gÃ©nÃ©rique, 8 spÃ©cifique)
                def _is_generic_fetch_keyword(kw: str) -> bool:
                    if not isinstance(kw, str):
                        return True
                    k = kw.strip().lower()
                    # Expressions multi-mots = spÃ©cifiques
                    if ' ' in k:
                        return False
                    GENERIC_SIMPLE = {
                        'people','person','start','thing','stuff','your','once','figure',
                        'they','them','this','that','what','when','where','how','any','some'
                    }
                    return (k in GENERIC_SIMPLE) or (len(k) <= 6)
                
                for _kw in top_kws:
                    per_kw_limit = 5 if _is_generic_fetch_keyword(_kw) else 8
                    try:
                        setattr(cfg, 'fetch_max_per_keyword', per_kw_limit)
                        print(f"    ðŸ”§ Limite par mot-clÃ© '{_kw}': {per_kw_limit} assets")
                    except Exception:
                        pass
                    ensure_assets_for_keywords(cfg, [_kw])
                
                # ðŸš¨ CORRECTION CRITIQUE: SYSTÃˆME D'UNICITÃ‰ DES B-ROLLS
                # Ã‰viter la duplication des B-rolls entre vidÃ©os diffÃ©rentes
                try:
                    # CrÃ©er un fichier de traÃ§abilitÃ© des B-rolls utilisÃ©s
                    broll_tracking_file = Config.OUTPUT_FOLDER / 'meta' / 'broll_usage_tracking.json'
                    broll_tracking_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Charger l'historique des B-rolls utilisÃ©s
                    broll_history = {}
                    if broll_tracking_file.exists():
                        try:
                            with open(broll_tracking_file, 'r', encoding='utf-8') as f:
                                broll_history = json.load(f)
                        except Exception:
                            broll_history = {}
                    
                    # Identifier les B-rolls disponibles pour ce clip
                    available_brolls = []
                    for asset_path in clip_broll_dir.rglob('*'):
                        if asset_path.suffix.lower() in {'.mp4', '.mov', '.mkv', '.webm', '.jpg', '.jpeg', '.png'}:
                            asset_hash = self._calculate_asset_hash(asset_path)
                            asset_info = {
                                'path': str(asset_path),
                                'hash': asset_hash,
                                'size': asset_path.stat().st_size,
                                'last_used': None,
                                'usage_count': 0
                            }
                            
                            # VÃ©rifier si ce B-roll a dÃ©jÃ  Ã©tÃ© utilisÃ©
                            if asset_hash in broll_history:
                                asset_info['last_used'] = broll_history[asset_hash].get('last_used')
                                asset_info['usage_count'] = broll_history[asset_hash].get('usage_count', 0)
                            
                            available_brolls.append(asset_info)
                    
                    # Trier par prioritÃ©: B-rolls jamais utilisÃ©s en premier, puis par anciennetÃ©
                    available_brolls.sort(key=lambda x: (x['usage_count'], x['last_used'] or '1970-01-01'))
                    
                    # SÃ©lectionner les B-rolls uniques pour cette vidÃ©o
                    selected_brolls = available_brolls[:3]  # 3 B-rolls uniques
                    
                    # Mettre Ã  jour l'historique d'utilisation
                    current_time = datetime.now().isoformat()
                    for broll in selected_brolls:
                        broll_history[broll['hash']] = {
                            'last_used': current_time,
                            'usage_count': broll['usage_count'] + 1,
                            'video_id': Path(input_path).stem
                        }
                    
                    # Sauvegarder l'historique
                    with open(broll_tracking_file, 'w', encoding='utf-8') as f:
                        json.dump(broll_history, f, ensure_ascii=False, indent=2)
                    
                    print(f"    ðŸŽ¯ B-rolls uniques sÃ©lectionnÃ©s: {len(selected_brolls)} (Ã©vite duplication)")
                    
                except Exception as e:
                    print(f"    âš ï¸ Erreur systÃ¨me d'unicitÃ©: {e}")
                    # Fallback: utiliser tous les B-rolls disponibles
                    pass
                
                # Comptage aprÃ¨s fetch dans le dossier du clip
                try:
                    _media_exts = {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}
                    _after = [p for p in clip_broll_dir.rglob('*') if p.suffix.lower() in _media_exts]
                    print(f"    ðŸ“¥ Fetch terminÃ©: {len(_after)} assets pour ce clip")
                    
                    # ðŸš¨ CORRECTION CRITIQUE: CrÃ©er fetched_brolls accessible globalement
                    fetched_brolls = []
                    for asset_path in _after:
                        if asset_path.exists():
                            fetched_brolls.append({
                                'path': str(asset_path),
                                'name': asset_path.name,
                                'size': asset_path.stat().st_size if asset_path.exists() else 0
                            })
                    
                    print(f"    ðŸŽ¯ {len(fetched_brolls)} B-rolls prÃªts pour l'assignation")
                    
                    if len(_after) == 0:
                        print("    âš ï¸ Aucun asset tÃ©lÃ©chargÃ©. VÃ©rifie les clÃ©s API et la connectivitÃ© rÃ©seau.")
                except Exception:
                    fetched_brolls = []
                    print("    âš ï¸ Erreur lors de la prÃ©paration des B-rolls fetchÃ©s")
                
                # Construire l'index FAISS pour ce clip spÃ©cifique
                try:
                    if 'build_index' in globals() and build_index is not None:  # type: ignore[name-defined]
                        index_handle = build_index(str(clip_broll_dir), model_name='ViT-B/32')  # type: ignore[misc]
                        print(f"    ðŸ§­ Index FAISS construit pour {clip_id}: {len(_after)} assets")
                except Exception:
                    index_handle = None
            except Exception:
                pass
  
            # Extensions optionnelles pour crossfade/LUT
            try:
                setattr(cfg, 'crossfade_frames', 3)
                setattr(cfg, 'enable_color_match', True)
                setattr(cfg, 'transition_mode', 'auto')  # 'auto' | 'cut' | 'crossfade' | 'zoom'
                setattr(cfg, 'allow_zoom_transitions', True)
                setattr(cfg, 'enable_image_kenburns', True)
            except Exception:
                pass
            
            # PrÃ©parer stop-words (legacy pipeline)
            stopwords: set[str] = set()
            try:
                swp = Path('config/stopwords.txt')
                if swp.exists():
                    stopwords = {ln.strip().lower() for ln in swp.read_text(encoding='utf-8').splitlines() if ln.strip()}
            except Exception:
                stopwords = set()

            # ðŸš€ CORRECTION: IntÃ©gration des mots-clÃ©s LLM dans la planification
            # Planification: nouvelle API prÃ©fÃ©rÃ©e (plan_broll_insertions(segments, cfg, index))
            
            # ðŸš¨ CORRECTION CRITIQUE: fetched_brolls est dÃ©jÃ  dÃ©clarÃ© plus haut, ne pas le redÃ©clarer !
            # fetched_brolls = []  # âŒ SUPPRIMÃ‰: Cette ligne Ã©crase la variable fetchÃ©e !
            
            try:
                plan = plan_broll_insertions(segments, cfg, index_handle)  # type: ignore[arg-type]
            except Exception:
                # ðŸš€ NOUVEAU: Utiliser les mots-clÃ©s LLM pour la planification
                seg_keywords: List[List[str]] = []
                
                # ðŸ§  PRIORITÃ‰ 1: Mots-clÃ©s LLM si disponibles
                if 'broll_keywords' in locals() and broll_keywords:
                    print(f"    ðŸš€ Utilisation des mots-clÃ©s LLM pour la planification: {len(broll_keywords)} termes")
                    # Distribuer les mots-clÃ©s LLM sur les segments
                    for i, s in enumerate(segments):
                        # Prendre 2-3 mots-clÃ©s LLM par segment
                        start_idx = (i * 2) % len(broll_keywords)
                        end_idx = min(start_idx + 2, len(broll_keywords))
                        segment_llm_kws = broll_keywords[start_idx:end_idx]
                        
                        # Combiner avec extraction basique
                        base_kws = extract_keywords_for_segment(s.text) or []
                        spacy_kws = self._extract_keywords_for_segment_spacy(s.text) or []
                        
                        # ðŸŽ¯ PRIORITÃ‰ aux mots-clÃ©s LLM
                        merged: List[str] = segment_llm_kws + base_kws + spacy_kws
                        
                        # Nettoyer et dÃ©dupliquer
                        cleaned: List[str] = []
                        seen = set()
                        for kw in merged:
                            if kw and kw.lower() not in seen:
                                low = kw.lower()
                                if not (len(low) < 3 and low in stopwords):
                                    cleaned.append(low)
                                    seen.add(low)
                        
                        seg_keywords.append(cleaned[:8])  # OPTIMISÃ‰: 15 â†’ 8 pour vitesse
                        print(f"    ðŸŽ¯ Segment {i}: {len(cleaned)} mots-clÃ©s (LLM: {len(segment_llm_kws)})")
                else:
                    # ðŸ”„ Fallback: extraction basique uniquement
                    print("    âš ï¸ Mots-clÃ©s LLM non disponibles, utilisation extraction basique")
                    for s in segments:
                        base_kws = extract_keywords_for_segment(s.text) or []
                        spacy_kws = self._extract_keywords_for_segment_spacy(s.text) or []
                        merged: List[str] = []
                        for kw in (base_kws + spacy_kws):
                            if kw and kw.lower() not in merged:
                                low = kw.lower()
                                if not (len(low) < 5 and low in stopwords):
                                    merged.append(low)
                        seg_keywords.append(merged[:6])
                
                with _VFC(str(input_path)) as _tmp:
                    duration = float(_tmp.duration)
                plan = plan_broll_insertions(  # type: ignore[call-arg]
                    segments,
                    seg_keywords,
                    total_duration=duration,
                    max_broll_ratio=cfg.max_broll_ratio,
                    min_gap_between_broll_s=cfg.min_gap_between_broll_s,
                    max_broll_clip_s=cfg.max_broll_clip_s,
                    min_broll_clip_s=1.5,  # ðŸš€ OPTIMISÃ‰: 0.8s â†’ 1.5s pour B-rolls plus visibles
                )
                
                # ðŸš¨ CORRECTION CRITIQUE: Assigner directement les B-rolls fetchÃ©s aux items du plan
                if plan and fetched_brolls:
                    print(f"    ðŸŽ¯ Assignation directe des {len(fetched_brolls)} B-rolls fetchÃ©s aux {len(plan)} items du plan...")
                    
                    # Filtrer les B-rolls valides
                    valid_brolls = [broll for broll in fetched_brolls if broll.get('path') and Path(broll.get('path')).exists()]
                    
                    if valid_brolls:
                        # Assigner les B-rolls aux items du plan
                        for i, item in enumerate(plan):
                            if i < len(valid_brolls):
                                asset_path = valid_brolls[i]['path']
                                
                                # Assigner l'asset_path selon le type d'objet
                                if hasattr(item, 'asset_path'):
                                    item.asset_path = asset_path
                                elif isinstance(item, dict):
                                    item['asset_path'] = asset_path
                                
                                print(f"    âœ… B-roll {i+1} assignÃ©: {Path(asset_path).name}")
                            else:
                                break
                        
                        print(f"    ðŸŽ‰ {min(len(plan), len(valid_brolls))} B-rolls assignÃ©s avec succÃ¨s au plan")
                    else:
                        print(f"    âš ï¸ Aucun B-roll valide trouvÃ© dans fetched_brolls")
                elif not fetched_brolls:
                    print(f"    âš ï¸ Aucun B-roll fetchÃ© disponible pour l'assignation")
                elif not plan:
                    print(f"    âš ï¸ Plan vide - aucun item Ã  traiter")
            # Scoring adaptatif si disponible (pertinence/diversitÃ©/esthÃ©tique)
            

            
            try:
                from src.pipeline.scoring import score_candidates  # type: ignore
                boosts = {
                    # ðŸš€ Business & Croissance
                    "croissance": 0.9, "growth": 0.9, "opportunitÃ©": 0.8, "opportunite": 0.8,
                    "innovation": 0.9, "dÃ©veloppement": 0.8, "developpement": 0.8, "expansion": 0.8,
                    "stratÃ©gie": 0.8, "strategie": 0.8, "plan": 0.7, "objectif": 0.8, "vision": 0.8,
                    
                    # ðŸ’° Argent & Finance
                    "argent": 1.0, "money": 1.0, "cash": 0.9, "investissement": 0.9, "investissements": 0.9,
                    "revenu": 0.8, "revenus": 0.8, "profit": 0.9, "profits": 0.9, "perte": 0.7, "pertes": 0.7,
                    "Ã©chec": 0.7, "echec": 0.7, "budget": 0.7, "gestion": 0.7, "marge": 0.8, "roi": 0.9,
                    "chiffre": 0.7, "ca": 0.7, "Ã©conomie": 0.8, "economie": 0.8, "financier": 0.8,
                    
                    # ðŸ¤ Relation & Client
                    "client": 0.9, "clients": 0.9, "collaboration": 0.8, "collaborations": 0.8,
                    "communautÃ©": 0.7, "communaute": 0.7, "confiance": 0.7, "vente": 0.8, "ventes": 0.8,
                    "deal": 0.7, "deals": 0.7, "prospect": 0.6, "prospects": 0.6, "contrat": 0.7,
                    "partenariat": 0.8, "Ã©quipe": 0.7, "equipe": 0.7, "rÃ©seau": 0.7, "reseau": 0.7,
                    
                    # ðŸ”¥ Motivation & SuccÃ¨s
                    "succÃ¨s": 0.9, "succes": 0.9, "motivation": 0.8, "Ã©nergie": 0.7, "energie": 0.7,
                    "victoire": 0.8, "discipline": 0.7, "viral": 0.8, "viralitÃ©": 0.8, "viralite": 0.8,
                    "impact": 0.6, "explose": 0.6, "explosion": 0.6, "inspiration": 0.8, "passion": 0.8,
                    "dÃ©termination": 0.8, "determination": 0.8, "persÃ©vÃ©rance": 0.8, "perseverance": 0.8,
                    
                    # ðŸ§  Intelligence & Apprentissage
                    "cerveau": 1.0, "brain": 1.0, "intelligence": 0.9, "savoir": 0.8, "connaissance": 0.8,
                    "apprentissage": 0.8, "apprendre": 0.8, "Ã©tude": 0.8, "etude": 0.8, "formation": 0.8,
                    "compÃ©tence": 0.8, "competence": 0.8, "expertise": 0.8, "maÃ®trise": 0.8, "maitrise": 0.8,
                    
                    # ðŸ’¡ Innovation & Technologie
                    "technologie": 0.9, "tech": 0.9, "innovation": 0.9, "digital": 0.8, "numÃ©rique": 0.8,
                    "numerique": 0.8, "futur": 0.8, "avancÃ©e": 0.8, "avancee": 0.8, "rÃ©volution": 0.8,
                    "revolution": 0.8, "disruption": 0.8, "transformation": 0.8, "Ã©volution": 0.8, "evolution": 0.8,
                    
                    # âš ï¸ Risque & Erreurs
                    "erreur": 0.6, "erreurs": 0.6, "warning": 0.6, "obstacle": 0.6, "obstacles": 0.6,
                    "solution": 0.6, "solutions": 0.6, "leÃ§on": 0.5, "lecon": 0.5, "apprentissage": 0.5,
                    "problÃ¨me": 0.6, "probleme": 0.6, "dÃ©fi": 0.7, "defi": 0.7, "challenge": 0.7,
                    
                    # ðŸŒŸ QualitÃ© & Excellence
                    "excellence": 0.9, "qualitÃ©": 0.8, "qualite": 0.8, "perfection": 0.8, "meilleur": 0.8,
                    "optimal": 0.8, "efficacitÃ©": 0.8, "efficacite": 0.8, "performance": 0.8, "rÃ©sultat": 0.8,
                    "resultat": 0.8, "succÃ¨s": 0.9, "succes": 0.9, "rÃ©ussite": 0.9, "reussite": 0.9,
                }
                plan = score_candidates(
                    plan, segments, broll_library=str(broll_library), clip_model='ViT-B/32',
                    use_faiss=True, top_k=10, keyword_boosts=boosts
                )
                
            except Exception:
                pass
 
            # FILTRE: Exclure les B-rolls trop tÃ´t dans la vidÃ©o (dÃ©lai minimum 3 secondes)
            try:
                filtered_plan = []
                for it in plan:
                    st = float(getattr(it, 'start', 0.0) if hasattr(it, 'start') else (it.get('start', 0.0) if isinstance(it, dict) else 0.0))
                    if st >= 3.0:  # DÃ©lai minimum de 3 secondes avant le premier B-roll
                        filtered_plan.append(it)
                    else:
                        print(f"    â° B-roll filtrÃ©: trop tÃ´t Ã  {st:.2f}s (minimum 3.0s)")
                
                plan = filtered_plan
                print(f"    âœ… Plan filtrÃ©: {len(plan)} B-rolls aprÃ¨s dÃ©lai minimum")
            except Exception:
                pass

            # DÃ©duplication souple: autoriser rÃ©utilisation si espacÃ©e (> 12s)
            try:
                seen: dict[str, float] = {}
                new_plan = []
                for it in plan:
                    # ðŸ”§ CORRECTION: GÃ©rer Ã  la fois BrollPlanItem et dict
                    if hasattr(it, 'asset_path'):
                        ap = it.asset_path
                        st = float(it.start)
                    elif isinstance(it, dict):
                        ap = it.get('asset_path')
                        st = float(it.get('start', 0.0))
                    else:
                        # Fallback pour autres types
                        ap = getattr(it, 'asset_path', None)
                        st = float(getattr(it, 'start', 0.0))
                    
                    if not ap:
                        new_plan.append(it)
                        continue
                    
                    last = seen.get(ap, -1e9)
                    if st - last >= 8.0:
                        new_plan.append(it)
                        seen[ap] = st
                plan = new_plan
                
            except Exception:
                pass
 
            # ðŸš€ PRIORISATION FRAÃŽCHEUR: Trier par timestamp du dossier (plus rÃ©cent en premier)
            try:
                if plan:
                    # Extraire le clip_id pour la priorisation
                    clip_id = input_path.stem
                    
                    # Prioriser par fraÃ®cheur si possible
                    for item in plan:
                        if hasattr(item, 'asset_path') and item.asset_path:
                            asset_path = item.asset_path
                        elif isinstance(item, dict) and item.get('asset_path'):
                            asset_path = item['asset_path']
                        else:
                            continue
                        
                        # Calculer le score de fraÃ®cheur
                        try:
                            path = Path(asset_path)
                            for part in path.parts:
                                if part.startswith(f"clip_{clip_id}_") and "_" in part:
                                    timestamp_str = part.split("_")[-1]
                                    if timestamp_str.isdigit():
                                        item.freshness_score = int(timestamp_str)
                                        break
                            else:
                                item.freshness_score = 0
                        except Exception:
                            item.freshness_score = 0
                    
                    # Trier par fraÃ®cheur dÃ©croissante
                    plan.sort(key=lambda x: getattr(x, 'freshness_score', 0), reverse=True)
                    print(f"    ðŸ†• Priorisation fraÃ®cheur: {len(plan)} B-rolls triÃ©s par timestamp")
                    
            except Exception as e:
                print(f"    âš ï¸  Erreur priorisation fraÃ®cheur: {e}")
 
            # ðŸŽ¯ SCORING CONTEXTUEL RENFORCÃ‰: PÃ©naliser les assets non pertinents au domaine
            try:
                if plan and "global_analysis" in locals() and hasattr(global_analysis, 'main_theme') and hasattr(global_analysis, 'keywords'):
                    domain = global_analysis.main_theme
                    keywords = global_analysis.keywords[:10] if hasattr(global_analysis, 'keywords') else []
                    
                    for item in plan:
                        if hasattr(item, 'asset_path') and item.asset_path:
                            asset_path = item.asset_path
                        elif isinstance(item, dict) and item.get('asset_path'):
                            asset_path = item['asset_path']
                        else:
                            continue
                        
                        # Calculer le score contextuel
                        context_score = _score_contextual_relevance(asset_path, domain, keywords)
                        
                        # Appliquer le score contextuel au score final
                        if hasattr(item, 'score'):
                            # Ajuster le score existant
                            item.score = item.score * context_score
                        elif isinstance(item, dict) and 'score' in item:
                            item['score'] = item['score'] * context_score
                        
                        # Stocker le score contextuel pour debug
                        if hasattr(item, 'context_score'):
                            item.context_score = context_score
                        elif isinstance(item, dict):
                            item['context_score'] = context_score
                    
                    print(f"    ðŸŽ¯ Scoring contextuel appliquÃ©: domaine '{domain}' avec {len(keywords)} mots-clÃ©s")
                    
                    # ðŸ” DEBUG B-ROLL SELECTION (si activÃ©)
                    debug_mode = getattr(Config, 'DEBUG_BROLL', False) or os.getenv('DEBUG_BROLL', 'false').lower() == 'true'
                    _debug_broll_selection(plan, domain, keywords, debug_mode)
                    
                    # ðŸš¨ FALLBACK PROPRE: Si aucun asset pertinent, utiliser des assets neutres
                    # ðŸ”§ CORRECTION CRITIQUE: VÃ©rifier d'abord si les items ont des assets assignÃ©s
                    items_without_assets = []
                    items_with_assets = []
                    
                    for item in plan:
                        if hasattr(item, 'asset_path') and item.asset_path:
                            items_with_assets.append(item)
                        elif isinstance(item, dict) and item.get('asset_path'):
                            items_with_assets.append(item)
                        else:
                            items_without_assets.append(item)
                    
                    print(f"    ðŸ” Analyse des assets: {len(items_with_assets)} avec assets, {len(items_without_assets)} sans assets")
                    
                    # ðŸš¨ CORRECTION: Assigner des assets aux items sans assets AVANT le fallback
                    if items_without_assets and fetched_brolls:
                        print(f"    ðŸŽ¯ Assignation d'assets aux {len(items_without_assets)} items sans assets...")
                        
                        # ðŸš€ NOUVEAU: Utiliser uniquement les B-rolls frais pour Ã©viter la duplication
                        available_assets = []
                        for broll in fetched_brolls:
                            asset_path = broll.get('path', '')
                            if asset_path and Path(asset_path).exists():
                                available_assets.append(asset_path)
                        
                        # ðŸš€ NOUVEAU: MÃ©langer pour Ã©viter l'ordre sÃ©quentiel rÃ©pÃ©titif
                        import random
                        random.shuffle(available_assets)
                        
                        print(f"    âœ… {len(available_assets)} assets frais disponibles (mÃ©langÃ©s pour diversitÃ©)")
                        
                        for i, item in enumerate(items_without_assets):
                            if i < len(available_assets):
                                asset_path = available_assets[i]
                                if hasattr(item, 'asset_path'):
                                    item.asset_path = asset_path
                                elif isinstance(item, dict):
                                    item['asset_path'] = asset_path
                                
                                print(f"    âœ… Asset frais assignÃ© Ã  item {i+1}: {Path(asset_path).name}")
                            else:
                                break
                    else:
                        print(f"    âš ï¸  Plan vide - Aucun item Ã  traiter")
                    
            except Exception as e:
                print(f"    âš ï¸  Erreur scoring contextuel: {e}")
 
                        # Affecter un asset_path pertinent via FAISS/CLIP si manquant
            try:
                from sentence_transformers import SentenceTransformer  # type: ignore
                import numpy as _np  # type: ignore
                import faiss as _faiss  # type: ignore
                from pathlib import Path as _P
                
                # ðŸš¨ NOUVEAU: Importer le systÃ¨me de scoring contextuel intelligent
                try:
                    from src.pipeline.broll_selector import get_contextual_broll_score
                    print("    ðŸ§  SystÃ¨me de scoring contextuel intelligent activÃ©")
                except ImportError:
                    print("    âš ï¸ SystÃ¨me de scoring contextuel non disponible")
                    get_contextual_broll_score = None
                
                # UTILISER LE DOSSIER SPÃ‰CIFIQUE DU CLIP (pas la librairie globale)
                clip_specific_dir = clip_broll_dir if 'clip_specific_dir' in locals() else broll_library
                idx_bin = (clip_specific_dir / 'faiss.index')
                idx_json = (clip_specific_dir / 'faiss.json')
                
                model_name = getattr(cfg, 'embedding_model_name', 'clip-ViT-B/32')
                # ðŸš€ OPTIMISATION: Utiliser le cache pour Ã©viter le rechargement
                final_model_name = 'clip-ViT-B/32' if 'ViT' in model_name else model_name
                st_model = get_sentence_transformer_model(final_model_name)
                
                # ðŸš€ CORRECTION: CrÃ©er emb_text conditionnellement
                emb_text = None
                if st_model is None:
                    print(f"    âš ï¸ Impossible de charger le modÃ¨le {final_model_name}, dÃ©sactivation FAISS")
                else:
                    def emb_text(t: str):
                        v = st_model.encode([t])[0].astype('float32')
                        n = _np.linalg.norm(v) + 1e-12
                        return v / n
                paths = []
                if idx_json.exists():
                    import json as _json
                    try:
                        paths = _json.loads(idx_json.read_text(encoding='utf-8')).get('paths', [])
                    except Exception:
                        paths = []
                index = _faiss.read_index(str(idx_bin)) if idx_bin.exists() else None
                used_recent: set[str] = set()
                for it in plan or []:
                    ap = getattr(it, 'asset_path', None) if hasattr(it, 'asset_path') else (it.get('asset_path') if isinstance(it, dict) else None)
                    if ap:
                        continue
                    # Texte local autour de l'event
                    st_e = float(getattr(it, 'start', 0.0) if hasattr(it, 'start') else (it.get('start') if isinstance(it, dict) else 0.0))
                    en_e = float(getattr(it, 'end', 0.0) if hasattr(it, 'end') else (it.get('end') if isinstance(it, dict) else 0.0))
                    local = " ".join(s.text for s in segments if float(s.start) <= en_e and float(s.end) >= st_e)[:400]
                    q = emb_text(local) if local and emb_text is not None else None
                    
                    # ðŸš¨ NOUVEAU: Extraction des mots-clÃ©s pour le scoring contextuel
                    local_keywords = []
                    if local:
                        # Extraire les mots-clÃ©s du texte local
                        words = local.lower().split()
                        local_keywords = [w for w in words if len(w) > 3 and w.isalpha()][:10]
                    
                    chosen = None
                    best_score = -1
                    
                    if index is not None and q is not None and paths:
                        # ðŸš¨ NOUVEAU: Recherche Ã©tendue pour Ã©valuation contextuelle
                        D,I = index.search(q.reshape(1,-1), 15)  # Augmenter de 5 Ã  15 candidats
                        
                        # ðŸš¨ NOUVEAU: Ã‰valuation contextuelle de tous les candidats
                        for idx in I[0].tolist():
                            if 0 <= idx < len(paths):
                                p = paths[idx]
                                if not p:
                                    continue
                                cand = _P(p)
                                if not cand.is_absolute():
                                    cand = (clip_specific_dir / p).resolve()
                                if str(cand) not in used_recent and cand.exists():
                                    # ðŸš¨ NOUVEAU: Calcul du score contextuel intelligent
                                    contextual_score = 0.0
                                    if 'get_contextual_broll_score' in globals() and local_keywords:
                                        try:
                                            # Extraire les tokens et tags du fichier
                                            asset_name = cand.stem.lower()
                                            asset_tokens = asset_name.split('_')
                                            asset_tags = asset_name.split('_')  # SimplifiÃ© pour l'exemple
                                            contextual_score = get_contextual_broll_score(local_keywords, asset_tokens, asset_tags)
                                        except Exception as e:
                                            print(f"    âš ï¸ Erreur scoring contextuel: {e}")
                                            contextual_score = 0.0
                                    
                                    # ðŸš¨ NOUVEAU: Score combinÃ© FAISS + Contextuel
                                    faiss_score = float(D[0][I[0].tolist().index(idx)]) if idx in I[0] else 0.0
                                    combined_score = faiss_score + (contextual_score * 2.0)  # Poids contextuel DOUBLÃ‰
                                    
                                    if combined_score > best_score:
                                        best_score = combined_score
                                        chosen = str(cand)
                        
                        # ðŸš¨ NOUVEAU: Log de la sÃ©lection contextuelle
                        if chosen and 'get_contextual_broll_score' in globals() and local_keywords:
                            try:
                                asset_name = Path(chosen).stem.lower()
                                asset_tokens = asset_name.split('_')
                                asset_tags = asset_name.split('_')
                                final_contextual_score = get_contextual_broll_score(local_keywords, asset_tokens, asset_tags)
                                print(f"    ðŸŽ¯ SÃ©lection contextuelle: {Path(chosen).stem} | Score: {best_score:.3f} | Contexte: {final_contextual_score:.2f}")
                            except Exception:
                                pass
                    
                    if chosen is None:
                        # ðŸš€ NOUVEAU: Fallback intelligent utilisant UNIQUEMENT les assets frais du dossier fetched/
                        print(f"    ðŸ” Fallback vers assets frais uniquement...")
                        fetched_dir = clip_specific_dir / 'fetched'
                        if fetched_dir.exists():
                            for p in fetched_dir.rglob('*'):
                                if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}:
                                    if str(p.resolve()) not in used_recent and p.exists():
                                        # ðŸš€ NOUVEAU: Ã‰valuation contextuelle prioritaire
                                        if 'get_contextual_broll_score' in globals() and local_keywords:
                                            try:
                                                asset_name = p.stem.lower()
                                                asset_tokens = asset_name.split('_')
                                                asset_tags = asset_name.split('_')
                                                fallback_score = get_contextual_broll_score(local_keywords, asset_tokens, asset_tags)
                                                if fallback_score > 1.0:  # Seuil rÃ©duit pour plus de diversitÃ©
                                                    chosen = str(p.resolve())
                                                    print(f"    âœ… Asset frais contextuel: {p.stem} | Score: {fallback_score:.2f}")
                                                    break
                                            except Exception:
                                                pass
                                        else:
                                            # Utiliser directement l'asset frais sans scoring
                                            chosen = str(p.resolve())
                                            print(f"    âœ… Asset frais utilisÃ©: {p.stem}")
                                            break
                        else:
                            print(f"    âš ï¸ Dossier fetched/ non trouvÃ©: {fetched_dir}")
                    
                    if chosen:
                        if isinstance(it, dict):
                            it['asset_path'] = chosen
                        else:
                            try:
                                setattr(it, 'asset_path', chosen)
                            except Exception:
                                pass
            except Exception:
                pass

            # VÃ©rification des asset_path avant normalisation + mini fallback non invasif
            try:
                def _get_ap(x):
                    return (getattr(x, 'asset_path', None) if hasattr(x, 'asset_path') else (x.get('asset_path') if isinstance(x, dict) else None))
                missing = [it for it in (plan or []) if not _get_ap(it)]
                if plan and len(missing) == len(plan):
                    # ðŸš€ NOUVEAU: Fallback intelligent anti-duplication
                    # UTILISER LE DOSSIER SPÃ‰CIFIQUE DU CLIP (fetched/ en prioritÃ©)
                    clip_specific_dir = clip_broll_dir if 'clip_specific_dir' in locals() else broll_library
                    
                    # ðŸš€ PRIORISER le dossier fetched/ pour des assets frais
                    fetched_dir = clip_specific_dir / 'fetched'
                    if fetched_dir.exists():
                        lib_assets = [p for p in fetched_dir.rglob('*') if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}]
                        print(f"    ðŸŽ¯ Utilisation assets frais du dossier fetched/: {len(lib_assets)} assets")
                    else:
                        lib_assets = [p for p in clip_specific_dir.rglob('*') if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}]
                        print(f"    âš ï¸ Fallback vers dossier complet: {len(lib_assets)} assets")
                    
                    if lib_assets:
                        # ðŸš€ NOUVEAU: MÃ©langer les assets pour Ã©viter l'ordre rÃ©pÃ©titif
                        import random
                        random.shuffle(lib_assets)
                        
                        # ðŸš€ NOUVEAU: RÃ©partition intelligente anti-duplication
                        assigned_assets = set()  # Tracker les assets dÃ©jÃ  utilisÃ©s
                        for i, it in enumerate(plan):
                            ap = _get_ap(it)
                            if ap:
                                continue
                                
                            # Chercher un asset non encore utilisÃ©
                            chosen_asset = None
                            for asset in lib_assets:
                                asset_path = str(asset.resolve())
                                if asset_path not in assigned_assets:
                                    chosen_asset = asset_path
                                    assigned_assets.add(asset_path)
                                    break
                            
                            # Si tous les assets sont utilisÃ©s, reprendre depuis le dÃ©but
                            if chosen_asset is None and lib_assets:
                                chosen_asset = str(lib_assets[i % len(lib_assets)].resolve())
                                print(f"    âš ï¸ Recyclage asset {i+1}: tous les assets frais Ã©puisÃ©s")
                            
                            if chosen_asset:
                                if isinstance(it, dict):
                                    it['asset_path'] = chosen_asset
                                else:
                                    try:
                                        setattr(it, 'asset_path', chosen_asset)
                                    except Exception:
                                        pass
                                print(f"    âœ… Asset intelligent assignÃ© {i+1}: {Path(chosen_asset).name}")
                        
                        print(f"    ðŸ“Š Assignation intelligente: {len(assigned_assets)} assets uniques utilisÃ©s sur {len(lib_assets)} disponibles")
            except Exception:
                pass
 
             # Normaliser la timeline en Ã©vÃ©nements canonique et rendre
            try:
                with _VFC(str(input_path)) as _fpsprobe:
                    fps_probe = float(_fpsprobe.fps or 25.0)
            except Exception:
                fps_probe = 25.0
            events = normalize_timeline(plan, fps=fps_probe)
            events = enrich_keywords(events)
            

            
            # Hard fail if no valid events
            if not events:
                raise RuntimeError('Aucun B-roll valide aprÃ¨s planification/scoring. VÃ©rifier l\'index FAISS et la librairie. Aucun fallback synthÃ©tique appliquÃ©.')
            # Valider que les mÃ©dias existent
            from pathlib import Path as _Path
            valid_events = []
            for ev in events:
                mp = getattr(ev, 'media_path', '')
                pp = _Path(mp)
                if not pp.exists() and mp and not pp.is_absolute():
                    pp = (broll_library / mp).resolve()
                    if pp.exists():
                        try:
                            setattr(ev, 'media_path', str(pp))
                        except Exception:
                            pass
                if getattr(ev, 'media_path', '') and _Path(getattr(ev, 'media_path')).exists():
                    valid_events.append(ev)
            # Log count and sample
            try:
                print(f"    ðŸ”Ž B-roll events valides: {len(valid_events)}")
                for _ev in valid_events[:3]:
                    print(f"       â€¢ {_ev.start_s:.2f}-{_ev.end_s:.2f} â†’ {getattr(_ev, 'media_path','')}")
            except Exception:
                pass
            if not valid_events:
                # Fallback legacy: construire un plan simple Ã  partir de la librairie existante
                try:
                    _media_exts = {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}
                    assets = [p for p in Path(broll_library).rglob('*') if p.suffix.lower() in _media_exts]
                    assets.sort(key=lambda p: p.stat().st_size if p.exists() else 0, reverse=True)
                    assets = assets[:20]
                    if assets:
                        # Choisir des segments suffisamment longs (>2.0s) et espacÃ©s
                        cands = []
                        for s in segments:
                            dur = float(getattr(s, 'end', 0.0) - getattr(s, 'start', 0.0))
                            if dur >= 2.0 and getattr(s, 'start', 0.0) >= 1.5:  # Plus flexible
                                cands.append(s)
                        plan_simple = []
                        gap = 6.0  # RÃ©duit: 8s â†’ 6s pour plus d'insertions
                        last = -1e9
                        ai = 0
                        for s in cands:
                            st = float(getattr(s,'start',0.0))
                            en = float(getattr(s,'end',0.0))
                            if st - last < gap:
                                continue
                            dur = min(7.0, max(2.5, en - st))  # DurÃ©e min: 2.5s, max: 7s
                            asset = assets[ai % len(assets)]
                            ai += 1
                            plan_simple.append({
                                'start': st,
                                'end': min(en, st + dur),
                                'asset_path': str(asset.resolve()),
                                'crossfade_frames': 2,
                            })
                            last = st
                        # Normaliser et rendre si on a des items
                        if plan_simple:
                            try:
                                with _VFC(str(input_path)) as _fpsprobe:
                                    fps_probe = float(_fpsprobe.fps or 25.0)
                            except Exception:
                                fps_probe = 25.0
                            legacy_events = normalize_timeline(plan_simple, fps=fps_probe)
                            legacy_events = enrich_keywords(legacy_events)
                            print(f"    â™»ï¸ Fallback legacy appliquÃ©: {len(legacy_events)} events")
                            valid_events = legacy_events
                            # Continue vers le rendu unique plus bas
                        else:
                            raise RuntimeError('Librairie B-roll prÃ©sente mais aucun slot valide pour fallback legacy')
                    else:
                        raise RuntimeError('B-rolls planifiÃ©s, aucun media_path valide et aucune ressource en librairie pour fallback')
                except Exception as _e:
                    raise RuntimeError('B-rolls planifiÃ©s, mais aucun media_path valide trouvÃ©. Fallback legacy impossible: ' + str(_e))
            # Rendu unique avec les events valides (incl. fallback le cas Ã©chÃ©ant)
            render_video(cfg, segments, valid_events)
            
            # VÃ‰RIFICATION ET NETTOYAGE INTELLIGENT DES B-ROLLS
            try:
                if getattr(Config, 'BROLL_DELETE_AFTER_USE', False):
                    print("    ðŸ” VÃ©rification des B-rolls avant suppression...")
                    
                    # Importer le systÃ¨me de vÃ©rification
                    try:
                        from broll_verification_system import create_verification_system
                        verifier = create_verification_system()
                        
                        # VÃ©rifier l'insertion des B-rolls
                        verification_result = verifier.verify_broll_insertion(
                            video_path=cfg.output_video,
                            broll_plan=plan or [],
                            broll_library_path=str(clip_broll_dir) if 'clip_broll_dir' in locals() else "AI-B-roll/broll_library"
                        )
                        
                        # ðŸš€ CORRECTION: VÃ©rifier le type du rÃ©sultat de vÃ©rification
                        if not isinstance(verification_result, dict):
                            print(f"    âš ï¸ RÃ©sultat de vÃ©rification invalide (type: {type(verification_result)}) - Fallback vers vÃ©rification basique")
                            verification_result = {
                                "verification_passed": True,  # Par dÃ©faut, autoriser la suppression
                                "issues": [],
                                "recommendations": []
                            }
                        
                        # DÃ©cider si la suppression est autorisÃ©e
                        if verification_result.get("verification_passed", False):
                            print("    âœ… VÃ©rification rÃ©ussie - Suppression autorisÃ©e")
                            
                            # Supprimer seulement les fichiers B-roll utilisÃ©s (pas le dossier)
                            used_files: List[str] = []
                            for item in (plan or []):
                                path = getattr(item, 'asset_path', None) if hasattr(item, 'asset_path') else (item.get('asset_path') if isinstance(item, dict) else None)
                                if path and os.path.exists(path):
                                    used_files.append(path)
                            
                            # Nettoyer les fichiers utilisÃ©s
                            cleaned_count = 0
                            for p in used_files:
                                try:
                                    os.remove(p)
                                    cleaned_count += 1
                                except Exception:
                                    pass
                            
                            # Marquer le dossier comme "utilisÃ©" mais le garder
                            if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                                try:
                                    # CrÃ©er un fichier de statut pour indiquer que le clip est traitÃ©
                                    status_file = clip_broll_dir / "STATUS_COMPLETED.txt"
                                    status_file.write_text(f"Clip traitÃ© le {time.strftime('%Y-%m-%d %H:%M:%S')}\nB-rolls utilisÃ©s: {cleaned_count}\nVÃ©rification: PASSED\n", encoding='utf-8')
                                    print(f"    ðŸ—‚ï¸ Dossier B-roll conservÃ©: {clip_broll_dir.name} (fichiers nettoyÃ©s: {cleaned_count})")
                                except Exception as e:
                                    print(f"    âš ï¸ Erreur crÃ©ation statut: {e}")
                        else:
                            print("    âŒ VÃ©rification Ã©chouÃ©e - Suppression REFUSÃ‰E")
                            print("    ðŸ“‹ ProblÃ¨mes dÃ©tectÃ©s:")
                            for issue in verification_result.get("issues", []):
                                print(f"       â€¢ {issue}")
                            print("    ðŸ’¡ Recommandations:")
                            for rec in verification_result.get("recommendations", []):
                                print(f"       â€¢ {rec}")
                            
                            # CrÃ©er un fichier de statut d'Ã©chec
                            if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                                try:
                                    status_file = clip_broll_dir / "STATUS_FAILED.txt"
                                    status_file.write_text(f"Clip traitÃ© le {time.strftime('%Y-%m-%d %H:%M:%S')}\nVÃ©rification: FAILED\nProblÃ¨mes: {', '.join(verification_result.get('issues', []))}\n", encoding='utf-8')
                                    print(f"    ðŸš¨ Dossier B-roll marquÃ© comme Ã©chec: {clip_broll_dir.name}")
                                except Exception as e:
                                    print(f"    âš ï¸ Erreur crÃ©ation statut d'Ã©chec: {e}")
                    
                    except ImportError:
                        print("    âš ï¸ SystÃ¨me de vÃ©rification non disponible - Suppression sans vÃ©rification")
                        # Fallback vers l'ancien systÃ¨me
                        used_files: List[str] = []
                        for item in (plan or []):
                            path = getattr(item, 'asset_path', None) if hasattr(item, 'asset_path') else (item.get('asset_path') if isinstance(item, dict) else None)
                            if path and os.path.exists(path):
                                used_files.append(path)
                        
                        cleaned_count = 0
                        for p in used_files:
                            try:
                                os.remove(p)
                                cleaned_count += 1
                            except Exception:
                                pass
                        
                        if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                            try:
                                status_file = clip_broll_dir / "STATUS_COMPLETED_NO_VERIFICATION.txt"
                                status_file.write_text(f"Clip traitÃ© le {time.strftime('%Y-%m-%d %H:%M:%S')}\nB-rolls utilisÃ©s: {cleaned_count}\nVÃ©rification: NON DISPONIBLE\n", encoding='utf-8')
                                print(f"    ðŸ—‚ï¸ Dossier B-roll conservÃ©: {clip_broll_dir.name} (fichiers nettoyÃ©s: {cleaned_count})")
                            except Exception as e:
                                print(f"    âš ï¸ Erreur crÃ©ation statut: {e}")
                    
            except Exception as e:
                print(f"    âš ï¸ Erreur lors de la vÃ©rification/nettoyage: {e}")
                # En cas d'erreur, ne pas supprimer les B-rolls
                pass

            if Path(cfg.output_video).exists():
                print("    âœ… B-roll insÃ©rÃ©s avec succÃ¨s")
            
                # ðŸ§¹ NOUVEAU: Nettoyage immÃ©diat du cache B-roll temporaire
                try:
                    if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                        folder_size = sum(f.stat().st_size for f in clip_broll_dir.rglob('*') if f.is_file()) / (1024**2)  # MB
                        # ðŸš€ OPTIMISATION: Utiliser safe_remove_tree
                        if safe_remove_tree(clip_broll_dir):
                            print(f"    ðŸ—‘ï¸ Cache B-roll nettoyÃ©: {folder_size:.1f} MB libÃ©rÃ©s")
                            print(f"    ðŸ’¾ Dossier temporaire supprimÃ©: {clip_broll_dir.name}")
                        else:
                            print(f"    âš ï¸ Nettoyage partiel du cache B-roll")
                except Exception as e:
                    print(f"    âš ï¸ Erreur nettoyage cache: {e}")
            
                return Path(cfg.output_video)
            else:
                print("    âš ï¸ Sortie B-roll introuvable, retour Ã  la vidÃ©o d'origine")
            
            # ðŸ§¹ Nettoyer mÃªme en cas d'Ã©chec
            try:
                if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                    # ðŸš€ OPTIMISATION: Utiliser safe_remove_tree
                    if safe_remove_tree(clip_broll_dir):
                        print(f"    ðŸ—‘ï¸ Cache B-roll nettoyÃ© (Ã©chec traitement)")
            except Exception:
                pass
            
            return input_path
        except Exception as e:
            print(f"    âŒ Erreur B-roll: {e}")
            
            # ðŸ§¹ IMPORTANT: Nettoyer mÃªme en cas d'erreur pour Ã©viter l'accumulation
            try:
                if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                    # ðŸš€ OPTIMISATION: Utiliser safe_remove_tree
                    if safe_remove_tree(clip_broll_dir):
                        print(f"    ðŸ—‘ï¸ Cache B-roll nettoyÃ© aprÃ¨s erreur")
            except Exception:
                pass
            
            return input_path

    # Si densitÃ© trop faible aprÃ¨s planification, injecter quelques B-rolls gÃ©nÃ©riques
    try:
        with _VFC(str(input_path)) as _tmp:
            _total = float(_tmp.duration or 0.0)
        cur_cov = sum(max(0.0, (float(getattr(it,'end', it.get('end',0.0))) - float(getattr(it,'start', it.get('start',0.0))))) for it in (plan or []))
        if _total > 0 and (cur_cov / _total) < 0.20:  # AugmentÃ©: 15% â†’ 20% pour plus de B-rolls
            _generics = []
            bank = [
                "money", "handshake", "meeting", "audience", "lightbulb", "typing", "city", "success"
            ]
            # Chercher quelques mÃ©dias gÃ©nÃ©riques existants
            for p in broll_library.rglob('*'):
                if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}:
                    name = p.stem.lower()
                    if any(k in name for k in bank):
                        _generics.append(str(p.resolve()))
            if _generics:
                # Injecter 2â€“4 gÃ©nÃ©riques espacÃ©s
                inject_count = min(4, max(2, int(len(_generics)/5)))
                st = 2.0
                while inject_count > 0 and st < (_total - 3.5):
                    plan.append({'start': st, 'end': min(_total, st+3.5), 'asset_path': _generics[inject_count % len(_generics)], 'crossfade_frames': 2})
                    st += 10.0
                    inject_count -= 1
                print("    âž• B-rolls gÃ©nÃ©riques injectÃ©s pour densitÃ© minimale")
    except Exception:
        pass

class PremiereProAutomation:
    """
    Classe pour l'automatisation Premiere Pro (optionnelle)
    Utilise ExtendScript pour les utilisateurs avancÃ©s
    """
    
    @staticmethod
    def create_jsx_script(clip_path: str, output_path: str) -> str:
        """GÃ©nÃ¨re un script ExtendScript pour Premiere Pro"""
        jsx_script = f'''
        // Script ExtendScript pour Premiere Pro
        var project = app.project;
        
        // Import du clip
        var importOptions = new ImportOptions();
        importOptions.file = new File("{clip_path}");
        var clip = project.importFiles([importOptions.file]);
        
        // CrÃ©ation d'une sÃ©quence 9:16
        var sequence = project.createNewSequence("Vertical_Clip", "HDV-1080i25");
        sequence.videoTracks[0].insertClip(clip[0], 0);
        
        // Application de l'effet Auto Reframe (si disponible)
        // Note: Ceci nÃ©cessite Premiere Pro 2019 ou plus rÃ©cent
        
        // Export
        var encoder = app.encoder;
        encoder.encodeSequence(sequence, "{output_path}", "H.264", false);
        '''
        return jsx_script
    
    @staticmethod 
    def run_premiere_script(jsx_script_content: str):
        """ExÃ©cute un script ExtendScript dans Premiere Pro"""
        try:
            # Sauvegarde du script temporaire
            script_path = Config.TEMP_FOLDER / "premiere_script.jsx"
            with open(script_path, 'w') as f:
                f.write(jsx_script_content)
            
            import platform
            system = platform.system()
            
            if system == 'Darwin':  # macOS
                subprocess.run([
                    'osascript', '-e',
                    f'tell application "Adobe Premiere Pro" to do script "{script_path}"'
                ], check=True)
            elif system == 'Windows':
                print("âš ï¸ ExÃ©cution ExtendScript automatisÃ©e non supportÃ©e nativement sous Windows dans ce pipeline.")
                print("   Ouvrez Premiere Pro et exÃ©cutez le script manuellement: " + str(script_path))
            else:
                print("âš ï¸ Plateforme non supportÃ©e pour l'exÃ©cution automatique de Premiere Pro.")
            
            logger.info("âœ… Script Premiere Pro traitÃ© (voir message ci-dessus)")
            
        except Exception as e:
            logger.error(f"âŒ Erreur Premiere Pro: {e}")
            raise

# Helper: filter noisy prompt terms
STOP_PROMPT_TERMS = {
    'very','really','clear','stuff','thing','things','some','any','ever','so','much','get','got',
    'will','discuss','this','that','these','those','it','its','im','ive','youve','because'
}

def _filter_prompt_terms(words):
    cleaned = []
    for w in words:
        if not isinstance(w, str):
            continue
        t = w.strip().lower()
        if not t or t in STOP_PROMPT_TERMS or len(t) < 3:
            continue
        cleaned.append(t)
    # de-duplicate preserving order
    seen = set()
    result = []
    for t in cleaned:
        if t not in seen:
            result.append(t)
            seen.add(t)
    return result[:5]

def _prioritize_fresh_assets(broll_candidates, clip_id):
    """Priorise les assets les plus rÃ©cents basÃ©s sur le timestamp du dossier."""
    if not broll_candidates:
        return broll_candidates
    
    try:
        # Extraire le timestamp du dossier pour chaque candidat
        for candidate in broll_candidates:
            if hasattr(candidate, 'file_path') and candidate.file_path:
                path = Path(candidate.file_path)
                # Chercher le pattern clip_*_timestamp dans le chemin
                for part in path.parts:
                    if part.startswith(f"clip_{clip_id}_") and "_" in part:
                        timestamp_str = part.split("_")[-1]
                        if timestamp_str.isdigit():
                            candidate.folder_timestamp = int(timestamp_str)
                            break
                else:
                    candidate.folder_timestamp = 0
            else:
                candidate.folder_timestamp = 0
        
        # Trier par timestamp dÃ©croissant (plus rÃ©cent en premier)
        broll_candidates.sort(key=lambda x: getattr(x, 'folder_timestamp', 0), reverse=True)
        
    except Exception as e:
        print(f"    âš ï¸  Erreur priorisation fraÃ®cheur: {e}")
    
    return broll_candidates

def _score_contextual_relevance(asset_path, domain, keywords):
    """Score de pertinence contextuelle basÃ© sur les tokens et le domaine."""
    try:
        if not asset_path or not domain or not keywords:
            return 0.5
        
        # Extraire les tokens du nom de fichier
        filename = Path(asset_path).stem.lower()
        asset_tokens = set(re.split(r'[^a-z0-9]+', filename))
        
        # Tokens du domaine et mots-clÃ©s
        domain_tokens = set(domain.lower().split())
        keyword_tokens = set()
        for kw in keywords:
            if isinstance(kw, str):
                keyword_tokens.update(kw.lower().split())
        
        # Calculer l'overlap
        relevant_tokens = domain_tokens | keyword_tokens
        if not relevant_tokens:
            return 0.5
        
        overlap = len(asset_tokens & relevant_tokens)
        total_relevant = len(relevant_tokens)
        
        # Score basÃ© sur l'overlap (0.0 Ã  1.0)
        base_score = min(1.0, overlap / max(1, total_relevant * 0.3))
        
        # Bonus pour les tokens de domaine
        domain_overlap = len(asset_tokens & domain_tokens)
        domain_bonus = min(0.3, domain_overlap * 0.1)
        
        final_score = min(1.0, base_score + domain_bonus)
        return final_score
        
    except Exception as e:
        print(f"    âš ï¸  Erreur scoring contextuel: {e}")
        return 0.5

def _get_fallback_neutral_assets(broll_library, count=3):
    """RÃ©cupÃ¨re des assets neutres/gÃ©nÃ©riques comme fallback."""
    try:
        fallback_keywords = ['neutral', 'generic', 'background', 'abstract', 'minimal']
        fallback_assets = []
        
        for keyword in fallback_keywords:
            # Chercher dans la librairie des assets avec ces mots-clÃ©s
            for ext in ['.mp4', '.mov', '.jpg', '.png']:
                for asset_path in broll_library.rglob(f"*{keyword}*{ext}"):
                    if asset_path.exists() and asset_path not in fallback_assets:
                        fallback_assets.append(str(asset_path))
                        if len(fallback_assets) >= count:
                            break
                if len(fallback_assets) >= count:
                    break
            if len(fallback_assets) >= count:
                break
        
        # Si pas assez d'assets spÃ©cifiques, prendre des assets gÃ©nÃ©riques
        if len(fallback_assets) < count:
            for ext in ['.mp4', '.mov', '.jpg', '.png']:
                for asset_path in broll_library.rglob(f"*{ext}"):
                    if asset_path.exists() and asset_path not in fallback_assets:
                        fallback_assets.append(str(asset_path))
                        if len(fallback_assets) >= count:
                            break
                if len(fallback_assets) >= count:
                    break
        
        return fallback_assets[:count]
        
    except Exception as e:
        print(f"    âš ï¸  Erreur fallback neutre: {e}")
        return []

def _debug_broll_selection(plan, domain, keywords, debug_mode=False):
    """Log dÃ©taillÃ© de la sÃ©lection B-roll si debug activÃ©."""
    if not debug_mode:
        return
    
    print(f"    ðŸ” DEBUG B-ROLL SELECTION:")
    print(f"       Domaine: {domain}")
    print(f"       Mots-clÃ©s: {keywords[:5]}")
    print(f"       Plan: {len(plan)} items")
    
    for i, item in enumerate(plan[:3]):  # Afficher les 3 premiers
        if hasattr(item, 'asset_path') and item.asset_path:
            asset_path = item.asset_path
            score = getattr(item, 'score', 'N/A')
            context_score = getattr(item, 'context_score', 'N/A')
            freshness = getattr(item, 'freshness_score', 'N/A')
        elif isinstance(item, dict):
            asset_path = item.get('asset_path', 'N/A')
            score = item.get('score', 'N/A')
            context_score = item.get('context_score', 'N/A')
            freshness = item.get('freshness_score', 'N/A')
        else:
            continue
        
        print(f"       Item {i+1}: {Path(asset_path).name}")
        print(f"         Score: {score}, Context: {context_score}, FraÃ®cheur: {freshness}")

# ðŸš€ NOUVEAU: Fonction de scoring mixte intelligent pour B-rolls
def score_broll_asset_mixed(asset_path: str, asset_tags: List[str], query_keywords: List[str], 
                           domain: Optional[str] = None, asset_metadata: Optional[Dict] = None) -> float:
    """
    Score un asset B-roll avec le systÃ¨me mixte intelligent.
    
    Args:
        asset_path: Chemin vers l'asset
        asset_tags: Tags de l'asset
        query_keywords: Mots-clÃ©s de la requÃªte
        domain: Domaine dÃ©tectÃ© (optionnel)
        asset_metadata: MÃ©tadonnÃ©es supplÃ©mentaires (optionnel)
    
    Returns:
        Score final entre 0.0 et 1.0
    """
    try:
        if not BROLL_SELECTOR_AVAILABLE:
            # Fallback vers scoring basique
            return _score_broll_asset_basic(asset_path, asset_tags, query_keywords)
        
        # Utiliser le nouveau sÃ©lecteur si disponible
        from broll_selector import Asset, ScoringFeatures
        
        # CrÃ©er un asset simulÃ© pour le scoring
        asset = Asset(
            id=f"asset_{hash(asset_path)}",
            file_path=asset_path,
            tags=asset_tags,
            title=Path(asset_path).stem,
            description="",
            source="local",
            fetched_at=datetime.now(),
            duration=asset_metadata.get('duration', 2.0) if asset_metadata else 2.0,
            resolution=asset_metadata.get('resolution', '1920x1080') if asset_metadata else '1920x1080'
        )
        
        # Normaliser les mots-clÃ©s de la requÃªte
        normalized_keywords = set()
        for kw in query_keywords:
            if kw and isinstance(kw, str):
                clean = kw.lower().strip()
                if len(clean) > 2:
                    normalized_keywords.add(clean)
        
        # Calculer les features de scoring
        features = ScoringFeatures()
        
        # 1. Token overlap (Jaccard)
        if asset_tags and normalized_keywords:
            intersection = len(set(asset_tags) & normalized_keywords)
            union = len(set(asset_tags) | normalized_keywords)
            features.token_overlap = intersection / union if union > 0 else 0.0
        
        # 2. Domain match
        if domain and asset_tags:
            domain_keywords = _get_domain_keywords(domain)
            domain_overlap = len(set(asset_tags) & set(domain_keywords))
            features.domain_match = min(1.0, domain_overlap / max(len(domain_keywords), 1))
        
        # 3. Freshness (basÃ© sur la date de crÃ©ation du fichier)
        try:
            file_path = Path(asset_path)
            if file_path.exists():
                mtime = file_path.stat().st_mtime
                days_old = (time.time() - mtime) / (24 * 3600)
                features.freshness = 1.0 / (1.0 + days_old / 60)  # Demi-vie de 60 jours
        except:
            features.freshness = 0.5  # Valeur par dÃ©faut
        
        # 4. Quality score (basÃ© sur la rÃ©solution et l'extension)
        features.quality_score = _calculate_quality_score(asset_path, asset_metadata)
        
        # 5. Embedding similarity (placeholder - Ã  implÃ©menter avec FAISS)
        features.embedding_similarity = 0.5  # Valeur par dÃ©faut
        
        # Calculer le score final pondÃ©rÃ©
        weights = {
            'embedding': 0.4,
            'token': 0.2,
            'domain': 0.15,
            'freshness': 0.1,
            'quality': 0.1,
            'diversity': 0.05
        }
        
        final_score = (
            weights['embedding'] * features.embedding_similarity +
            weights['token'] * features.token_overlap +
            weights['domain'] * features.domain_match +
            weights['freshness'] * features.freshness +
            weights['quality'] * features.quality_score
        )
        
        return max(0.0, min(1.0, final_score))
        
    except Exception as e:
        print(f"âš ï¸ Erreur scoring mixte: {e}")
        # Fallback vers scoring basique
        return _score_broll_asset_basic(asset_path, asset_tags, query_keywords)

def _score_broll_asset_basic(asset_path: str, asset_tags: List[str], query_keywords: List[str]) -> float:
    """Scoring basique de fallback"""
    try:
        # Score simple basÃ© sur l'overlap de tags
        if not asset_tags or not query_keywords:
            return 0.5
        
        asset_tag_set = set(tag.lower() for tag in asset_tags)
        query_set = set(kw.lower() for kw in query_keywords if kw)
        
        if not query_set:
            return 0.5
        
        intersection = len(asset_tag_set & query_set)
        union = len(asset_tag_set | query_set)
        
        return intersection / union if union > 0 else 0.0
        
    except Exception as e:
        print(f"âš ï¸ Erreur scoring basique: {e}")
        return 0.5

def _get_domain_keywords(domain: str) -> List[str]:
    """Retourne les mots-clÃ©s spÃ©cifiques au domaine"""
    domain_keywords = {
        'health': ['medical', 'healthcare', 'wellness', 'fitness', 'medicine', 'hospital', 'doctor'],
        'technology': ['tech', 'digital', 'innovation', 'computer', 'ai', 'software', 'data'],
        'business': ['business', 'entrepreneur', 'success', 'growth', 'strategy', 'office', 'professional'],
        'education': ['learning', 'education', 'knowledge', 'study', 'teaching', 'school', 'university'],
        'finance': ['money', 'finance', 'investment', 'wealth', 'business', 'success', 'growth']
    }
    
    return domain_keywords.get(domain.lower(), [domain])

def _calculate_quality_score(asset_path: str, metadata: Optional[Dict] = None) -> float:
    """Calcule un score de qualitÃ© basÃ© sur les mÃ©tadonnÃ©es"""
    try:
        score = 0.5  # Score de base
        
        # Bonus pour la rÃ©solution
        if metadata and 'resolution' in metadata:
            res = metadata['resolution']
            if '4k' in res or '3840' in res:
                score += 0.2
            elif '1080' in res or '1920' in res:
                score += 0.1
        
        # Bonus pour la durÃ©e
        if metadata and 'duration' in metadata:
            duration = metadata['duration']
            if 2.0 <= duration <= 6.0:  # DurÃ©e optimale
                score += 0.1
        
        # Bonus pour l'extension (prÃ©fÃ©rer MP4)
        if asset_path.lower().endswith('.mp4'):
            score += 0.1
        
        return min(1.0, score)
        
    except Exception:
        return 0.5

    def _load_broll_selector_config(self):
        """Charge la configuration du sÃ©lecteur B-roll depuis le fichier YAML"""
        try:
            import yaml
            if Config.BROLL_SELECTOR_CONFIG_PATH.exists():
                with open(Config.BROLL_SELECTOR_CONFIG_PATH, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
            else:
                print(f"    âš ï¸ Fichier de configuration introuvable: {Config.BROLL_SELECTOR_CONFIG_PATH}")
                return {}
        except Exception as e:
            print(f"    âš ï¸ Erreur chargement configuration: {e}")
            return {}

    def _calculate_asset_hash(self, asset_path: Path) -> str:
        """Calcule un hash unique pour un asset B-roll basÃ© sur son contenu et mÃ©tadonnÃ©es"""
        try:
            import hashlib
            import os
            from datetime import datetime
            
            # Hash basÃ© sur le nom, la taille et la date de modification
            stat = asset_path.stat()
            hash_data = f"{asset_path.name}_{stat.st_size}_{stat.st_mtime}"
            return hashlib.md5(hash_data.encode()).hexdigest()
        except Exception:
            # Fallback sur le nom du fichier
            return str(asset_path.name)
