import sys
sys.stdout.reconfigure(encoding='utf-8')

import os
import json
import subprocess
import logging
import random
import numpy as np
import shutil
import time  # NEW: pour timestamps uniques
from datetime import datetime  # NEW: pour mÃ©tadonnÃ©es intelligentes
from pathlib import Path
from typing import List, Dict, Optional
import whisper
import requests
import cv2
# Gestion optionnelle de Mediapipe avec fallback
try:
    import mediapipe as mp
    MEDIAPIPE_AVAILABLE = True
    print("âœ… Mediapipe disponible - Utilisation des fonctionnalitÃ©s IA avancÃ©es")
except ImportError:
    MEDIAPIPE_AVAILABLE = False
    mp = None
    print("âš ï¸ Mediapipe non disponible - Utilisation du fallback OpenCV (fonctionnalitÃ©s rÃ©duites)")

# ğŸš€ NOUVEAU: Import du sÃ©lecteur B-roll gÃ©nÃ©rique
try:
    from broll_selector import BrollSelector, Asset, ScoringFeatures, BrollCandidate
    BROLL_SELECTOR_AVAILABLE = True
    print("âœ… SÃ©lecteur B-roll gÃ©nÃ©rique disponible - Scoring mixte activÃ©")
except ImportError as e:
    BROLL_SELECTOR_AVAILABLE = False
    print(f"âš ï¸ SÃ©lecteur B-roll gÃ©nÃ©rique non disponible: {e}")
    print("   ğŸ”„ Utilisation du systÃ¨me de scoring existant")

from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from tqdm import tqdm  # NEW: console progress
import re # NEW: for caption/hashtag generation
from hormozi_subtitles import add_hormozi_subtitles


def _format_srt_timestamp(total_seconds: float) -> str:
    """Format seconds to SRT timestamp HH:MM:SS,mmm"""
    if total_seconds < 0:
        total_seconds = 0.0
    hours = int(total_seconds // 3600)
    minutes = int((total_seconds % 3600) // 60)
    seconds = int(total_seconds % 60)
    milliseconds = int(round((total_seconds - int(total_seconds)) * 1000))
    return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"


def write_srt(segments: List[Dict], srt_path: Path) -> None:
    """Write segments [{'start','end','text'}] to SRT file."""
    srt_path = Path(srt_path)
    srt_path.parent.mkdir(parents=True, exist_ok=True)
    lines: List[str] = []
    index = 1
    for seg in segments:
        text = (seg.get('text') or '').strip()
        if not text:
            continue
        start = float(seg.get('start') or 0.0)
        end = float(seg.get('end') or max(0.0, start + 0.01))
        start_ts = _format_srt_timestamp(start)
        end_ts = _format_srt_timestamp(end)
        lines.append(str(index))
        lines.append(f"{start_ts} --> {end_ts}")
        lines.append(text)
        lines.append("")
        index += 1
    with open(srt_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))

def write_vtt(segments: List[Dict], vtt_path: Path) -> None:
    """Write segments to WebVTT file."""
    vtt_path = Path(vtt_path)
    vtt_path.parent.mkdir(parents=True, exist_ok=True)
    def to_vtt_ts(total_seconds: float) -> str:
        if total_seconds < 0:
            total_seconds = 0.0
        hours = int(total_seconds // 3600)
        minutes = int((total_seconds % 3600) // 60)
        seconds = int(total_seconds % 60)
        milliseconds = int(round((total_seconds - int(total_seconds)) * 1000))
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}"
    lines: List[str] = ["WEBVTT",""]
    for seg in segments:
        text = (seg.get('text') or '').strip()
        if not text:
            continue
        start = float(seg.get('start') or 0.0)
        end = float(seg.get('end') or max(0.0, start + 0.01))
        lines.append(f"{to_vtt_ts(start)} --> {to_vtt_ts(end)}")
        lines.append(text)
        lines.append("")
    with open(vtt_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))


def _read_ui_settings() -> Dict:
    """Read optional UI settings from config/ui_settings.json."""
    try:
        cfg_path = Path('config/ui_settings.json')
        if cfg_path.exists():
            with open(cfg_path, 'r', encoding='utf-8') as f:
                return json.load(f) or {}
    except Exception:
        pass
    return {}


def _to_bool(v, default=False) -> bool:
    if v is None:
        return bool(default)
    if isinstance(v, bool):
        return v
    s = str(v).strip().lower()
    return s in {"1","true","yes","on"}


# Load optional UI overrides once
_UI_SETTINGS = _read_ui_settings()

# Configuration automatique d'ImageMagick pour MoviePy
def configure_imagemagick():
    """Configure automatiquement ImageMagick pour MoviePy"""
    try:
        import moviepy.config as cfg
        
        # Chemins possibles pour ImageMagick sur Windows
        possible_paths = [
            r"C:\Program Files\ImageMagick-7.1.2-Q16-HDRI\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.2-Q16\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.1-Q16\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.0-Q16-HDRI\magick.exe",
            r"C:\Program Files\ImageMagick-7.1.0-Q16\magick.exe",
        ]
        
        # Chercher ImageMagick
        for path in possible_paths:
            if os.path.exists(path):
                cfg.change_settings({"IMAGEMAGICK_BINARY": path})
                print(f"âœ… ImageMagick configurÃ©: {path}")
                return True
        
        print("âš ï¸ ImageMagick non trouvÃ©, utilisation du mode fallback")
        return False
        
    except Exception as e:
        print(f"âš ï¸ Erreur configuration ImageMagick: {e}")
        return False

# Configuration automatique au dÃ©marrage
configure_imagemagick()

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Config:
    """Configuration centralisÃ©e du pipeline"""
    CLIPS_FOLDER = Path("./clips")
    OUTPUT_FOLDER = Path("./output") 
    TEMP_FOLDER = Path("./temp")
    
    # RÃ©solution cible pour les rÃ©seaux sociaux
    TARGET_WIDTH = 720
    TARGET_HEIGHT = 1280  # Format 9:16
    
    # ParamÃ¨tres Whisper
    WHISPER_MODEL = "tiny"  # ou "small", "medium", "large"
    
    # ParamÃ¨tres sous-titres
    SUBTITLE_FONT_SIZE = 60
    SUBTITLE_COLOR = 'yellow'
    SUBTITLE_STROKE_COLOR = 'black'
    SUBTITLE_STROKE_WIDTH = 3
    # Biais global (en secondes) pour corriger un lÃ©ger dÃ©calage systÃ©matique
    # 0.0 par dÃ©faut pour Ã©viter tout dÃ©calage si non nÃ©cessaire
    SUBTITLE_TIMING_BIAS_S = 0.0

    # Activation B-roll: UI > ENV > dÃ©faut(off)
    # Si fetchers cochÃ©s, activer automatiquement l'insertion B-roll, sauf si explicitement dÃ©sactivÃ© cÃ´tÃ© UI
    _UI_ENABLE_BROLL = _UI_SETTINGS.get('enable_broll') if 'enable_broll' in _UI_SETTINGS else None
    _ENV_ENABLE_BROLL = os.getenv('ENABLE_BROLL') or os.getenv('AI_BROLL_ENABLED')
    _AUTO_ENABLE = _to_bool(_UI_SETTINGS.get('broll_fetch_enable'), default=True) if 'broll_fetch_enable' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ENABLE') or os.getenv('AI_BROLL_ENABLE_FETCHER'), default=True)
    ENABLE_BROLL = (
        _to_bool(_UI_ENABLE_BROLL, default=False) if _UI_ENABLE_BROLL is not None
        else (_to_bool(_ENV_ENABLE_BROLL, default=False) or _AUTO_ENABLE)
    )

    # === Options fetcher B-roll (stock) ===
    # Active le fetch automatique: UI > ENV > dÃ©faut(on)
    BROLL_FETCH_ENABLE = _to_bool(_UI_SETTINGS.get('broll_fetch_enable'), default=True) if 'broll_fetch_enable' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ENABLE') or os.getenv('AI_BROLL_ENABLE_FETCHER'), default=True)
    # Fournisseur: UI > ENV > dÃ©faut pexels
    BROLL_FETCH_PROVIDER = (_UI_SETTINGS.get('broll_fetch_provider') or os.getenv('AI_BROLL_FETCH_PROVIDER') or 'pexels')
    # ClÃ©s API
    PEXELS_API_KEY = _UI_SETTINGS.get('PEXELS_API_KEY') or os.getenv('PEXELS_API_KEY')
    PIXABAY_API_KEY = _UI_SETTINGS.get('PIXABAY_API_KEY') or os.getenv('PIXABAY_API_KEY')
    # ContrÃ´les de fetch
    BROLL_FETCH_MAX_PER_KEYWORD = int(_UI_SETTINGS.get('broll_fetch_max_per_keyword') or os.getenv('BROLL_FETCH_MAX_PER_KEYWORD') or 25)  # CORRIGÃ‰: 12 â†’ 25
    BROLL_FETCH_ALLOW_VIDEOS = _to_bool(_UI_SETTINGS.get('broll_fetch_allow_videos'), default=True) if 'broll_fetch_allow_videos' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ALLOW_VIDEOS'), default=True)
    BROLL_FETCH_ALLOW_IMAGES = _to_bool(_UI_SETTINGS.get('broll_fetch_allow_images'), default=False) if 'broll_fetch_allow_images' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_FETCH_ALLOW_IMAGES'), default=False)
    # Ã‰largir le pool par dÃ©faut: activer les images si non prÃ©cisÃ©
    if 'broll_fetch_allow_images' not in _UI_SETTINGS and os.getenv('BROLL_FETCH_ALLOW_IMAGES') is None:
        BROLL_FETCH_ALLOW_IMAGES = True
    # Embeddings pour matching sÃ©mantique
    BROLL_USE_EMBEDDINGS = _to_bool(_UI_SETTINGS.get('broll_use_embeddings'), default=True) if 'broll_use_embeddings' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_USE_EMBEDDINGS'), default=True)
    BROLL_EMBEDDING_MODEL = (_UI_SETTINGS.get('broll_embedding_model') or os.getenv('BROLL_EMBEDDING_MODEL') or 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
    # Config contextuelle
    CONTEXTUAL_CONFIG_PATH = Path(_UI_SETTINGS.get('contextual_broll_yml') or os.getenv('CONTEXTUAL_BROLL_YML') or 'config/contextual_broll.yml')

    # Sortie et nettoyage
    USE_HARDLINKS = _to_bool(_UI_SETTINGS.get('use_hardlinks'), default=True) if 'use_hardlinks' in _UI_SETTINGS else _to_bool(os.getenv('USE_HARDLINKS'), default=True)
    BROLL_DELETE_AFTER_USE = _to_bool(_UI_SETTINGS.get('broll_delete_after_use'), default=True) if 'broll_delete_after_use' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_DELETE_AFTER_USE') or os.getenv('AI_BROLL_PURGE_AFTER_USE'), default=True)
    BROLL_PURGE_AFTER_RUN = _to_bool(_UI_SETTINGS.get('broll_purge_after_run'), default=True) if 'broll_purge_after_run' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_PURGE_AFTER_RUN') or os.getenv('AI_BROLL_PURGE_AFTER_RUN'), default=True)
    # Brand kit
    BRAND_KIT_ID = _UI_SETTINGS.get('brand_kit_id') or os.getenv('BRAND_KIT_ID') or 'default'
    # Experimental FX (wipes/zoom/LUT etc.)
    ENABLE_EXPERIMENTAL_FX = _to_bool(_UI_SETTINGS.get('enable_experimental_fx'), default=False) if 'enable_experimental_fx' in _UI_SETTINGS else _to_bool(os.getenv('ENABLE_EXPERIMENTAL_FX'), default=False)

    # ğŸš€ NOUVEAU: Configuration du sÃ©lecteur B-roll gÃ©nÃ©rique
    BROLL_SELECTOR_CONFIG_PATH = Path(_UI_SETTINGS.get('broll_selector_config') or os.getenv('BROLL_SELECTOR_CONFIG') or 'config/broll_selector_config.yaml')
    BROLL_SELECTOR_ENABLED = _to_bool(_UI_SETTINGS.get('broll_selector_enabled'), default=True) if 'broll_selector_enabled' in _UI_SETTINGS else _to_bool(os.getenv('BROLL_SELECTOR_ENABLED') or os.getenv('AI_BROLL_SELECTOR_ENABLED'), default=True)

def _detect_local_llm() -> Dict[str, str]:
    """Detect a local LLM server (Ollama or LM Studio) and return provider/base/model."""
    provider = os.getenv("LLM_PROVIDER") or ""
    base = os.getenv("LLM_BASE_URL") or ""
    model = os.getenv("LLM_MODEL") or "gemma3-4b-4g"
    # If env not provided, probe common ports
    if not base:
        try:
            r = requests.get("http://localhost:11434/api/tags", timeout=1.0)
            if r.ok:
                provider = "ollama"; base = "http://localhost:11434"
        except Exception:
            pass
    if not base:
        try:
            r = requests.get("http://localhost:1234/v1/models", timeout=1.0)
            if r.ok:
                provider = "lmstudio"; base = "http://localhost:1234/v1"
        except Exception:
            pass
    return {"provider": provider, "base": base, "model": model}

def _llm_generate_caption_hashtags(transcript_text: str) -> Optional[Dict[str, object]]:
    """Use local LLM to generate viral-ready title, description, hashtags and B-roll keywords as JSON. Returns dict or None on failure."""
    info = _detect_local_llm()
    provider = info.get("provider")
    base = info.get("base")
    model = info.get("model") or "gemma3-4b-4g"
    if not base or not provider:
        return None
    # Limit transcript for prompt brevity
    text = (transcript_text or "").strip()
    if len(text) > 2000:
        text = text[:2000]
    
    # ğŸš€ NOUVEAU: Prompt enrichi pour inclure les mots-clÃ©s B-roll
    prompt = (
        "You are a social media strategist and B-roll content expert for TikTok and Instagram.\n"
        "From this transcript, produce elements optimized for virality AND B-roll video content selection.\n"
        "Write in English only.\n\n"
        "REQUIRED OUTPUT:\n"
        "1. title: short, catchy (<= 60 characters), TikTok/Instagram Reels style\n"
        "2. description: 1-2 punchy sentences with an implicit call-to-action\n"
        "3. hashtags: 10-14 varied hashtags, exact format #keyword (no spaces), mix of niche + trending\n"
        "4. broll_keywords: 15-20 keywords optimized for B-roll video selection, covering:\n"
        "   - Main concepts and themes\n"
        "   - Visual elements (people, actions, places, objects)\n"
        "   - Synonyms and related terms\n"
        "   - Cross-domain concepts for broader B-roll matching\n"
        "   - Terms that are easily illustrated with stock footage\n\n"
        "Respond ONLY in compact JSON with keys: title (string), description (string), hashtags (array), broll_keywords (array).\n\n"
        f"Transcript:\n{text}\n\n"
        "JSON:"
    )
    
    try:
        if provider == "ollama":
            url = base.rstrip("/") + "/api/generate"
            payload = {"model": model, "prompt": prompt, "temperature": 0.7, "stream": False}
            
            # ğŸš€ NOUVEAU: Timeout plus long pour Ollama (gÃ©nÃ©ration complexe)
            print(f"    ğŸ¤– [LLM] GÃ©nÃ©ration avec Ollama ({model})...")
            r = requests.post(url, json=payload, timeout=120)  # 2 minutes au lieu de 60s
            r.raise_for_status()
            
            data = r.json() if r.headers.get("content-type","" ).startswith("application/json") else {"response": r.text}
            raw = data.get("response", "") if isinstance(data, dict) else ""
            
            if not raw:
                print(f"    âš ï¸ [LLM] RÃ©ponse vide d'Ollama")
                return None
                
            print(f"    âœ… [LLM] RÃ©ponse reÃ§ue ({len(raw)} caractÃ¨res)")
            
        else:
            # LM Studio OpenAI-compatible completions
            url = base.rstrip("/") + "/completions"
            payload = {"model": model, "prompt": prompt, "temperature": 0.7, "max_tokens": 512}  # AugmentÃ© pour les mots-clÃ©s B-roll
            r = requests.post(url, json=payload, timeout=60)
            r.raise_for_status()
            jd = r.json()
            raw = "".join(ch.get("text", "") for ch in jd.get("choices", [])).strip()
        
        # Try parse JSON from raw (may include surrounding text)
        import json as _json
        raw_str = raw.strip()
        # Find first and last braces to robustly extract JSON
        sidx = raw_str.find("{")
        eidx = raw_str.rfind("}")
        if sidx != -1 and eidx != -1 and eidx > sidx:
            raw_str = raw_str[sidx:eidx+1]
        obj = _json.loads(raw_str)
        
        title = (obj.get("title") or "").strip()
        description = (obj.get("description") or "").strip()
        tags = obj.get("hashtags") or []
        tags = [t.strip() for t in tags if isinstance(t, str) and t.strip()]
        
        # ğŸš€ NOUVEAU: Extraction des mots-clÃ©s B-roll
        broll_keywords = obj.get("broll_keywords") or []
        broll_keywords = [kw.strip().lower() for kw in broll_keywords if isinstance(kw, str) and kw.strip()]
        
        # Validation et fallback pour les mots-clÃ©s B-roll
        if not broll_keywords:
            # Fallback: extraire des mots-clÃ©s basiques du titre et de la description
            fallback_text = f"{title} {description}".lower()
            fallback_keywords = [word for word in fallback_text.split() if len(word) > 3 and word.isalpha()]
            broll_keywords = list(set(fallback_keywords))[:10]  # Limiter Ã  10 mots-clÃ©s de fallback
        
        if not (title or description or tags):
            return None
        
        # ğŸš€ NOUVEAU: Retourner aussi les mots-clÃ©s B-roll
        return {
            "title": title, 
            "description": description, 
            "hashtags": tags,
            "broll_keywords": broll_keywords  # Nouveau champ
        }
        
    except Exception as e:
        print(f"âš ï¸ Erreur gÃ©nÃ©ration LLM: {e}")
        return None

# === IA: Analyse mots-clÃ©s et prompts visuels pour guider le B-roll ===

def extract_keywords_from_transcript_ai(transcript_segments: List[Dict]) -> Dict:
    """Analyse simple: thÃ¨mes, occurrences et timestamps pour B-roll contextuel."""
    keyword_categories = {
        'money': ['money', 'cash', 'dollars', 'profit', 'revenue', 'income', 'wealth'],
        'business': ['business', 'company', 'startup', 'entrepreneur', 'strategy'],
        'technology': ['tech', 'software', 'app', 'digital', 'online', 'ai', 'automation'],
        'success': ['success', 'win', 'achievement', 'goal', 'growth', 'scale'],
        'people': ['team', 'customer', 'client', 'person', 'human', 'community'],
        'emotion_positive': ['amazing', 'incredible', 'fantastic', 'awesome', 'fire'],
        'emotion_negative': ['problem', 'issue', 'difficult', 'challenge', 'fail'],
        'action': ['build', 'create', 'launch', 'start', 'implement', 'execute']
    }
    full_text = ' '.join([(seg.get('text') or '').lower() for seg in transcript_segments])
    detected_keywords: Dict[str, List[str]] = {}
    timestamps_by_category: Dict[str, List[Dict]] = {}
    for category, kws in keyword_categories.items():
        detected_keywords[category] = []
        timestamps_by_category[category] = []
        for kw in kws:
            if kw in full_text:
                detected_keywords[category].append(kw)
                for seg in transcript_segments:
                    text = (seg.get('text') or '').lower()
                    if kw in text:
                        timestamps_by_category[category].append({
                            'start': float(seg.get('start') or 0.0),
                            'end': float(seg.get('end') or 0.0),
                            'keyword': kw,
                            'context': seg.get('text') or ''
                        })
    dominant_theme = 'business'
    try:
        dominant_theme = max(detected_keywords.items(), key=lambda x: len(x[1]))[0]
    except Exception:
        pass
    return {
        'keywords': detected_keywords,
        'timestamps': timestamps_by_category,
        'dominant_theme': dominant_theme,
        'total_duration': float(transcript_segments[-1]['end']) if transcript_segments else 0.0
    }


def generate_broll_prompts_ai(keyword_analysis: Dict) -> List[Dict]:
    """Generate B-roll prompts using AI analysis."""
    try:
        # Extract main theme and keywords
        main_theme = keyword_analysis.get('main_theme', 'general')
        keywords = keyword_analysis.get('keywords', [])
        sentiment = keyword_analysis.get('sentiment', 0.0)
        
        # Generate context-aware prompts
        prompts = []
        
        # Base prompts from main theme
        if main_theme == 'technology':
            prompts.extend([
                'artificial intelligence neural network',
                'computer vision algorithm',
                'tech innovation future',
                'digital transformation',
                'machine learning data'
            ])
        elif main_theme == 'medical':
            prompts.extend([
                'medical research laboratory',
                'healthcare innovation hospital',
                'microscope scientific discovery',
                'medical technology',
                'healthcare professionals'
            ])
        elif main_theme == 'business':
            prompts.extend([
                'business success growth',
                'entrepreneurship motivation',
                'professional development office',
                'team collaboration',
                'business strategy'
            ])
        elif main_theme == 'neuroscience':
            prompts.extend([
                'neuroscience brain neurons synapse',
                'brain reflexes nervous system',
                'brain scan mri eeg lab',
                'cognitive science',
                'mental health awareness'
            ])
        else:
            # Generic prompts for other themes
            base_keywords = keywords[:3] if keywords else [main_theme]
            for kw in base_keywords:
                prompts.append(f"{main_theme} {kw}")
        
        # Add sentiment-based prompts
        if sentiment > 0.3:
            prompts.extend(['positive energy', 'success achievement', 'happy people'])
        elif sentiment < -0.3:
            prompts.extend(['serious focus', 'determination', 'overcoming challenges'])
        
        # Limit and deduplicate
        unique_prompts = list(dict.fromkeys(prompts))[:8]
        
        return unique_prompts
        
    except Exception as e:
        print(f"âš ï¸ Erreur gÃ©nÃ©ration prompts AI: {e}")
        # Fallback prompts
        return ['general content', 'people working', 'modern technology']

class VideoProcessor:
    """Classe principale pour traiter les vidÃ©os"""
    
    def __init__(self):
        self.whisper_model = whisper.load_model(Config.WHISPER_MODEL)
        self._setup_directories()
        # Cache Ã©ventuel pour spaCy
        self._spacy_model = None
    
    def _setup_directories(self):
        """CrÃ©e les dossiers nÃ©cessaires"""
        for folder in [Config.CLIPS_FOLDER, Config.OUTPUT_FOLDER, Config.TEMP_FOLDER]:
            folder.mkdir(exist_ok=True)
    
    def _generate_unique_output_dir(self, clip_stem: str) -> Path:
        """CrÃ©e un dossier unique pour ce clip sous output/clips/<stem>[-NNN]"""
        root = Config.OUTPUT_FOLDER / 'clips'
        root.mkdir(parents=True, exist_ok=True)
        base = root / clip_stem
        if not base.exists():
            base.mkdir(parents=True, exist_ok=True)
            return base
        # Trouver suffixe -001, -002, ...
        for i in range(1, 1000):
            candidate = root / f"{clip_stem}-{i:03d}"
            if not candidate.exists():
                candidate.mkdir(parents=True, exist_ok=True)
                return candidate
        # Fallback timestamp
        from datetime import datetime
        ts = datetime.now().strftime('%Y%m%d-%H%M%S')
        cand = root / f"{clip_stem}-{ts}"
        cand.mkdir(parents=True, exist_ok=True)
        return cand
    
    def _safe_copy(self, src: Path, dst: Path) -> None:
        try:
            if src and Path(src).exists():
                dst.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(str(src), str(dst))
        except Exception:
            pass

    def _hardlink_or_copy(self, src: Path, dst: Path) -> None:
        """CrÃ©e un hardlink si possible, sinon copie le fichier."""
        try:
            dst.parent.mkdir(parents=True, exist_ok=True)
            if getattr(Config, 'USE_HARDLINKS', True):
                os.link(str(src), str(dst))
            else:
                shutil.copy2(str(src), str(dst))
        except Exception:
            try:
                shutil.copy2(str(src), str(dst))
            except Exception:
                pass
 
    def _unique_path(self, directory: Path, base_name: str, extension: str) -> Path:
        """Retourne un chemin unique dans directory en ajoutant -NNN si collision."""
        directory.mkdir(parents=True, exist_ok=True)
        candidate = directory / f"{base_name}{extension}"
        if not candidate.exists():
            return candidate
        for i in range(1, 1000):
            alt = directory / f"{base_name}-{i:03d}{extension}"
            if not alt.exists():
                return alt
        from datetime import datetime
        ts = datetime.now().strftime('%Y%m%d-%H%M%S')
        return directory / f"{base_name}-{ts}{extension}"
    
    def _cleanup_files(self, paths: List[Path]) -> None:
        for p in paths:
            try:
                if p and Path(p).exists():
                    Path(p).unlink()
            except Exception:
                pass
 
    def _purge_broll_caches(self) -> None:
        try:
            broll_lib = Path('AI-B-roll') / 'broll_library'
            broll_cache = Path('AI-B-roll') / '.cache'
            if broll_lib.exists():
                for item in broll_lib.glob('*'):
                    try:
                        if item.is_dir():
                            shutil.rmtree(item, ignore_errors=True)
                        else:
                            item.unlink(missing_ok=True)
                    except Exception:
                        pass
            if broll_cache.exists():
                shutil.rmtree(broll_cache, ignore_errors=True)
        except Exception:
            pass

    # ğŸš¨ CORRECTION CRITIQUE: MÃ©thodes manquantes pour le sÃ©lecteur B-roll
    def _load_broll_selector_config(self):
        """Charge la configuration du sÃ©lecteur B-roll depuis le fichier YAML"""
        try:
            import yaml
            if Config.BROLL_SELECTOR_CONFIG_PATH.exists():
                with open(Config.BROLL_SELECTOR_CONFIG_PATH, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
            else:
                print(f"    âš ï¸ Fichier de configuration introuvable: {Config.BROLL_SELECTOR_CONFIG_PATH}")
                return {}
        except Exception as e:
            print(f"    âš ï¸ Erreur chargement configuration: {e}")
            return {}

    def _calculate_asset_hash(self, asset_path: Path) -> str:
        """Calcule un hash unique pour un asset B-roll basÃ© sur son contenu et mÃ©tadonnÃ©es"""
        try:
            import hashlib
            import os
            from datetime import datetime
            
            # Hash basÃ© sur le nom, la taille et la date de modification
            stat = asset_path.stat()
            hash_data = f"{asset_path.name}_{stat.st_size}_{stat.st_mtime}"
            return hashlib.md5(hash_data.encode()).hexdigest()
        except Exception:
            # Fallback sur le nom du fichier
            return str(asset_path.name)

    def _extract_keywords_for_segment_spacy(self, text: str) -> List[str]:
        """Extraction optionnelle (spaCy) de mots-clÃ©s (noms/verbes/entitÃ©s). Fallback heuristique si indisponible."""
        try:
            import re as _re
            
            # ğŸš¨ CORRECTION IMMÃ‰DIATE: Filtre des mots gÃ©nÃ©riques inutiles
            GENERIC_WORDS = {
                'very', 'much', 'many', 'some', 'any', 'all', 'each', 'every', 'few', 'several',
                'reflexes', 'speed', 'clear', 'good', 'bad', 'big', 'small', 'new', 'old', 'high', 'low',
                'fast', 'slow', 'hard', 'easy', 'strong', 'weak', 'hot', 'cold', 'warm', 'cool',
                'right', 'wrong', 'true', 'false', 'yes', 'no', 'maybe', 'perhaps', 'probably',
                'thing', 'stuff', 'way', 'time', 'place', 'person', 'people', 'man', 'woman', 'child',
                'work', 'make', 'do', 'get', 'go', 'come', 'see', 'look', 'hear', 'feel', 'think',
                'know', 'want', 'need', 'like', 'love', 'hate', 'hope', 'wish', 'try', 'help'
            }
            
            if self._spacy_model is None:
                try:
                    import spacy as _spacy
                    for _model in ['en_core_web_sm', 'fr_core_news_sm', 'xx_ent_wiki_sm']:
                        try:
                            self._spacy_model = _spacy.load(_model, disable=['parser','lemmatizer'])
                            break
                        except Exception:
                            continue
                    if self._spacy_model is None:
                        self._spacy_model = _spacy.blank('en')
                except Exception:
                    self._spacy_model = None
            doc = None
            if self._spacy_model is not None:
                try:
                    doc = self._spacy_model(text)
                except Exception:
                    doc = None
            keywords: List[str] = []
            if doc is not None and hasattr(doc, 'ents'):
                for ent in doc.ents:
                    val = ent.text.strip()
                    if len(val) >= 3 and val.lower() not in keywords and val.lower() not in GENERIC_WORDS:
                        keywords.append(val.lower())
            # POS si dispo
            if doc is not None and getattr(doc, 'has_annotation', lambda *_: False)('TAG'):
                for tok in doc:
                    if tok.pos_ in ('NOUN','PROPN','VERB') and len(tok.text) >= 3:
                        lemma = (tok.lemma_ or tok.text).lower()
                        if lemma not in keywords and lemma not in GENERIC_WORDS:
                            keywords.append(lemma)
            # Fallback heuristique simple avec filtre
            if not keywords:
                for w in _re.findall(r"[A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿0-9']{4,}", text or ""):
                    lw = w.lower()
                    if lw not in keywords and lw not in GENERIC_WORDS:
                        keywords.append(lw)
            
            # ğŸš¨ CORRECTION IMMÃ‰DIATE: Prioriser les mots contextuels importants
            PRIORITY_WORDS = {
                'neuroscience', 'brain', 'mind', 'consciousness', 'cognitive', 'mental', 'psychology',
                'medical', 'health', 'treatment', 'research', 'science', 'discovery', 'innovation',
                'technology', 'digital', 'future', 'ai', 'artificial', 'intelligence', 'machine',
                'business', 'success', 'growth', 'strategy', 'leadership', 'entrepreneur', 'startup'
            }
            
            # RÃ©organiser pour prioriser les mots importants
            priority_keywords = [kw for kw in keywords if kw in PRIORITY_WORDS]
            other_keywords = [kw for kw in keywords if kw not in PRIORITY_WORDS]
            
            # Retourner d'abord les mots prioritaires, puis les autres
            final_keywords = priority_keywords + other_keywords
            return final_keywords[:12]
        except Exception:
            return []

    def process_all_clips(self, input_video_path: str):
        """Pipeline principal de traitement"""
        logger.info("ğŸš€ DÃ©but du pipeline de traitement")
        print("ğŸ¬ DÃ©marrage du pipeline de traitement...")
        
        # Ã‰tape 1: DÃ©coupage (votre IA existante)
        
        # Ã‰tape 2: Traitement de chaque clip
        clip_files = list(Config.CLIPS_FOLDER.glob("*.mp4"))
        total_clips = len(clip_files)
        
        print(f"ğŸ“ {total_clips} clips trouvÃ©s dans le dossier clips/")
        
        for i, clip_path in enumerate(clip_files):
            print(f"\nğŸ¬ [{i+1}/{total_clips}] Traitement de: {clip_path.name}")
            logger.info(f"ğŸ¬ Traitement du clip {i+1}/{total_clips}: {clip_path.name}")
            
            # Skip si dÃ©jÃ  traitÃ©
            stem = Path(clip_path).stem
            final_dir = Config.OUTPUT_FOLDER / 'final'
            processed_already = False
            if final_dir.exists():
                matches = list(final_dir.glob(f"final_{stem}*.mp4"))
                processed_already = len(matches) > 0
            if processed_already:
                print(f"â© Clip dÃ©jÃ  traitÃ©, ignorÃ© : {clip_path.name}")
                logger.info(f"â© Clip dÃ©jÃ  traitÃ©, ignorÃ© : {clip_path.name}")
                continue

            # Verrou concurrentiel par clip
            locks_dir = Config.OUTPUT_FOLDER / 'locks'
            locks_dir.mkdir(parents=True, exist_ok=True)
            lock_file = locks_dir / f"{stem}.lock"
            if lock_file.exists():
                print(f"â­ï¸ Verrou dÃ©tectÃ©, saut du clip: {clip_path.name}")
                continue
            try:
                lock_file.write_text("locked", encoding='utf-8')
                self.process_single_clip(clip_path)
                print(f"âœ… Clip {clip_path.name} traitÃ© avec succÃ¨s")
                logger.info(f"âœ… Clip {clip_path.name} traitÃ© avec succÃ¨s")
            except Exception as e:
                print(f"âŒ Erreur lors du traitement de {clip_path.name}: {e}")
                logger.error(f"âŒ Erreur lors du traitement de {clip_path.name}: {e}")
            finally:
                try:
                    if lock_file.exists():
                        lock_file.unlink()
                except Exception:
                    pass
        
        print(f"\nğŸ‰ Pipeline terminÃ© ! {total_clips} clips traitÃ©s.")
        logger.info("ğŸ‰ Pipeline terminÃ© avec succÃ¨s")
        # Purge B-roll (librairie + caches) si demandÃ© pour garder le disque lÃ©ger
        try:
            if getattr(Config, 'BROLL_PURGE_AFTER_RUN', False):
                self._purge_broll_caches()
        except Exception:
            pass
        # AgrÃ©ger un rapport global mÃªme sans --json-report
        try:
            final_dir = (Config.OUTPUT_FOLDER / 'final')
            items = []
            if final_dir.exists():
                for jf in final_dir.glob('final_*.json'):
                    try:
                        items.append(json.loads(jf.read_text(encoding='utf-8')))
                    except Exception:
                        pass
            report_path = Config.OUTPUT_FOLDER / 'report.json'
            report_path.write_text(json.dumps({'clips': items}, ensure_ascii=False, indent=2), encoding='utf-8')
        except Exception:
            pass

    def cut_viral_clips(self, input_video_path: str):
        """
        Interface pour votre IA de dÃ©coupage existante
        Remplacez cette mÃ©thode par votre implÃ©mentation
        """
        logger.info("ğŸ“¼ DÃ©coupage des clips avec IA...")
        
        # Exemple basique - remplacez par votre IA
        video = VideoFileClip(input_video_path)
        duration = video.duration
        
        # DÃ©coupage adaptatif selon la durÃ©e
        if duration <= 30:
            # VidÃ©o courte : utiliser toute la vidÃ©o
            segment_duration = duration
            segments = 1
        else:
            # VidÃ©o longue : dÃ©couper en segments de 30 secondes
            segment_duration = 30
            segments = max(1, int(duration // segment_duration))
        
        for i in range(min(segments, 5)):  # Max 5 clips pour test
            start_time = i * segment_duration
            end_time = min((i + 1) * segment_duration, duration)
            
            clip = video.subclip(start_time, end_time)
            output_path = Config.CLIPS_FOLDER / f"clip_{i+1:02d}.mp4"
            clip.write_videofile(str(output_path), verbose=False, logger=None)
        
        video.close()
        logger.info(f"âœ… {segments} clips gÃ©nÃ©rÃ©s")
    
    def process_single_clip(self, clip_path: Path):
        """Traite un clip individuel (reframe -> transcription (pour B-roll) -> B-roll -> sous-titres)"""
        
        # Dossier de sortie dÃ©diÃ© et unique
        per_clip_dir = self._generate_unique_output_dir(clip_path.stem)
        
        print(f"  ğŸ“ Ã‰tape 1/4: Reframe dynamique IA...")
        reframed_path = self.reframe_to_vertical(clip_path)
        # DÃ©placer artefact reframed dans le dossier du clip
        try:
            dst_reframed = per_clip_dir / 'reframed.mp4'
            if Path(reframed_path).exists():
                shutil.move(str(reframed_path), str(dst_reframed))
            reframed_path = dst_reframed
        except Exception:
            pass
        
        print(f"  ğŸ—£ï¸ Ã‰tape 2/4: Transcription Whisper (guide B-roll)...")
        # Transcrire tÃ´t pour guider la sÃ©lection B-roll (SRT disponible)
        subtitles = self.transcribe_segments(reframed_path)
        try:
            # Ã‰crire un SRT Ã  cÃ´tÃ© de la vidÃ©o reframÃ©e
            srt_reframed = reframed_path.with_suffix('.srt')
            write_srt(subtitles, srt_reframed)
            # Sauvegarder transcription segments JSON
            seg_json = per_clip_dir / f"{clip_path.stem}_segments.json"
            with open(seg_json, 'w', encoding='utf-8') as f:
                json.dump(subtitles, f, ensure_ascii=False)
        except Exception:
            pass
        
        print(f"  ğŸï¸ Ã‰tape 3/4: Insertion des B-rolls {'(activÃ©e)' if getattr(Config, 'ENABLE_BROLL', False) else '(dÃ©sactivÃ©e)'}...")
        
        # ğŸš€ CORRECTION: GÃ©nÃ©rer les mots-clÃ©s LLM AVANT l'insertion des B-rolls
        broll_keywords = []
        try:
            print("    ğŸ¤– GÃ©nÃ©ration prÃ©coce des mots-clÃ©s LLM pour B-rolls...")
            title, description, hashtags, broll_keywords = self.generate_caption_and_hashtags(subtitles)
            print(f"    âœ… Mots-clÃ©s B-roll LLM gÃ©nÃ©rÃ©s: {len(broll_keywords)} termes")
            print(f"    ğŸ¯ Exemples: {', '.join(broll_keywords[:5])}")
        except Exception as e:
            print(f"    âš ï¸ Erreur gÃ©nÃ©ration mots-clÃ©s LLM: {e}")
            broll_keywords = []
        
        # Maintenant insÃ©rer les B-rolls avec les mots-clÃ©s LLM disponibles
        with_broll_path = self.insert_brolls_if_enabled(reframed_path, subtitles, broll_keywords)
        
        # Copier artefact with_broll si diffÃ©rent
        try:
            if with_broll_path and with_broll_path != reframed_path:
                self._safe_copy(with_broll_path, per_clip_dir / 'with_broll.mp4')
        except Exception:
            pass
        
        print(f"  âœ¨ Ã‰tape 4/4: Ajout des sous-titres Hormozi 1...")
        # GÃ©nÃ©rer meta (titre/hashtags) depuis transcription (dÃ©jÃ  fait)
        try:
            # RÃ©utiliser les donnÃ©es dÃ©jÃ  gÃ©nÃ©rÃ©es
            if not broll_keywords:  # Fallback si pas encore gÃ©nÃ©rÃ©
                title, description, hashtags, broll_keywords = self.generate_caption_and_hashtags(subtitles)
            
            print(f"  ğŸ“ Title: {title}")
            print(f"  ğŸ“ Description: {description}")
            print(f"  #ï¸âƒ£ Hashtags: {' '.join(hashtags)}")
            meta_path = per_clip_dir / 'meta.txt'
            with open(meta_path, 'w', encoding='utf-8') as f:
                f.write(
                    "Title: " + title + "\n\n" +
                    "Description: " + description + "\n\n" +
                    "Hashtags: " + ' '.join(hashtags) + "\n\n" +
                    "B-roll Keywords: " + ', '.join(broll_keywords) + "\n"
                )
        except Exception:
            pass
        
        # Appliquer style Hormozi sur la vidÃ©o post B-roll
        subtitled_out_dir = per_clip_dir
        subtitled_out_dir.mkdir(parents=True, exist_ok=True)
        final_subtitled_path = subtitled_out_dir / 'final_subtitled.mp4'
        try:
            span_style_map = {
                # Business & Croissance
                "croissance": {"color": "#39FF14", "bold": True, "emoji": "ğŸ“ˆ"},
                "growth": {"color": "#39FF14", "bold": True, "emoji": "ğŸ“ˆ"},
                "opportunitÃ©": {"color": "#FFD700", "bold": True, "emoji": "ï¿½ï¿½"},
                "opportunite": {"color": "#FFD700", "bold": True, "emoji": "ğŸ”‘"},
                "innovation": {"color": "#00E5FF", "emoji": "âš¡"},
                "idÃ©e": {"color": "#00E5FF", "emoji": "ğŸ’¡"},
                "idee": {"color": "#00E5FF", "emoji": "ğŸ’¡"},
                "stratÃ©gie": {"color": "#FF73FA", "emoji": "ğŸ§­"},
                "strategie": {"color": "#FF73FA", "emoji": "ğŸ§­"},
                "plan": {"color": "#FF73FA", "emoji": "ğŸ—ºï¸"},
                # Argent & Finance
                "argent": {"color": "#FFD700", "bold": True, "emoji": "ğŸ’°"},
                "money": {"color": "#FFD700", "bold": True, "emoji": "ğŸ’°"},
                "cash": {"color": "#FFD700", "bold": True, "emoji": "ğŸ’°"},
                "investissement": {"color": "#8AFF00", "bold": True, "emoji": "ğŸ“Š"},
                "investissements": {"color": "#8AFF00", "bold": True, "emoji": "ğŸ“Š"},
                "revenu": {"color": "#8AFF00", "emoji": "ğŸ¦"},
                "revenus": {"color": "#8AFF00", "emoji": "ğŸ¦"},
                "profit": {"color": "#8AFF00", "bold": True, "emoji": "ğŸ’°"},
                "profits": {"color": "#8AFF00", "bold": True, "emoji": "ğŸ’°"},
                "perte": {"color": "#FF3131", "emoji": "ğŸ“‰"},
                "pertes": {"color": "#FF3131", "emoji": "ğŸ“‰"},
                "Ã©chec": {"color": "#FF3131", "emoji": "âŒ"},
                "echec": {"color": "#FF3131", "emoji": "âŒ"},
                "budget": {"color": "#FFD700", "emoji": "ğŸ§¾"},
                "gestion": {"color": "#FFD700", "emoji": "ğŸª™"},
                "roi": {"color": "#8AFF00", "bold": True, "emoji": "ğŸ“ˆ"},
                "chiffre": {"color": "#FFD700", "emoji": "ğŸ’°"},
                "ca": {"color": "#FFD700", "emoji": "ğŸ’°"},
                # Relation & Client
                "client": {"color": "#00E5FF", "underline": True, "emoji": "ğŸ¤"},
                "clients": {"color": "#00E5FF", "underline": True, "emoji": "ğŸ¤"},
                "collaboration": {"color": "#00E5FF", "emoji": "ğŸ«±ğŸ¼â€ğŸ«²ğŸ½"},
                "collaborations": {"color": "#00E5FF", "emoji": "ğŸ«±ğŸ¼â€ğŸ«²ğŸ½"},
                "communautÃ©": {"color": "#39FF14", "emoji": "ğŸŒ"},
                "communaute": {"color": "#39FF14", "emoji": "ğŸŒ"},
                "confiance": {"color": "#00E5FF", "emoji": "ğŸ”’"},
                "vente": {"color": "#FF73FA", "emoji": "ğŸ›’"},
                "ventes": {"color": "#FF73FA", "emoji": "ğŸ›’"},
                "deal": {"color": "#FF73FA", "emoji": "ğŸ“¦"},
                "deals": {"color": "#FF73FA", "emoji": "ğŸ“¦"},
                "prospect": {"color": "#00E5FF", "emoji": "ğŸ¤"},
                "prospects": {"color": "#00E5FF", "emoji": "ğŸ¤"},
                "contrat": {"color": "#FF73FA", "emoji": "ğŸ“‹"},
                # Motivation & SuccÃ¨s
                "succÃ¨s": {"color": "#39FF14", "italic": True, "emoji": "ğŸ†"},
                "succes": {"color": "#39FF14", "italic": True, "emoji": "ğŸ†"},
                "motivation": {"color": "#FF73FA", "bold": True, "emoji": "ğŸ”¥"},
                "Ã©nergie": {"color": "#FF73FA", "emoji": "âš¡"},
                "energie": {"color": "#FF73FA", "emoji": "âš¡"},
                "victoire": {"color": "#39FF14", "emoji": "ğŸ¯"},
                "discipline": {"color": "#FFD700", "emoji": "â³"},
                "viral": {"color": "#FF73FA", "bold": True, "emoji": "ğŸš€"},
                "viralitÃ©": {"color": "#FF73FA", "bold": True, "emoji": "ğŸŒ"},
                "viralite": {"color": "#FF73FA", "bold": True, "emoji": "ğŸŒ"},
                "impact": {"color": "#FF73FA", "emoji": "ğŸ’¥"},
                "explose": {"color": "#FF73FA", "emoji": "ğŸ’¥"},
                "explosion": {"color": "#FF73FA", "emoji": "ğŸ’¥"},
                # Risque & Erreurs
                "erreur": {"color": "#FF3131", "emoji": "âš ï¸"},
                "erreurs": {"color": "#FF3131", "emoji": "âš ï¸"},
                "warning": {"color": "#FF3131", "emoji": "âš ï¸"},
                "obstacle": {"color": "#FF3131", "emoji": "ğŸ§±"},
                "obstacles": {"color": "#FF3131", "emoji": "ğŸ§±"},
                "solution": {"color": "#00E5FF", "emoji": "ğŸ”§"},
                "solutions": {"color": "#00E5FF", "emoji": "ğŸ”§"},
                "leÃ§on": {"color": "#00E5FF", "emoji": "ğŸ“š"},
                "lecon": {"color": "#00E5FF", "emoji": "ğŸ“š"},
                "apprentissage": {"color": "#00E5FF", "emoji": "ğŸ§ "},
                "problÃ¨me": {"color": "#FF3131", "emoji": "ğŸ›‘"},
                "probleme": {"color": "#FF3131", "emoji": "ğŸ›‘"},
            }
            add_hormozi_subtitles(
                str(with_broll_path), subtitles, str(final_subtitled_path),
                brand_kit=getattr(Config, 'BRAND_KIT_ID', 'default'),
                span_style_map=span_style_map
            )
        except Exception as e:
            print(f"  âŒ Erreur ajout sous-titres Hormozi: {e}")
            # Pas de retour anticipÃ©: continuer export simple
        
        # Export final accumulÃ© dans output/final/ et sous-titrÃ© (burn-in) dans output/subtitled/
        final_dir = Config.OUTPUT_FOLDER / 'final'
        subtitled_dir = Config.OUTPUT_FOLDER / 'subtitled'
        # Noms de base sans extension
        base_name = clip_path.stem
        output_path = self._unique_path(final_dir, f"final_{base_name}", ".mp4")
        try:
            # Choisir source finale: si sous-titrÃ©e existe sinon with_broll sinon reframed
            source_final = None
            if final_subtitled_path.exists():
                source_final = final_subtitled_path
            elif with_broll_path and Path(with_broll_path).exists():
                source_final = with_broll_path
            else:
                source_final = reframed_path
            if source_final and Path(source_final).exists():
                self._hardlink_or_copy(source_final, output_path)
                # Ecrire SRT: Ã©viter le doublon si la vidÃ©o finale a dÃ©jÃ  les sous-titres incrustÃ©s
                is_burned = (final_subtitled_path.exists() and Path(source_final) == Path(final_subtitled_path))
                if not is_burned:
                    srt_out = output_path.with_suffix('.srt')
                    write_srt(subtitles, srt_out)
                    self._hardlink_or_copy(srt_out, per_clip_dir / 'final.srt')
                    # WebVTT
                    try:
                        vtt_out = output_path.with_suffix('.vtt')
                        write_vtt(subtitles, vtt_out)
                    except Exception:
                        pass
                else:
                    # Produire uniquement une SRT dans le dossier du clip, pas Ã  cÃ´tÃ© du MP4 final
                    try:
                        write_srt(subtitles, per_clip_dir / 'final.srt')
                    except Exception:
                        pass
                # Toujours produire un VTT Ã  cÃ´tÃ© du final pour compat
                try:
                    vtt_out = output_path.with_suffix('.vtt')
                    write_vtt(subtitles, vtt_out)
                except Exception:
                    pass
                # Copier final dans dossier clip
                self._hardlink_or_copy(output_path, per_clip_dir / 'final.mp4')
                # Si une version sous-titrÃ©e burn-in existe, la dupliquer dans output/subtitled/
                if final_subtitled_path.exists():
                    subtitled_out = self._unique_path(subtitled_dir, f"{base_name}_subtitled", ".mp4")
                    self._hardlink_or_copy(final_subtitled_path, subtitled_out)
                # Copier meta.txt Ã  cÃ´tÃ© du final accumulÃ©
                try:
                    meta_src = per_clip_dir / 'meta.txt'
                    if meta_src.exists():
                        self._hardlink_or_copy(meta_src, output_path.with_suffix('.txt'))
                except Exception:
                    pass
                # Ecrire un JSON rÃ©cap par clip
                try:
                    # DurÃ©e et hash final
                    final_duration = None
                    try:
                        with VideoFileClip(str(output_path)) as vc:
                            final_duration = float(vc.duration)
                    except Exception:
                        final_duration = None
                    media_hash = None
                    try:
                        from src.pipeline.utils import hash_media  # type: ignore
                    except Exception:
                        hash_media = None  # type: ignore
                    if hash_media:
                        try:
                            media_hash = hash_media(str(output_path))
                        except Exception:
                            media_hash = None
                    summary = {
                        'clip': base_name,
                        'final_mp4': str(output_path.resolve()),
                        'final_srt': str(output_path.with_suffix('.srt').resolve()) if (not is_burned) and output_path.with_suffix('.srt').exists() else None,
                        'final_vtt': str(output_path.with_suffix('.vtt').resolve()) if (not is_burned) and output_path.with_suffix('.vtt').exists() else None,
                        'subtitled_mp4': str((subtitled_out.resolve() if final_subtitled_path.exists() else '')) if final_subtitled_path.exists() else None,
                        'meta_txt': str(output_path.with_suffix('.txt').resolve()) if output_path.with_suffix('.txt').exists() else None,
                        'per_clip_dir': str(per_clip_dir.resolve()),
                        'duration_s': final_duration,
                        'media_hash': media_hash,
                        'events': [
                            {
                                'id': getattr(ev, 'id', ev.get('id') if isinstance(ev, dict) else ''),
                                'start_s': float(getattr(ev, 'start_s', ev.get('start_s') if isinstance(ev, dict) else 0.0) or 0.0),
                                'end_s': float(getattr(ev, 'end_s', ev.get('end_s') if isinstance(ev, dict) else 0.0) or 0.0),
                                'media_path': getattr(ev, 'media_path', ev.get('media_path') if isinstance(ev, dict) else ''),
                                'transition': getattr(ev, 'transition', ev.get('transition') if isinstance(ev, dict) else None),
                                'transition_duration': float(getattr(ev, 'transition_duration', ev.get('transition_duration') if isinstance(ev, dict) else 0.0) or 0.0),
                            } for ev in (events or [])
                        ]
                    }
                    with open(output_path.with_suffix('.json'), 'w', encoding='utf-8') as jf:
                        json.dump(summary, jf, ensure_ascii=False, indent=2)
                    # JSONL log
                    try:
                        jsonl = (Config.OUTPUT_FOLDER / 'pipeline.log.jsonl')
                        with open(jsonl, 'a', encoding='utf-8') as lf:
                            lf.write(json.dumps(summary, ensure_ascii=False) + '\n')
                    except Exception:
                        pass
                except Exception:
                    pass
                print(f"  ğŸ“¤ Export terminÃ©: {output_path.name}")
                # Nettoyage des intermÃ©diaires pour limiter l'empreinte disque
                self._cleanup_files([
                    with_broll_path if with_broll_path and with_broll_path != output_path else None,
                ])
                return output_path
            else:
                print(f"  âš ï¸ Fichier final introuvable")
                return None
        except Exception as e:
            print(f"  âŒ Erreur export: {e}")
            return None

    def _get_sample_times(self, duration: float, fps: int) -> List[float]:
        if duration <= 10:
            return list(np.arange(0, duration, 1/fps))
        elif duration <= 30:
            return list(np.arange(0, duration, 2/fps))
        else:
            return list(np.arange(0, duration, 4/fps))

    def _smooth_trajectory(self, x_centers: List[float], window_size: int = 15) -> List[float]:
        # FenÃªtre plus grande pour un lissage plus smooth
        window_size = max(window_size, 31)
        if len(x_centers) < window_size:
            kernel = np.ones(min(9, len(x_centers))) / max(1, min(9, len(x_centers)))
            return np.convolve(x_centers, kernel, mode='same').tolist()
        try:
            from scipy.signal import savgol_filter
            smoothed = savgol_filter(x_centers, window_size, 3).tolist()
        except Exception:
            kernel = np.ones(window_size) / window_size
            smoothed = np.convolve(x_centers, kernel, mode='same').tolist()
        # EMA additionnel pour attÃ©nuer le jitter haute frÃ©quence
        alpha = 0.15  # plus petit = plus lisse
        ema = []
        last = smoothed[0] if smoothed else 0.5
        for v in smoothed:
            last = (1 - alpha) * last + alpha * v
            ema.append(last)
        return ema

    def _interpolate_trajectory(self, x_centers: List[float], sample_times: List[float], duration: float, fps: int) -> List[float]:
        if not x_centers:
            return [0.5] * int(duration * fps)
        target_times = np.arange(0, duration, 1/fps)
        if len(x_centers) == 1:
            return [x_centers[0]] * len(target_times)
        try:
            return np.interp(target_times, sample_times, x_centers).tolist()
        except Exception:
            return [x_centers[-1]] * len(target_times)

    def _detect_single_frame(self, image_rgb: np.ndarray) -> float:
        # DÃ©tecteurs MediaPipe
        mp_pose = mp.solutions.pose
        mp_face = mp.solutions.face_detection
        h, w = image_rgb.shape[:2]
        with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.8) as pose, mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.7) as face_detection:
            pose_results = pose.process(image_rgb)
            if pose_results.pose_landmarks:
                landmarks = pose_results.pose_landmarks.landmark
                key_points = [
                    landmarks[mp_pose.PoseLandmark.NOSE],
                    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],
                    landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],
                ]
                valid_points = [p.x for p in key_points if p.visibility > 0.5]
                if valid_points:
                    return sum(valid_points) / len(valid_points)
            face_results = face_detection.process(image_rgb)
            if face_results.detections:
                detection = face_results.detections[0]
                bbox = detection.location_data.relative_bounding_box
                return bbox.xmin + bbox.width / 2
        gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if contours:
            moments = [cv2.moments(c) for c in contours if cv2.contourArea(c) > 100]
            if moments:
                centroids_x = [m['m10']/m['m00'] for m in moments if m['m00'] > 0]
                if centroids_x:
                    return sum(centroids_x) / len(centroids_x) / w
        return 0.5

    def _detect_focus_points(self, video: VideoFileClip, fps: int, duration: float) -> List[float]:
        x_centers = []
        sample_times = self._get_sample_times(duration, fps)
        mp_pose = mp.solutions.pose
        mp_face = mp.solutions.face_detection
        with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.8) as pose, mp_face.FaceDetection(model_selection=0, min_detection_confidence=0.7) as face_detection:
            for t in tqdm(sample_times, desc="ğŸ” IA focus", leave=False):
                try:
                    frame = video.get_frame(t)  # MoviePy retourne des frames RGB
                    image_rgb = frame
                    # Pose
                    pose_results = pose.process(image_rgb)
                    if pose_results.pose_landmarks:
                        landmarks = pose_results.pose_landmarks.landmark
                        key_points = [
                            landmarks[mp_pose.PoseLandmark.NOSE],
                            landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],
                            landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],
                        ]
                        valid_points = [p.x for p in key_points if p.visibility > 0.5]
                        if valid_points:
                            x_centers.append(sum(valid_points)/len(valid_points))
                            continue
                    # Face fallback
                    face_results = face_detection.process(image_rgb)
                    if face_results.detections:
                        detection = face_results.detections[0]
                        bbox = detection.location_data.relative_bounding_box
                        x_centers.append(bbox.xmin + bbox.width/2)
                        continue
                    # Mouvement fallback
                    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
                    edges = cv2.Canny(gray, 50, 150)
                    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    if contours:
                        moments = [cv2.moments(c) for c in contours if cv2.contourArea(c) > 100]
                        centroids_x = [m['m10']/m['m00'] for m in moments if m['m00'] > 0]
                        if centroids_x:
                            x_centers.append(sum(centroids_x)/len(centroids_x)/image_rgb.shape[1])
                            continue
                    x_centers.append(0.5)
                except Exception:
                    x_centers.append(0.5)
        return self._interpolate_trajectory(x_centers, sample_times, duration, fps)

    def reframe_to_vertical(self, clip_path: Path) -> Path:
        """Reframe dynamique basÃ© sur dÃ©tection IA optimisÃ©e"""
        logger.info("ğŸ¯ Reframe dynamique avec IA (optimisÃ©)")
        print("    ğŸ¯ DÃ©tection IA en cours...")
        video = VideoFileClip(str(clip_path))
        fps = int(video.fps)
        duration = video.duration
        # DÃ©tection des centres d'intÃ©rÃªt
        x_centers = self._detect_focus_points(video, fps, duration)
        x_centers_smooth = self._smooth_trajectory(x_centers, window_size=min(15, max(5, len(x_centers)//4)))
        frame_index = 0
        applied_x_center_px = None
        beta = 0.85  # amortissement (0.85 = trÃ¨s smooth)
        def crop_frame(frame):
            nonlocal frame_index
            nonlocal applied_x_center_px
            h, w, _ = frame.shape
            if frame_index < len(x_centers_smooth):
                x_target_px = x_centers_smooth[frame_index] * w
            else:
                x_target_px = w * 0.5
            frame_index += 1
            # Initialisation EMA
            if applied_x_center_px is None:
                applied_x_center_px = x_target_px
            # Clamp vitesse de dÃ©placement + deadband
            shift = x_target_px - applied_x_center_px
            deadband_px = w * 0.003
            if abs(shift) < deadband_px:
                shift = 0.0
            max_shift_px = w * 0.02
            if shift > max_shift_px:
                shift = max_shift_px
            elif shift < -max_shift_px:
                shift = -max_shift_px
            x_clamped = applied_x_center_px + shift
            # EMA amorti
            applied_x_center_px = beta * applied_x_center_px + (1 - beta) * x_clamped
            
            # ğŸš¨ CORRECTION BUG: Forcer des dimensions paires pour H.264
            target_width = Config.TARGET_WIDTH
            target_height = Config.TARGET_HEIGHT
            
            # Calcul du crop avec ratio 9:16
            crop_width = int(target_width * h / target_height)
            crop_width = min(crop_width, w)
            
            # ğŸš¨ CORRECTION: S'assurer que crop_width est pair
            if crop_width % 2 != 0:
                crop_width = crop_width - 1 if crop_width > 1 else crop_width + 1
            
            x1 = int(max(0, min(w - crop_width, applied_x_center_px - crop_width / 2)))
            x2 = x1 + crop_width
            cropped = frame[:, x1:x2]
            
            # ğŸš¨ CORRECTION: S'assurer que les dimensions finales sont paires
            final_width = target_width
            final_height = target_height
            
            # VÃ©rifier et corriger si nÃ©cessaire
            if final_width % 2 != 0:
                final_width = final_width - 1 if final_width > 1 else final_width + 1
            if final_height % 2 != 0:
                final_height = final_height - 1 if final_height > 1 else final_height + 1
            
            return cv2.resize(cropped, (final_width, final_height), interpolation=cv2.INTER_LANCZOS4)
        reframed = video.fl_image(crop_frame)
        output_path = Config.TEMP_FOLDER / f"reframed_{clip_path.name}"
        try:
            # Prefer AMD AMF hardware encoder on this system; boost quality slightly with QP=18
            reframed.write_videofile(
                str(output_path),
                fps=fps,
                codec='h264_nvenc',
                audio_codec='aac',
                verbose=False,
                logger=None,
                preset=None,
                ffmpeg_params=['-rc','vbr','-cq','19','-b:v','0','-maxrate','0','-pix_fmt','yuv420p','-movflags','+faststart']
            )
        except Exception:
            # Fallback to CPU x264 with stable CRF
            reframed.write_videofile(
                str(output_path),
                fps=fps,
                codec='libx264',
                audio_codec='aac',
                verbose=False,
                logger=None,
                preset='medium',
                ffmpeg_params=['-pix_fmt','yuv420p','-movflags','+faststart','-crf','20']
            )
        video.close(); reframed.close()
        print("    âœ… Reframe terminÃ©")
        return output_path
    
    def transcribe_audio(self, video_path: Path) -> str:
        """Transcription avec Whisper"""
        logger.info("ğŸ“ Transcription audio avec Whisper")
        print("    ğŸ“ Transcription Whisper en cours...")
        
        result = self.whisper_model.transcribe(str(video_path))
        print("    âœ… Transcription terminÃ©e")
        return result["text"]
    
    def transcribe_segments(self, video_path: Path) -> List[Dict]:
        """
        Transcrit l'audio en segments avec timestamps (sans rendu visuel).
        Retourne une liste de segments {'text', 'start', 'end'} et conserve les mots si fournis.
        """
        logger.info("â±ï¸ Transcription avec timestamps")
        print("    â±ï¸ GÃ©nÃ©ration des timestamps...")
        result = self.whisper_model.transcribe(str(video_path), word_timestamps=True)
        bias = getattr(Config, 'SUBTITLE_TIMING_BIAS_S', 0.0)
        subtitles: List[Dict] = []
        for segment in result.get("segments", []):
            seg_start = max(0.0, (segment.get("start") or 0.0) + bias)
            seg_end = max(seg_start, (segment.get("end") or seg_start) + bias)
            subtitle: Dict = {
                "text": (segment.get("text") or "").strip(),
                "start": seg_start,
                "end": seg_end
            }
            words = segment.get("words")
            if words:
                precise_words = []
                for w in words:
                    ws = max(0.0, (w.get("start") or seg_start) + bias)
                    we = max(ws, (w.get("end") or ws) + bias)
                    wt = (w.get("word") or w.get("text") or "").strip()
                    if wt:
                        precise_words.append({"text": wt, "start": ws, "end": we})
                if precise_words:
                    subtitle["words"] = precise_words
            subtitles.append(subtitle)
        print(f"    âœ… {len(subtitles)} segments de sous-titres gÃ©nÃ©rÃ©s")
        return subtitles

    def generate_caption_and_hashtags(self, subtitles: List[Dict]) -> (str, str, List[str], List[str]):
        """GÃ©nÃ¨re une lÃ©gende, des hashtags et des mots-clÃ©s B-roll. PrivilÃ©gie le LLM local si disponible, sinon heuristique."""
        full_text = ' '.join(s.get('text', '') for s in subtitles)
        # Try LLM first
        llm_res = _llm_generate_caption_hashtags(full_text)
        if llm_res and (llm_res.get('title') or llm_res.get('description') or llm_res.get('hashtags')):
            title = (llm_res.get('title') or '').strip()
            description = (llm_res.get('description') or '').strip()
            hashtags = [h for h in (llm_res.get('hashtags') or []) if h]
            
            # ğŸš€ NOUVEAU: Extraction des mots-clÃ©s B-roll du LLM
            broll_keywords = llm_res.get('broll_keywords', [])
            if broll_keywords:
                print(f"    ğŸ¤– [LLM] Titre/description/hashtags + {len(broll_keywords)} mots-clÃ©s B-roll gÃ©nÃ©rÃ©s par LLM local")
                print(f"    ğŸ¯ Mots-clÃ©s B-roll LLM: {', '.join(broll_keywords[:8])}...")
            else:
                print("    ğŸ¤– [LLM] Titre/description/hashtags gÃ©nÃ©rÃ©s par LLM local")
                # Fallback: extraire des mots-clÃ©s basiques du titre et de la description
                fallback_text = f"{title} {description}".lower()
                broll_keywords = [word for word in fallback_text.split() if len(word) > 3 and word.isalpha()]
                broll_keywords = list(set(broll_keywords))[:10]
                print(f"    ğŸ”„ Fallback mots-clÃ©s B-roll: {', '.join(broll_keywords[:5])}...")
            
            # Back-compat: si titre vide mais description prÃ©sente, promouvoir description en titre court
            if not title and description:
                title = (description[:60] + ('â€¦' if len(description) > 60 else ''))
            return title, description, hashtags, broll_keywords
        
        # Fallback heuristic
        words = [w.strip().lower() for w in re.split(r"[^a-zA-Z0-9Ã©Ã¨Ã Ã¹Ã§ÃªÃ®Ã´Ã¢]+", full_text) if len(w) > 2]
        from collections import Counter
        counts = Counter(words)
        common = [w for w,_ in counts.most_common(12) if w.isalpha()]
        hashtags = [f"#{w}" for w in common[:12]]
        
        # ğŸš€ NOUVEAU: Mots-clÃ©s B-roll de fallback basÃ©s sur les mots communs
        broll_keywords = [w for w in common if len(w) > 3][:15]
        
        # Heuristic title/description
        title = (full_text.strip()[:60] + ("â€¦" if len(full_text.strip()) > 60 else "")) if full_text.strip() else ""
        description = (full_text.strip()[:180] + ("â€¦" if len(full_text.strip()) > 180 else "")) if full_text.strip() else ""
        print("    ğŸ§© [Heuristics] Meta gÃ©nÃ©rÃ©es en fallback")
        print(f"    ğŸ”‘ Mots-clÃ©s B-roll fallback: {', '.join(broll_keywords[:5])}...")
        return title, description, hashtags, broll_keywords

    def insert_brolls_if_enabled(self, input_path: Path, subtitles: List[Dict], broll_keywords: List[str]) -> Path:
        """Point d'extension B-roll: retourne le chemin vidÃ©o aprÃ¨s insertion si activÃ©e."""
        if not getattr(Config, 'ENABLE_BROLL', False):
            print("    â­ï¸ B-roll dÃ©sactivÃ©s: aucune insertion")
            return input_path
        
        try:
            # VÃ©rifier la librairie B-roll
            broll_root = Path("AI-B-roll")
            broll_library = broll_root / "broll_library"
            if not broll_library.exists():
                print("    âš ï¸ Librairie B-roll introuvable, saut de l'insertion")
                return input_path
            # PrÃ©parer chemins (Ã©crire directement dans le dossier du clip si possible)
            clip_dir = (Path(input_path).parent if (Path(input_path).name == 'reframed.mp4') else Config.TEMP_FOLDER)
            # Si input_path est dÃ©jÃ  dans un dossier clip (reframed.mp4), sortir with_broll.mp4 Ã  cÃ´tÃ©
            if Path(input_path).name == 'reframed.mp4':
                output_with_broll = clip_dir / 'with_broll.mp4'
            else:
                output_with_broll = Config.TEMP_FOLDER / f"with_broll_{Path(input_path).name}"
            output_with_broll.parent.mkdir(parents=True, exist_ok=True)
            
            # Assurer l'import du pipeline local (src/*)
            if str(broll_root.resolve()) not in sys.path:
                sys.path.insert(0, str(broll_root.resolve()))
            
            # ğŸš€ NOUVEAUX IMPORTS INTELLIGENTS SYNCHRONES
            try:
                from sync_context_analyzer import SyncContextAnalyzer
                from broll_diversity_manager import BrollDiversityManager
                INTELLIGENT_BROLL_AVAILABLE = True
                print("    ğŸ§  SYSTÃˆME B-ROLL INTELLIGENT SYNCHRONE ACTIVÃ‰ !")
            except ImportError as e:
                print(f"    âš ï¸  SystÃ¨me intelligent non disponible: {e}")
                print("    ğŸ”„ Fallback vers ancien systÃ¨me...")
                INTELLIGENT_BROLL_AVAILABLE = False
            
            # Imports B-roll dans tous les cas
            from src.pipeline.config import BrollConfig  # type: ignore
            from src.pipeline.keyword_extraction import extract_keywords_for_segment  # type: ignore
            from src.pipeline.timeline_legacy import plan_broll_insertions, normalize_timeline, enrich_keywords  # type: ignore
            from src.pipeline.renderer import render_video  # type: ignore
            from src.pipeline.transcription import TranscriptSegment  # type: ignore
            
            from moviepy.editor import VideoFileClip as _VFC
            # Optionnel: indexation FAISS/CLIP
            try:
                from src.pipeline.indexer import build_index  # type: ignore
                index_handle = None
            except Exception:
                build_index = None  # type: ignore
                index_handle = None
            
            # ğŸ§  ANALYSE INTELLIGENTE AVANCÃ‰E
            if INTELLIGENT_BROLL_AVAILABLE:
                print("    ğŸ§  Utilisation du systÃ¨me B-roll intelligent...")
                try:
                    # Initialiser l'analyseur contextuel intelligent SYNCHRONE
                    context_analyzer = SyncContextAnalyzer()
                    
                    # Analyser le contexte global de la vidÃ©o
                    transcript_text = " ".join([s.get('text', '') for s in subtitles])
                    global_analysis = context_analyzer.analyze_context(transcript_text)
                    
                    print(f"    ğŸ¯ Contexte dÃ©tectÃ©: {global_analysis.main_theme}")
                    print(f"    ğŸ§¬ Sujets: {', '.join(global_analysis.key_topics[:3])}")
                    print(f"    ğŸ˜Š Sentiment: {global_analysis.sentiment}")
                    print(f"    ğŸ“Š ComplexitÃ©: {global_analysis.complexity}")
                    print(f"    ğŸ”‘ Mots-clÃ©s: {', '.join(global_analysis.keywords[:5])}")
                    
                    # Persister l'analyse intelligente
                    try:
                        meta_dir = Config.OUTPUT_FOLDER / 'meta'
                        meta_dir.mkdir(parents=True, exist_ok=True)
                        meta_path = meta_dir / f"{Path(input_path).stem}_intelligent_broll_metadata.json"
                        with open(meta_path, 'w', encoding='utf-8') as f:
                            json.dump({
                                'intelligent_analysis': {
                                    'main_theme': global_analysis.main_theme,
                                    'key_topics': global_analysis.key_topics,
                                    'sentiment': global_analysis.sentiment,
                                    'complexity': global_analysis.complexity,
                                    'keywords': global_analysis.keywords,
                                    'context_score': global_analysis.context_score
                                },
                                'timestamp': str(datetime.now())
                            }, f, ensure_ascii=False, indent=2)
                        print(f"    ğŸ’¾ MÃ©tadonnÃ©es intelligentes sauvegardÃ©es: {meta_path}")
                        
                        # ğŸ¬ INSÃ‰RATION INTELLIGENTE DES B-ROLLS
                        print("    ğŸ¬ Insertion intelligente des B-rolls...")
                        try:
                            # CrÃ©er un dossier unique pour ce clip
                            clip_id = input_path.stem
                            unique_broll_dir = broll_library / f"clip_intelligent_{clip_id}_{int(time.time())}"
                            unique_broll_dir.mkdir(parents=True, exist_ok=True)
                            
                            # GÃ©nÃ©rer des prompts intelligents basÃ©s sur l'analyse
                            intelligent_prompts = []
                            main_theme = global_analysis.main_theme
                            kws = _filter_prompt_terms(global_analysis.keywords[:6]) if hasattr(global_analysis, 'keywords') else []
                            if main_theme == 'technology':
                                intelligent_prompts.extend([
                                    'artificial intelligence neural network',
                                    'computer vision algorithm',
                                    'tech innovation future'
                                ])
                            elif main_theme == 'medical':
                                intelligent_prompts.extend([
                                    'medical research laboratory',
                                    'healthcare innovation hospital',
                                    'microscope scientific discovery'
                                ])
                            elif main_theme == 'business':
                                intelligent_prompts.extend([
                                    'business success growth',
                                    'entrepreneurship motivation',
                                    'professional development office'
                                ])
                            elif main_theme == 'neuroscience':
                                intelligent_prompts.extend([
                                    'neuroscience brain neurons synapse',
                                    'brain reflexes nervous system',
                                    'brain scan mri eeg lab'
                                ])
                            else:
                                base = _filter_prompt_terms([main_theme] + kws)
                                intelligent_prompts.extend([f"{main_theme} {kw}" for kw in base[:3]])

                            # Ajouter variantes from cleaned keywords
                            for kw in kws[:3]:
                                intelligent_prompts.append(f"{main_theme} {kw}")

                            # Dedup and trim
                            seen_ip = set()
                            intelligent_prompts = [p for p in intelligent_prompts if not (p in seen_ip or seen_ip.add(p))][:8]

                            print(f"    ğŸ¯ Prompts intelligents gÃ©nÃ©rÃ©s: {', '.join(intelligent_prompts[:3])}")
                            
                            # Utiliser l'ancien systÃ¨me mais avec les prompts intelligents
                            # (temporaire en attendant l'intÃ©gration complÃ¨te)
                            print("    ğŸ”„ Utilisation du systÃ¨me B-roll avec prompts intelligents...")
                            
                        except Exception as e:
                            print(f"    âš ï¸  Erreur insertion intelligente: {e}")
                            print("    ğŸ”„ Fallback vers ancien systÃ¨me...")
                            INTELLIGENT_BROLL_AVAILABLE = False
                            
                    except Exception as e:
                        print(f"    âš ï¸  Erreur systÃ¨me intelligent: {e}")
                        print("    ğŸ”„ Fallback vers ancien systÃ¨me...")
                        INTELLIGENT_BROLL_AVAILABLE = False
                except Exception as e:
                    print(f"    âš ï¸  Erreur systÃ¨me intelligent: {e}")
                    print("    ğŸ”„ Fallback vers ancien systÃ¨me...")
                    INTELLIGENT_BROLL_AVAILABLE = False
                    
            # Fallback: ancienne analyse si systÃ¨me intelligent indisponible
            if not INTELLIGENT_BROLL_AVAILABLE:
                print("    ğŸ”„ Utilisation de l'ancien systÃ¨me B-roll...")
                analysis = extract_keywords_from_transcript_ai(subtitles)
                prompts = generate_broll_prompts_ai(analysis)
                # Filtrer les prompts fallback
                try:
                    cleaned_prompts = []
                    for p in prompts:
                        tokens = _filter_prompt_terms(str(p).split())
                        if tokens:
                            cleaned_prompts.append(' '.join(tokens))
                    if cleaned_prompts:
                        prompts = cleaned_prompts
                except Exception:
                    pass
                # Persiste metadata dans un dossier clip dÃ©diÃ© si possible
                try:
                    meta_dir = Config.OUTPUT_FOLDER / 'meta'
                    meta_dir.mkdir(parents=True, exist_ok=True)
                    meta_path = meta_dir / f"{Path(input_path).stem}_broll_metadata.json"
                    with open(meta_path, 'w', encoding='utf-8') as f:
                        json.dump({'analysis': analysis, 'prompts': prompts}, f, ensure_ascii=False, indent=2)
                except Exception:
                    pass
            else:
                # ğŸ¯ UTILISER LES PROMPTS INTELLIGENTS
                print("    ğŸ¯ Utilisation des prompts intelligents pour B-rolls...")
                try:
                    # CrÃ©er une analyse basÃ©e sur l'analyse intelligente
                    analysis = {
                        'main_theme': global_analysis.main_theme,
                        'key_topics': global_analysis.key_topics,
                        'sentiment': global_analysis.sentiment,
                        'keywords': global_analysis.keywords
                    }
                    
                    # Utiliser les prompts intelligents gÃ©nÃ©rÃ©s
                    prompts = intelligent_prompts if 'intelligent_prompt' in locals() else [
                        f"{global_analysis.main_theme} {kw}" for kw in global_analysis.keywords[:3]
                    ]
                    
                    print(f"    ğŸ¯ Prompts utilisÃ©s: {', '.join(prompts[:3])}")
                    
                except Exception as e:
                    print(f"    âš ï¸  Erreur prompts intelligents: {e}")
                    # Fallback vers prompts gÃ©nÃ©riques
                    analysis = extract_keywords_from_transcript_ai(subtitles)
                    prompts = generate_broll_prompts_ai(analysis)
            
            # ğŸš€ NOUVEAU: IntÃ©gration des mots-clÃ©s B-roll du LLM
            # RÃ©cupÃ©rer les mots-clÃ©s B-roll gÃ©nÃ©rÃ©s par le LLM (si disponibles)
            llm_broll_keywords = []
            try:
                # Les mots-clÃ©s B-roll sont dÃ©jÃ  disponibles depuis generate_caption_and_hashtags
                # Ils sont passÃ©s via la variable broll_keywords dans le scope parent
                if 'broll_keywords' in locals():
                    llm_broll_keywords = broll_keywords
                    print(f"    ğŸ§  Mots-clÃ©s B-roll LLM intÃ©grÃ©s: {len(llm_broll_keywords)} termes")
                    print(f"    ğŸ¯ Exemples: {', '.join(llm_broll_keywords[:5])}")
                else:
                    print("    âš ï¸ Mots-clÃ©s B-roll LLM non disponibles")
            except Exception as e:
                print(f"    âš ï¸ Erreur rÃ©cupÃ©ration mots-clÃ©s B-roll LLM: {e}")
            
            # Combiner les mots-clÃ©s LLM avec les prompts existants
            if llm_broll_keywords:
                # Enrichir les prompts avec les mots-clÃ©s LLM
                enhanced_prompts = []
                for kw in llm_broll_keywords[:8]:  # Limiter Ã  8 mots-clÃ©s principaux
                    enhanced_prompts.append(kw)
                    # CrÃ©er des combinaisons avec le thÃ¨me principal
                    if 'global_analysis' in locals() and hasattr(global_analysis, 'main_theme'):
                        enhanced_prompts.append(f"{global_analysis.main_theme} {kw}")
                
                # Ajouter les prompts existants
                enhanced_prompts.extend(prompts)
                
                # DÃ©dupliquer et limiter
                seen_prompts = set()
                final_prompts = []
                for p in enhanced_prompts:
                    if p not in seen_prompts and len(p) > 2:
                        final_prompts.append(p)
                        seen_prompts.add(p)
                
                prompts = final_prompts[:12]  # Limiter Ã  12 prompts finaux
                print(f"    ğŸš€ Prompts enrichis avec LLM: {len(prompts)} termes")
                print(f"    ğŸ¯ Prompts finaux: {', '.join(prompts[:5])}...")
            
            # Convertir nos sous-titres en segments attendus par le pipeline
            segments = [
                TranscriptSegment(start=float(s.get('start', 0.0)), end=float(s.get('end', 0.0)), text=str(s.get('text', '')).strip())
                for s in subtitles if (s.get('text') and (s.get('end', 0.0) >= s.get('start', 0.0)))
            ]
            if not segments:
                print("    âš ï¸ Aucun segment de transcription valide, saut B-roll")
                return input_path
            
            # Construire la config du pipeline (fetch + embeddings activÃ©s, pas de limites)
            cfg = BrollConfig(
                input_video=str(input_path),
                output_video=output_with_broll,
                broll_library=broll_library,
                srt_path=None,
                render_subtitles=False,
                            max_broll_ratio=0.65,           # CORRIGÃ‰: 90% â†’ 65% pour Ã©quilibre optimal
            min_gap_between_broll_s=1.5,    # CORRIGÃ‰: 0.2s â†’ 1.5s pour respiration visuelle
                            max_broll_clip_s=4.0,           # CORRIGÃ‰: 8.0s â†’ 4.0s pour B-rolls Ã©quilibrÃ©s
            min_broll_clip_s=2.0,           # CORRIGÃ‰: 3.5s â†’ 2.0s pour durÃ©e optimale
                use_whisper=False,
                ffmpeg_preset="fast",
                crf=23,
                threads=0,
                # Fetchers (stock)
                enable_fetcher=getattr(Config, 'BROLL_FETCH_ENABLE', False),
                fetch_provider=getattr(Config, 'BROLL_FETCH_PROVIDER', 'pexels'),
                pexels_api_key=getattr(Config, 'PEXELS_API_KEY', None),
                pixabay_api_key=getattr(Config, 'PIXABAY_API_KEY', None),
                fetch_max_per_keyword=getattr(Config, 'BROLL_FETCH_MAX_PER_KEYWORD', 25),  # CORRIGÃ‰: 50 â†’ 25 pour qualitÃ© optimale
                fetch_allow_videos=getattr(Config, 'BROLL_FETCH_ALLOW_VIDEOS', True),
                fetch_allow_images=getattr(Config, 'BROLL_FETCH_ALLOW_IMAGES', True),  # ActivÃ©: images animÃ©es + Ken Burns
                # Embeddings
                use_embeddings=getattr(Config, 'BROLL_USE_EMBEDDINGS', True),
                embedding_model_name=getattr(Config, 'BROLL_EMBEDDING_MODEL', 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'),
                contextual_config_path=getattr(Config, 'CONTEXTUAL_CONFIG_PATH', Path('config/contextual_broll.yml')),
                # Experimental FX toggle
                enable_experimental_fx=getattr(Config, 'ENABLE_EXPERIMENTAL_FX', False),
            )
            # FETCH DYNAMIQUE PAR CLIP: CrÃ©er un dossier unique et forcer le fetch Ã  chaque fois
            try:
                from src.pipeline.fetchers import ensure_assets_for_keywords  # type: ignore
                
                # CrÃ©er un dossier unique pour ce clip (Ã©viter le partage entre clips)
                clip_id = input_path.stem  # Nom du fichier sans extension
                clip_broll_dir = broll_library / f"clip_{clip_id}_{int(time.time())}"
                clip_broll_dir.mkdir(parents=True, exist_ok=True)
                
                # Forcer l'activation du fetcher pour chaque clip
                setattr(cfg, 'enable_fetcher', True)
                setattr(cfg, 'broll_library', str(clip_broll_dir))  # Utiliser le dossier unique
                
                print(f"    ğŸ”„ Fetch B-roll personnalisÃ© pour clip: {clip_id}")
                print(f"    ğŸ“ Dossier B-roll unique: {clip_broll_dir.name}")
                
                # ğŸš€ NOUVEAU: IntÃ©gration du sÃ©lecteur B-roll gÃ©nÃ©rique
                if BROLL_SELECTOR_AVAILABLE and getattr(Config, 'BROLL_SELECTOR_ENABLED', True):
                    try:
                        print("    ğŸ¯ SÃ©lecteur B-roll gÃ©nÃ©rique activÃ© - Scoring mixte intelligent")
                        
                        # Initialiser le sÃ©lecteur avec la configuration
                        selector_config = None
                        if getattr(Config, 'BROLL_SELECTOR_CONFIG_PATH', None):
                            try:
                                import yaml
                                with open(Config.BROLL_SELECTOR_CONFIG_PATH, 'r', encoding='utf-8') as f:
                                    selector_config = yaml.safe_load(f)
                                print(f"    âš™ï¸ Configuration chargÃ©e: {Config.BROLL_SELECTOR_CONFIG_PATH}")
                            except Exception as e:
                                print(f"    âš ï¸ Erreur chargement config: {e}")
                        
                        # CrÃ©er le sÃ©lecteur
                        from broll_selector import BrollSelector
                        broll_selector = BrollSelector(selector_config)
                        
                        # Analyser le contexte pour la sÃ©lection intelligente
                        context_keywords = []
                        if 'global_analysis' in locals():
                            context_keywords = global_analysis.keywords[:10] if hasattr(global_analysis, 'keywords') else []
                        else:
                            # Fallback vers extraction basique
                            for s in subtitles:
                                text = s.get('text', '')
                                if text:
                                    words = text.lower().split()
                                    context_keywords.extend([w for w in words if len(w) > 3 and w.isalpha()])
                        
                        # DÃ©tecter le domaine
                        detected_domain = None
                        if 'global_analysis' in locals() and hasattr(global_analysis, 'main_theme'):
                            detected_domain = global_analysis.main_theme
                        
                        print(f"    ğŸ¯ Contexte: {detected_domain or 'gÃ©nÃ©ral'}")
                        print(f"    ğŸ”‘ Mots-clÃ©s contextuels: {', '.join(context_keywords[:5])}")
                        
                        # Utiliser le sÃ©lecteur pour la planification
                        selection_report = broll_selector.select_brolls(
                            keywords=context_keywords,
                            domain=detected_domain,
                            min_delay=self._load_broll_selector_config().get('thresholds', {}).get('min_delay_seconds', 4.0),
                            desired_count=self._load_broll_selector_config().get('desired_broll_count', 3)
                        )
                        
                        # Sauvegarder le rapport de sÃ©lection
                        try:
                            meta_dir = Config.OUTPUT_FOLDER / 'meta'
                            meta_dir.mkdir(parents=True, exist_ok=True)
                            selection_report_path = meta_dir / f"{Path(input_path).stem}_broll_selection_report.json"
                            with open(selection_report_path, 'w', encoding='utf-8') as f:
                                json.dump(selection_report, f, ensure_ascii=False, indent=2)
                            print(f"    ğŸ’¾ Rapport de sÃ©lection sauvegardÃ©: {selection_report_path}")
                        except Exception as e:
                            print(f"    âš ï¸ Erreur sauvegarde rapport: {e}")
                        
                        # Afficher les statistiques de sÃ©lection
                        if 'diagnostics' in selection_report:
                            diag = selection_report['diagnostics']
                            print(f"    ğŸ“Š SÃ©lection: {diag.get('num_selected', 0)}/{diag.get('num_candidates', 0)} B-rolls")
                            print(f"    ğŸ¯ Top score: {diag.get('top_score', 0):.3f}")
                            print(f"    ğŸ“ Seuil appliquÃ©: {diag.get('min_score', 0):.3f}")
                        
                        if selection_report.get('fallback_used'):
                            print(f"    ğŸ†˜ Fallback activÃ©: Tier {selection_report.get('fallback_tier', '?')}")
                        
                    except Exception as e:
                        print(f"    âš ï¸ Erreur sÃ©lecteur gÃ©nÃ©rique: {e}")
                        print("    ğŸ”„ Fallback vers systÃ¨me existant")
                
                # ğŸš€ CORRECTION: IntÃ©gration des mots-clÃ©s LLM pour le fetch
                # SÃ‰LECTION INTELLIGENTE: Mots-clÃ©s contextuels + concepts associÃ©s
                from collections import Counter as _Counter
                kw_pool: list[str] = []
                
                # ğŸ§  PRIORITÃ‰ 1: Mots-clÃ©s LLM si disponibles
                if 'broll_keywords' in locals() and broll_keywords:
                    print(f"    ğŸš€ Utilisation des mots-clÃ©s LLM pour le fetch: {len(broll_keywords)} termes")
                    # Ajouter TOUS les mots-clÃ©s LLM en prioritÃ©
                    for kw in broll_keywords:
                        low = (kw or '').strip().lower()
                        if low and len(low) >= 3:
                            kw_pool.append(low)
                            # Ajouter des variations pour enrichir
                            if ' ' in low:  # Mots composÃ©s
                                parts = low.split()
                                kw_pool.extend(parts)
                    
                    print(f"    ğŸ¯ Mots-clÃ©s LLM ajoutÃ©s: {', '.join(broll_keywords[:8])}")
                
                # ğŸ”„ PRIORITÃ‰ 2: Extraction des mots-clÃ©s du transcript
                for s in subtitles:
                    base_kws = extract_keywords_for_segment(s.get('text','')) or []
                    spacy_kws = self._extract_keywords_for_segment_spacy(s.get('text','')) or []
                    for kw in (base_kws + spacy_kws):
                        low = (kw or '').strip().lower()
                        if low and len(low) >= 3:
                            kw_pool.append(low)
                
                # ğŸš€ CONCEPTS ASSOCIÃ‰S ENRICHIS (50+ concepts)
                concept_mapping = {
                    # ğŸ§  Cerveau & Intelligence
                    'brain': ['neuroscience', 'mind', 'thinking', 'intelligence', 'cognitive', 'mental', 'psychology', 'consciousness'],
                    'mind': ['brain', 'thinking', 'thought', 'intelligence', 'cognitive', 'mental', 'psychology'],
                    'thinking': ['brain', 'mind', 'thought', 'intelligence', 'cognitive', 'mental', 'logic'],
                    
                    # ğŸ’° Argent & Finance
                    'money': ['finance', 'business', 'success', 'wealth', 'investment', 'cash', 'profit', 'revenue'],
                    'argent': ['finance', 'business', 'success', 'wealth', 'investment', 'cash', 'profit', 'revenue'],
                    'finance': ['money', 'business', 'investment', 'wealth', 'profit', 'revenue', 'budget'],
                    
                    # ğŸ¯ Focus & Concentration
                    'focus': ['concentration', 'productivity', 'attention', 'mindfulness', 'clarity', 'precision'],
                    'concentration': ['focus', 'attention', 'mindfulness', 'clarity', 'precision', 'dedication'],
                    'attention': ['focus', 'concentration', 'mindfulness', 'awareness', 'observation'],
                    
                    # ğŸ† SuccÃ¨s & RÃ©ussite
                    'success': ['achievement', 'goal', 'victory', 'winning', 'growth', 'accomplishment', 'triumph'],
                    'succÃ¨s': ['achievement', 'goal', 'victory', 'winning', 'growth', 'accomplishment', 'triumph'],
                    'victory': ['success', 'achievement', 'winning', 'triumph', 'conquest', 'domination'],
                    
                    # â¤ï¸ SantÃ© & Bien-Ãªtre
                    'health': ['wellness', 'fitness', 'medical', 'lifestyle', 'nutrition', 'vitality', 'strength'],
                    'santÃ©': ['wellness', 'fitness', 'medical', 'lifestyle', 'nutrition', 'vitality', 'strength'],
                    'fitness': ['health', 'wellness', 'exercise', 'training', 'strength', 'endurance'],
                    
                    # ğŸ¤– Technologie & Innovation
                    'technology': ['digital', 'innovation', 'future', 'ai', 'automation', 'tech', 'modern'],
                    'technologie': ['digital', 'innovation', 'future', 'ai', 'automation', 'tech', 'modern'],
                    'innovation': ['technology', 'digital', 'future', 'ai', 'automation', 'creativity', 'progress'],
                    
                    # ğŸ’¼ Business & Entreprise
                    'business': ['entrepreneur', 'startup', 'strategy', 'leadership', 'growth', 'company', 'enterprise'],
                    'entreprise': ['entrepreneur', 'startup', 'strategy', 'leadership', 'growth', 'company', 'enterprise'],
                    'strategy': ['business', 'planning', 'tactics', 'approach', 'method', 'system'],
                    
                    # ğŸš€ Action & Dynamisme
                    'action': ['movement', 'energy', 'power', 'vitality', 'dynamism', 'activity', 'motion'],
                    'action': ['movement', 'energy', 'power', 'vitality', 'dynamism', 'activity', 'motion'],
                    'energy': ['power', 'vitality', 'strength', 'force', 'intensity', 'enthusiasm'],
                    
                    # ğŸ”¥ Ã‰motion & Passion
                    'emotion': ['feeling', 'passion', 'excitement', 'inspiration', 'motivation', 'enthusiasm'],
                    'Ã©motion': ['feeling', 'passion', 'excitement', 'inspiration', 'motivation', 'enthusiasm'],
                    'passion': ['emotion', 'feeling', 'excitement', 'inspiration', 'motivation', 'enthusiasm'],
                    
                    # ğŸ§  DÃ©veloppement Personnel
                    'growth': ['development', 'improvement', 'progress', 'advancement', 'evolution', 'maturity'],
                    'croissance': ['development', 'improvement', 'progress', 'advancement', 'evolution', 'maturity'],
                    'development': ['growth', 'improvement', 'progress', 'advancement', 'evolution', 'maturity'],
                    
                    # âœ… Solutions & RÃ©solution
                    'solution': ['resolution', 'fix', 'answer', 'remedy', 'cure', 'treatment'],
                    'solution': ['resolution', 'fix', 'answer', 'remedy', 'cure', 'treatment'],
                    'resolution': ['solution', 'fix', 'answer', 'remedy', 'cure', 'treatment'],
                    
                    # âš ï¸ ProblÃ¨mes & DÃ©fis
                    'problem': ['challenge', 'difficulty', 'obstacle', 'barrier', 'issue', 'trouble'],
                    'problÃ¨me': ['challenge', 'difficulty', 'obstacle', 'barrier', 'issue', 'trouble'],
                    'challenge': ['problem', 'difficulty', 'obstacle', 'barrier', 'issue', 'trouble'],
                    
                    # ğŸŒŸ QualitÃ© & Excellence
                    'quality': ['excellence', 'perfection', 'superiority', 'premium', 'best', 'optimal'],
                    'qualitÃ©': ['excellence', 'perfection', 'superiority', 'premium', 'best', 'optimal'],
                    'excellence': ['quality', 'perfection', 'superiority', 'premium', 'best', 'optimal']
                }
                
                # Enrichir avec des concepts associÃ©s
                for kw in kw_pool[:]:
                    for concept, related in concept_mapping.items():
                        if concept in kw or any(r in kw for r in related):
                            kw_pool.extend(related[:2])  # Ajouter 2 concepts max
                
                counts = _Counter(kw_pool)
                
                # ğŸš¨ CORRECTION CRITIQUE: PRIORISER les mots-clÃ©s LLM sur les mots-clÃ©s gÃ©nÃ©riques
                if 'broll_keywords' in locals() and broll_keywords:
                    # Utiliser DIRECTEMENT les mots-clÃ©s LLM comme requÃªte principale
                    llm_keywords = [kw.strip().lower() for kw in broll_keywords if kw and len(kw.strip()) >= 3]
                    if llm_keywords:
                        # Prendre les 8 premiers mots-clÃ©s LLM + 2 concepts associÃ©s
                        top_kws = llm_keywords[:8]
                        # Ajouter quelques concepts associÃ©s pour enrichir
                        for kw in top_kws[:3]:  # Pour les 3 premiers mots-clÃ©s LLM
                            for concept, related in concept_mapping.items():
                                if concept in kw or any(r in kw for r in related):
                                    top_kws.extend(related[:1])  # 1 concept max par mot-clÃ© LLM
                                    break
                        print(f"    ğŸš€ REQUÃŠTE LLM PRIORITAIRE: {' '.join(top_kws[:5])}")
                    else:
                        top_kws = [w for w,_n in counts.most_common(15)]
                        print(f"    ğŸ”„ Fallback vers mots-clÃ©s gÃ©nÃ©riques: {' '.join(top_kws[:5])}")
                else:
                    top_kws = [w for w,_n in counts.most_common(15)]
                    print(f"    ğŸ”„ Mots-clÃ©s gÃ©nÃ©riques: {' '.join(top_kws[:5])}")
                
                # Fallback intelligent selon le contexte
                if not top_kws:
                    top_kws = ["focus","concentration","study","brain","mind","productivity","success"]
                print(f"    ğŸ” Fetch B-roll sur requÃªte: {' '.join(top_kws[:5])}")
                # Provider auto-fallback si pas de clÃ©s -> archive
                import os as _os
                pex = getattr(Config, 'PEXELS_API_KEY', None) or _os.getenv('PEXELS_API_KEY')
                pixa = getattr(Config, 'PIXABAY_API_KEY', None) or _os.getenv('PIXABAY_API_KEY')
                uns = getattr(Config, 'UNSPLASH_ACCESS_KEY', None) or _os.getenv('UNSPLASH_ACCESS_KEY')
                giphy = _os.getenv('GIPHY_API_KEY')  # ğŸ­ GIPHY pour GIFs animÃ©s
                # Exposer l'accÃ¨s Unsplash dans la cfg si dispo
                try:
                    if uns:
                        setattr(cfg, 'unsplash_access_key', uns)
                except Exception:
                    pass
                if not any([pex, pixa, uns]):
                    try:
                        setattr(cfg, 'fetch_provider', 'archive')
                        print("    ğŸŒ Providers: archive (aucune clÃ© API dÃ©tectÃ©e)")
                    except Exception:
                        pass
                else:
                    # ğŸš€ AMÃ‰LIORATION: Construire une liste de providers optimisÃ©e
                    prov = []
                    if pex:
                        prov.append('pexels')
                    if pixa:
                        prov.append('pixabay')
                    if uns:
                        prov.append('unsplash')
                    if giphy:
                        prov.append('giphy')  # ğŸ­ GIPHY pour GIFs animÃ©s
                    
                    # ğŸ¯ AJOUT SÃ‰CURISÃ‰: Archive.org comme source supplÃ©mentaire
                    try:
                        if prov:  # Si on a des providers avec clÃ©s API
                            prov.append('archive')  # Ajouter Archive.org
                            print(f"    ğŸŒ Providers: {','.join(prov)} (Archive.org + Giphy ajoutÃ©s pour variÃ©tÃ©)")
                        else:
                            prov = ['archive']  # Seulement Archive.org si pas de clÃ©s
                            print(f"    ğŸŒ Providers: {','.join(prov)} (Archive.org uniquement)")
                        
                        setattr(cfg, 'fetch_provider', ",".join(prov))
                    except Exception as e:
                        # Fallback sÃ©curisÃ©
                        try:
                            if prov:
                                setattr(cfg, 'fetch_provider', ",".join(prov))
                                print(f"    ğŸŒ Providers: {','.join(prov)} (fallback sÃ©curisÃ©)")
                            else:
                                setattr(cfg, 'fetch_provider', 'archive')
                                print(f"    ğŸŒ Providers: archive (fallback ultime)")
                        except Exception:
                            pass
                
                try:
                    setattr(cfg, 'fetch_allow_images', True)
                    # ğŸš€ OPTIMISATION MULTI-SOURCES: QualitÃ© optimale (CORRIGÃ‰)
                    if uns and giphy:  # Si Unsplash ET Giphy sont disponibles
                        setattr(cfg, 'fetch_max_per_keyword', 35)  # CORRIGÃ‰: 125 â†’ 35 pour qualitÃ© maximale
                        print("    ğŸ“Š Configuration optimisÃ©e: 35 assets max + images activÃ©es (Unsplash + Giphy + Archive)")
                    elif uns:  # Si seulement Unsplash est disponible
                        setattr(cfg, 'fetch_max_per_keyword', 30)  # CORRIGÃ‰: 100 â†’ 30 pour qualitÃ© maximale
                        print("    ğŸ“Š Configuration optimisÃ©e: 30 assets max + images activÃ©es (Unsplash + Archive)")
                    elif giphy:  # Si seulement Giphy est disponible
                        setattr(cfg, 'fetch_max_per_keyword', 30)  # CORRIGÃ‰: 100 â†’ 30 pour qualitÃ© avec GIFs
                        print("    ğŸ“Š Configuration optimisÃ©e: 30 assets max + images activÃ©es (Giphy + Archive)")
                    else:
                        setattr(cfg, 'fetch_max_per_keyword', 25)  # CORRIGÃ‰: 75 â†’ 25 pour Archive.org
                        print("    ğŸ“Š Configuration optimisÃ©e: 25 assets max + images activÃ©es (Archive.org)")
                except Exception:
                    pass
                # DÃ©clencher le fetch dans le dossier unique du clip
                ensure_assets_for_keywords(cfg, top_kws)
                
                # ğŸš¨ CORRECTION CRITIQUE: SYSTÃˆME D'UNICITÃ‰ DES B-ROLLS
                # Ã‰viter la duplication des B-rolls entre vidÃ©os diffÃ©rentes
                try:
                    # CrÃ©er un fichier de traÃ§abilitÃ© des B-rolls utilisÃ©s
                    broll_tracking_file = Config.OUTPUT_FOLDER / 'meta' / 'broll_usage_tracking.json'
                    broll_tracking_file.parent.mkdir(parents=True, exist_ok=True)
                    
                    # Charger l'historique des B-rolls utilisÃ©s
                    broll_history = {}
                    if broll_tracking_file.exists():
                        try:
                            with open(broll_tracking_file, 'r', encoding='utf-8') as f:
                                broll_history = json.load(f)
                        except Exception:
                            broll_history = {}
                    
                    # Identifier les B-rolls disponibles pour ce clip
                    available_brolls = []
                    for asset_path in clip_broll_dir.rglob('*'):
                        if asset_path.suffix.lower() in {'.mp4', '.mov', '.mkv', '.webm', '.jpg', '.jpeg', '.png'}:
                            asset_hash = self._calculate_asset_hash(asset_path)
                            asset_info = {
                                'path': str(asset_path),
                                'hash': asset_hash,
                                'size': asset_path.stat().st_size,
                                'last_used': None,
                                'usage_count': 0
                            }
                            
                            # VÃ©rifier si ce B-roll a dÃ©jÃ  Ã©tÃ© utilisÃ©
                            if asset_hash in broll_history:
                                asset_info['last_used'] = broll_history[asset_hash].get('last_used')
                                asset_info['usage_count'] = broll_history[asset_hash].get('usage_count', 0)
                            
                            available_brolls.append(asset_info)
                    
                    # Trier par prioritÃ©: B-rolls jamais utilisÃ©s en premier, puis par anciennetÃ©
                    available_brolls.sort(key=lambda x: (x['usage_count'], x['last_used'] or '1970-01-01'))
                    
                    # SÃ©lectionner les B-rolls uniques pour cette vidÃ©o
                    selected_brolls = available_brolls[:3]  # 3 B-rolls uniques
                    
                    # Mettre Ã  jour l'historique d'utilisation
                    current_time = datetime.now().isoformat()
                    for broll in selected_brolls:
                        broll_history[broll['hash']] = {
                            'last_used': current_time,
                            'usage_count': broll['usage_count'] + 1,
                            'video_id': Path(input_path).stem
                        }
                    
                    # Sauvegarder l'historique
                    with open(broll_tracking_file, 'w', encoding='utf-8') as f:
                        json.dump(broll_history, f, ensure_ascii=False, indent=2)
                    
                    print(f"    ğŸ¯ B-rolls uniques sÃ©lectionnÃ©s: {len(selected_brolls)} (Ã©vite duplication)")
                    
                except Exception as e:
                    print(f"    âš ï¸ Erreur systÃ¨me d'unicitÃ©: {e}")
                    # Fallback: utiliser tous les B-rolls disponibles
                    pass
                
                # Comptage aprÃ¨s fetch dans le dossier du clip
                try:
                    _media_exts = {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}
                    _after = [p for p in clip_broll_dir.rglob('*') if p.suffix.lower() in _media_exts]
                    print(f"    ğŸ“¥ Fetch terminÃ©: {len(_after)} assets pour ce clip")
                    
                    # ğŸš¨ CORRECTION CRITIQUE: CrÃ©er fetched_brolls accessible globalement
                    fetched_brolls = []
                    for asset_path in _after:
                        if asset_path.exists():
                            fetched_brolls.append({
                                'path': str(asset_path),
                                'name': asset_path.name,
                                'size': asset_path.stat().st_size if asset_path.exists() else 0
                            })
                    
                    print(f"    ğŸ¯ {len(fetched_brolls)} B-rolls prÃªts pour l'assignation")
                    
                    if len(_after) == 0:
                        print("    âš ï¸ Aucun asset tÃ©lÃ©chargÃ©. VÃ©rifie les clÃ©s API et la connectivitÃ© rÃ©seau.")
                except Exception:
                    fetched_brolls = []
                    print("    âš ï¸ Erreur lors de la prÃ©paration des B-rolls fetchÃ©s")
                
                # Construire l'index FAISS pour ce clip spÃ©cifique
                try:
                    if 'build_index' in globals() and build_index is not None:  # type: ignore[name-defined]
                        index_handle = build_index(str(clip_broll_dir), model_name='ViT-B/32')  # type: ignore[misc]
                        print(f"    ğŸ§­ Index FAISS construit pour {clip_id}: {len(_after)} assets")
                except Exception:
                    index_handle = None
            except Exception:
                pass
  
            # Extensions optionnelles pour crossfade/LUT
            try:
                setattr(cfg, 'crossfade_frames', 3)
                setattr(cfg, 'enable_color_match', True)
                setattr(cfg, 'transition_mode', 'auto')  # 'auto' | 'cut' | 'crossfade' | 'zoom'
                setattr(cfg, 'allow_zoom_transitions', True)
                setattr(cfg, 'enable_image_kenburns', True)
            except Exception:
                pass
            
            # PrÃ©parer stop-words (legacy pipeline)
            stopwords: set[str] = set()
            try:
                swp = Path('config/stopwords.txt')
                if swp.exists():
                    stopwords = {ln.strip().lower() for ln in swp.read_text(encoding='utf-8').splitlines() if ln.strip()}
            except Exception:
                stopwords = set()

            # ğŸš€ CORRECTION: IntÃ©gration des mots-clÃ©s LLM dans la planification
            # Planification: nouvelle API prÃ©fÃ©rÃ©e (plan_broll_insertions(segments, cfg, index))
            
            # ğŸš¨ CORRECTION CRITIQUE: fetched_brolls est dÃ©jÃ  dÃ©clarÃ© plus haut, ne pas le redÃ©clarer !
            # fetched_brolls = []  # âŒ SUPPRIMÃ‰: Cette ligne Ã©crase la variable fetchÃ©e !
            
            try:
                plan = plan_broll_insertions(segments, cfg, index_handle)  # type: ignore[arg-type]
            except Exception:
                # ğŸš€ NOUVEAU: Utiliser les mots-clÃ©s LLM pour la planification
                seg_keywords: List[List[str]] = []
                
                # ğŸ§  PRIORITÃ‰ 1: Mots-clÃ©s LLM si disponibles
                if 'broll_keywords' in locals() and broll_keywords:
                    print(f"    ğŸš€ Utilisation des mots-clÃ©s LLM pour la planification: {len(broll_keywords)} termes")
                    # Distribuer les mots-clÃ©s LLM sur les segments
                    for i, s in enumerate(segments):
                        # Prendre 2-3 mots-clÃ©s LLM par segment
                        start_idx = (i * 2) % len(broll_keywords)
                        end_idx = min(start_idx + 2, len(broll_keywords))
                        segment_llm_kws = broll_keywords[start_idx:end_idx]
                        
                        # Combiner avec extraction basique
                        base_kws = extract_keywords_for_segment(s.text) or []
                        spacy_kws = self._extract_keywords_for_segment_spacy(s.text) or []
                        
                        # ğŸ¯ PRIORITÃ‰ aux mots-clÃ©s LLM
                        merged: List[str] = segment_llm_kws + base_kws + spacy_kws
                        
                        # Nettoyer et dÃ©dupliquer
                        cleaned: List[str] = []
                        seen = set()
                        for kw in merged:
                            if kw and kw.lower() not in seen:
                                low = kw.lower()
                                if not (len(low) < 3 and low in stopwords):
                                    cleaned.append(low)
                                    seen.add(low)
                        
                        seg_keywords.append(cleaned[:15])  # AugmentÃ©: 12 â†’ 15
                        print(f"    ğŸ¯ Segment {i}: {len(cleaned)} mots-clÃ©s (LLM: {len(segment_llm_kws)})")
                else:
                    # ğŸ”„ Fallback: extraction basique uniquement
                    print("    âš ï¸ Mots-clÃ©s LLM non disponibles, utilisation extraction basique")
                    for s in segments:
                        base_kws = extract_keywords_for_segment(s.text) or []
                        spacy_kws = self._extract_keywords_for_segment_spacy(s.text) or []
                        merged: List[str] = []
                        for kw in (base_kws + spacy_kws):
                            if kw and kw.lower() not in merged:
                                low = kw.lower()
                                if not (len(low) < 5 and low in stopwords):
                                    merged.append(low)
                        seg_keywords.append(merged[:12])
                
                with _VFC(str(input_path)) as _tmp:
                    duration = float(_tmp.duration)
                plan = plan_broll_insertions(  # type: ignore[call-arg]
                    segments,
                    seg_keywords,
                    total_duration=duration,
                    max_broll_ratio=cfg.max_broll_ratio,
                    min_gap_between_broll_s=cfg.min_gap_between_broll_s,
                    max_broll_clip_s=cfg.max_broll_clip_s,
                    min_broll_clip_s=cfg.min_broll_clip_s,
                )
                
                # ğŸš¨ CORRECTION CRITIQUE: Assigner directement les B-rolls fetchÃ©s aux items du plan
                if plan and fetched_brolls:
                    print(f"    ğŸ¯ Assignation directe des {len(fetched_brolls)} B-rolls fetchÃ©s aux {len(plan)} items du plan...")
                    
                    # Filtrer les B-rolls valides
                    valid_brolls = [broll for broll in fetched_brolls if broll.get('path') and Path(broll.get('path')).exists()]
                    
                    if valid_brolls:
                        # Assigner les B-rolls aux items du plan
                        for i, item in enumerate(plan):
                            if i < len(valid_brolls):
                                asset_path = valid_brolls[i]['path']
                                
                                # Assigner l'asset_path selon le type d'objet
                                if hasattr(item, 'asset_path'):
                                    item.asset_path = asset_path
                                elif isinstance(item, dict):
                                    item['asset_path'] = asset_path
                                
                                print(f"    âœ… B-roll {i+1} assignÃ©: {Path(asset_path).name}")
                            else:
                                break
                        
                        print(f"    ğŸ‰ {min(len(plan), len(valid_brolls))} B-rolls assignÃ©s avec succÃ¨s au plan")
                    else:
                        print(f"    âš ï¸ Aucun B-roll valide trouvÃ© dans fetched_brolls")
                elif not fetched_brolls:
                    print(f"    âš ï¸ Aucun B-roll fetchÃ© disponible pour l'assignation")
                elif not plan:
                    print(f"    âš ï¸ Plan vide - aucun item Ã  traiter")
            # Scoring adaptatif si disponible (pertinence/diversitÃ©/esthÃ©tique)
            

            
            try:
                from src.pipeline.scoring import score_candidates  # type: ignore
                boosts = {
                    # ğŸš€ Business & Croissance
                    "croissance": 0.9, "growth": 0.9, "opportunitÃ©": 0.8, "opportunite": 0.8,
                    "innovation": 0.9, "dÃ©veloppement": 0.8, "developpement": 0.8, "expansion": 0.8,
                    "stratÃ©gie": 0.8, "strategie": 0.8, "plan": 0.7, "objectif": 0.8, "vision": 0.8,
                    
                    # ğŸ’° Argent & Finance
                    "argent": 1.0, "money": 1.0, "cash": 0.9, "investissement": 0.9, "investissements": 0.9,
                    "revenu": 0.8, "revenus": 0.8, "profit": 0.9, "profits": 0.9, "perte": 0.7, "pertes": 0.7,
                    "Ã©chec": 0.7, "echec": 0.7, "budget": 0.7, "gestion": 0.7, "marge": 0.8, "roi": 0.9,
                    "chiffre": 0.7, "ca": 0.7, "Ã©conomie": 0.8, "economie": 0.8, "financier": 0.8,
                    
                    # ğŸ¤ Relation & Client
                    "client": 0.9, "clients": 0.9, "collaboration": 0.8, "collaborations": 0.8,
                    "communautÃ©": 0.7, "communaute": 0.7, "confiance": 0.7, "vente": 0.8, "ventes": 0.8,
                    "deal": 0.7, "deals": 0.7, "prospect": 0.6, "prospects": 0.6, "contrat": 0.7,
                    "partenariat": 0.8, "Ã©quipe": 0.7, "equipe": 0.7, "rÃ©seau": 0.7, "reseau": 0.7,
                    
                    # ğŸ”¥ Motivation & SuccÃ¨s
                    "succÃ¨s": 0.9, "succes": 0.9, "motivation": 0.8, "Ã©nergie": 0.7, "energie": 0.7,
                    "victoire": 0.8, "discipline": 0.7, "viral": 0.8, "viralitÃ©": 0.8, "viralite": 0.8,
                    "impact": 0.6, "explose": 0.6, "explosion": 0.6, "inspiration": 0.8, "passion": 0.8,
                    "dÃ©termination": 0.8, "determination": 0.8, "persÃ©vÃ©rance": 0.8, "perseverance": 0.8,
                    
                    # ğŸ§  Intelligence & Apprentissage
                    "cerveau": 1.0, "brain": 1.0, "intelligence": 0.9, "savoir": 0.8, "connaissance": 0.8,
                    "apprentissage": 0.8, "apprendre": 0.8, "Ã©tude": 0.8, "etude": 0.8, "formation": 0.8,
                    "compÃ©tence": 0.8, "competence": 0.8, "expertise": 0.8, "maÃ®trise": 0.8, "maitrise": 0.8,
                    
                    # ğŸ’¡ Innovation & Technologie
                    "technologie": 0.9, "tech": 0.9, "innovation": 0.9, "digital": 0.8, "numÃ©rique": 0.8,
                    "numerique": 0.8, "futur": 0.8, "avancÃ©e": 0.8, "avancee": 0.8, "rÃ©volution": 0.8,
                    "revolution": 0.8, "disruption": 0.8, "transformation": 0.8, "Ã©volution": 0.8, "evolution": 0.8,
                    
                    # âš ï¸ Risque & Erreurs
                    "erreur": 0.6, "erreurs": 0.6, "warning": 0.6, "obstacle": 0.6, "obstacles": 0.6,
                    "solution": 0.6, "solutions": 0.6, "leÃ§on": 0.5, "lecon": 0.5, "apprentissage": 0.5,
                    "problÃ¨me": 0.6, "probleme": 0.6, "dÃ©fi": 0.7, "defi": 0.7, "challenge": 0.7,
                    
                    # ğŸŒŸ QualitÃ© & Excellence
                    "excellence": 0.9, "qualitÃ©": 0.8, "qualite": 0.8, "perfection": 0.8, "meilleur": 0.8,
                    "optimal": 0.8, "efficacitÃ©": 0.8, "efficacite": 0.8, "performance": 0.8, "rÃ©sultat": 0.8,
                    "resultat": 0.8, "succÃ¨s": 0.9, "succes": 0.9, "rÃ©ussite": 0.9, "reussite": 0.9,
                }
                plan = score_candidates(
                    plan, segments, broll_library=str(broll_library), clip_model='ViT-B/32',
                    use_faiss=True, top_k=10, keyword_boosts=boosts
                )
                
            except Exception:
                pass
 
            # FILTRE: Exclure les B-rolls trop tÃ´t dans la vidÃ©o (dÃ©lai minimum 3 secondes)
            try:
                filtered_plan = []
                for it in plan:
                    st = float(getattr(it, 'start', 0.0) if hasattr(it, 'start') else (it.get('start', 0.0) if isinstance(it, dict) else 0.0))
                    if st >= 3.0:  # DÃ©lai minimum de 3 secondes avant le premier B-roll
                        filtered_plan.append(it)
                    else:
                        print(f"    â° B-roll filtrÃ©: trop tÃ´t Ã  {st:.2f}s (minimum 3.0s)")
                
                plan = filtered_plan
                print(f"    âœ… Plan filtrÃ©: {len(plan)} B-rolls aprÃ¨s dÃ©lai minimum")
            except Exception:
                pass

            # DÃ©duplication souple: autoriser rÃ©utilisation si espacÃ©e (> 12s)
            try:
                seen: dict[str, float] = {}
                new_plan = []
                for it in plan:
                    # ğŸ”§ CORRECTION: GÃ©rer Ã  la fois BrollPlanItem et dict
                    if hasattr(it, 'asset_path'):
                        ap = it.asset_path
                        st = float(it.start)
                    elif isinstance(it, dict):
                        ap = it.get('asset_path')
                        st = float(it.get('start', 0.0))
                    else:
                        # Fallback pour autres types
                        ap = getattr(it, 'asset_path', None)
                        st = float(getattr(it, 'start', 0.0))
                    
                    if not ap:
                        new_plan.append(it)
                        continue
                    
                    last = seen.get(ap, -1e9)
                    if st - last >= 8.0:
                        new_plan.append(it)
                        seen[ap] = st
                plan = new_plan
                
            except Exception:
                pass
 
            # ğŸš€ PRIORISATION FRAÃCHEUR: Trier par timestamp du dossier (plus rÃ©cent en premier)
            try:
                if plan:
                    # Extraire le clip_id pour la priorisation
                    clip_id = input_path.stem
                    
                    # Prioriser par fraÃ®cheur si possible
                    for item in plan:
                        if hasattr(item, 'asset_path') and item.asset_path:
                            asset_path = item.asset_path
                        elif isinstance(item, dict) and item.get('asset_path'):
                            asset_path = item['asset_path']
                        else:
                            continue
                        
                        # Calculer le score de fraÃ®cheur
                        try:
                            path = Path(asset_path)
                            for part in path.parts:
                                if part.startswith(f"clip_{clip_id}_") and "_" in part:
                                    timestamp_str = part.split("_")[-1]
                                    if timestamp_str.isdigit():
                                        item.freshness_score = int(timestamp_str)
                                        break
                            else:
                                item.freshness_score = 0
                        except Exception:
                            item.freshness_score = 0
                    
                    # Trier par fraÃ®cheur dÃ©croissante
                    plan.sort(key=lambda x: getattr(x, 'freshness_score', 0), reverse=True)
                    print(f"    ğŸ†• Priorisation fraÃ®cheur: {len(plan)} B-rolls triÃ©s par timestamp")
                    
            except Exception as e:
                print(f"    âš ï¸  Erreur priorisation fraÃ®cheur: {e}")
 
            # ğŸ¯ SCORING CONTEXTUEL RENFORCÃ‰: PÃ©naliser les assets non pertinents au domaine
            try:
                if plan and hasattr(global_analysis, 'main_theme') and hasattr(global_analysis, 'keywords'):
                    domain = global_analysis.main_theme
                    keywords = global_analysis.keywords[:10] if hasattr(global_analysis, 'keywords') else []
                    
                    for item in plan:
                        if hasattr(item, 'asset_path') and item.asset_path:
                            asset_path = item.asset_path
                        elif isinstance(item, dict) and item.get('asset_path'):
                            asset_path = item['asset_path']
                        else:
                            continue
                        
                        # Calculer le score contextuel
                        context_score = _score_contextual_relevance(asset_path, domain, keywords)
                        
                        # Appliquer le score contextuel au score final
                        if hasattr(item, 'score'):
                            # Ajuster le score existant
                            item.score = item.score * context_score
                        elif isinstance(item, dict) and 'score' in item:
                            item['score'] = item['score'] * context_score
                        
                        # Stocker le score contextuel pour debug
                        if hasattr(item, 'context_score'):
                            item.context_score = context_score
                        elif isinstance(item, dict):
                            item['context_score'] = context_score
                    
                    print(f"    ğŸ¯ Scoring contextuel appliquÃ©: domaine '{domain}' avec {len(keywords)} mots-clÃ©s")
                    
                    # ğŸ” DEBUG B-ROLL SELECTION (si activÃ©)
                    debug_mode = getattr(Config, 'DEBUG_BROLL', False) or os.getenv('DEBUG_BROLL', 'false').lower() == 'true'
                    _debug_broll_selection(plan, domain, keywords, debug_mode)
                    
                    # ğŸš¨ FALLBACK PROPRE: Si aucun asset pertinent, utiliser des assets neutres
                    # ğŸ”§ CORRECTION CRITIQUE: VÃ©rifier d'abord si les items ont des assets assignÃ©s
                    items_without_assets = []
                    items_with_assets = []
                    
                    for item in plan:
                        if hasattr(item, 'asset_path') and item.asset_path:
                            items_with_assets.append(item)
                        elif isinstance(item, dict) and item.get('asset_path'):
                            items_with_assets.append(item)
                        else:
                            items_without_assets.append(item)
                    
                    print(f"    ğŸ” Analyse des assets: {len(items_with_assets)} avec assets, {len(items_without_assets)} sans assets")
                    
                    # ğŸš¨ CORRECTION: Assigner des assets aux items sans assets AVANT le fallback
                    if items_without_assets and fetched_brolls:
                        print(f"    ğŸ¯ Assignation d'assets aux {len(items_without_assets)} items sans assets...")
                        
                        # Utiliser les B-rolls fetchÃ©s pour assigner aux items
                        available_assets = [broll.get('path', '') for broll in fetched_brolls if broll.get('path')]
                        
                        for i, item in enumerate(items_without_assets):
                            if i < len(available_assets):
                                asset_path = available_assets[i]
                                if hasattr(item, 'asset_path'):
                                    item.asset_path = asset_path
                                elif isinstance(item, dict):
                                    item['asset_path'] = asset_path
                                
                                print(f"    âœ… Asset assignÃ© Ã  item {i+1}: {Path(asset_path).name}")
                            else:
                                break
                        
                        # Recalculer les listes aprÃ¨s assignation
                        items_with_assets = [item for item in plan if (hasattr(item, 'asset_path') and item.asset_path) or (isinstance(item, dict) and item.get('asset_path'))]
                        items_without_assets = [item for item in plan if not ((hasattr(item, 'asset_path') and item.asset_path) or (isinstance(item, dict) and item.get('asset_path')))]
                    
                    # ğŸš¨ FALLBACK UNIQUEMENT SI VRAIMENT NÃ‰CESSAIRE
                    if not items_with_assets and items_without_assets:
                        print(f"    âš ï¸  Aucun asset disponible, activation du fallback neutre")
                        fallback_assets = _get_fallback_neutral_assets(broll_library, count=3)
                        if fallback_assets:
                            print(f"    ğŸ†˜ Fallback neutre: {len(fallback_assets)} assets gÃ©nÃ©riques utilisÃ©s")
                            # CrÃ©er des items de plan avec les assets de fallback
                            for i, asset_path in enumerate(fallback_assets):
                                fallback_item = {
                                    'start': 3.0 + (i * 5.0),  # Espacer les fallbacks
                                    'end': 3.0 + (i * 5.0) + 3.0,
                                    'asset_path': asset_path,
                                    'score': 0.5,  # Score neutre
                                    'context_score': 0.3,  # Pertinence faible
                                    'is_fallback': True
                                }
                                plan.append(fallback_item)
                        else:
                            print(f"    ğŸš¨ Aucun asset de fallback disponible")
                    elif items_with_assets:
                        print(f"    âœ… {len(items_with_assets)} items avec assets assignÃ©s - Pas de fallback nÃ©cessaire")
                    else:
                        print(f"    âš ï¸  Plan vide - Aucun item Ã  traiter")
                    
            except Exception as e:
                print(f"    âš ï¸  Erreur scoring contextuel: {e}")
 
                        # Affecter un asset_path pertinent via FAISS/CLIP si manquant
            try:
                from sentence_transformers import SentenceTransformer  # type: ignore
                import numpy as _np  # type: ignore
                import faiss as _faiss  # type: ignore
                from pathlib import Path as _P
                
                # ğŸš¨ NOUVEAU: Importer le systÃ¨me de scoring contextuel intelligent
                try:
                    from src.pipeline.broll_selector import get_contextual_broll_score
                    print("    ğŸ§  SystÃ¨me de scoring contextuel intelligent activÃ©")
                except ImportError:
                    print("    âš ï¸ SystÃ¨me de scoring contextuel non disponible")
                    get_contextual_broll_score = None
                
                # UTILISER LE DOSSIER SPÃ‰CIFIQUE DU CLIP (pas la librairie globale)
                clip_specific_dir = clip_broll_dir if 'clip_specific_dir' in locals() else broll_library
                idx_bin = (clip_specific_dir / 'faiss.index')
                idx_json = (clip_specific_dir / 'faiss.json')
                
                model_name = getattr(cfg, 'embedding_model_name', 'clip-ViT-B/32')
                st_model = SentenceTransformer('clip-ViT-B/32') if 'ViT' in model_name else SentenceTransformer(model_name)
                def emb_text(t: str):
                    v = st_model.encode([t])[0].astype('float32')
                    n = _np.linalg.norm(v) + 1e-12
                    return v / n
                paths = []
                if idx_json.exists():
                    import json as _json
                    try:
                        paths = _json.loads(idx_json.read_text(encoding='utf-8')).get('paths', [])
                    except Exception:
                        paths = []
                index = _faiss.read_index(str(idx_bin)) if idx_bin.exists() else None
                used_recent: set[str] = set()
                for it in plan or []:
                    ap = getattr(it, 'asset_path', None) if hasattr(it, 'asset_path') else (it.get('asset_path') if isinstance(it, dict) else None)
                    if ap:
                        continue
                    # Texte local autour de l'event
                    st_e = float(getattr(it, 'start', 0.0) if hasattr(it, 'start') else (it.get('start') if isinstance(it, dict) else 0.0))
                    en_e = float(getattr(it, 'end', 0.0) if hasattr(it, 'end') else (it.get('end') if isinstance(it, dict) else 0.0))
                    local = " ".join(s.text for s in segments if float(s.start) <= en_e and float(s.end) >= st_e)[:400]
                    q = emb_text(local) if local else None
                    
                    # ğŸš¨ NOUVEAU: Extraction des mots-clÃ©s pour le scoring contextuel
                    local_keywords = []
                    if local:
                        # Extraire les mots-clÃ©s du texte local
                        words = local.lower().split()
                        local_keywords = [w for w in words if len(w) > 3 and w.isalpha()][:10]
                    
                    chosen = None
                    best_score = -1
                    
                    if index is not None and q is not None and paths:
                        # ğŸš¨ NOUVEAU: Recherche Ã©tendue pour Ã©valuation contextuelle
                        D,I = index.search(q.reshape(1,-1), 15)  # Augmenter de 5 Ã  15 candidats
                        
                        # ğŸš¨ NOUVEAU: Ã‰valuation contextuelle de tous les candidats
                        for idx in I[0].tolist():
                            if 0 <= idx < len(paths):
                                p = paths[idx]
                                if not p:
                                    continue
                                cand = _P(p)
                                if not cand.is_absolute():
                                    cand = (clip_specific_dir / p).resolve()
                                if str(cand) not in used_recent and cand.exists():
                                    # ğŸš¨ NOUVEAU: Calcul du score contextuel intelligent
                                    contextual_score = 0.0
                                    if 'get_contextual_broll_score' in globals() and local_keywords:
                                        try:
                                            # Extraire les tokens et tags du fichier
                                            asset_name = cand.stem.lower()
                                            asset_tokens = asset_name.split('_')
                                            asset_tags = asset_name.split('_')  # SimplifiÃ© pour l'exemple
                                            contextual_score = get_contextual_broll_score(local_keywords, asset_tokens, asset_tags)
                                        except Exception as e:
                                            print(f"    âš ï¸ Erreur scoring contextuel: {e}")
                                            contextual_score = 0.0
                                    
                                    # ğŸš¨ NOUVEAU: Score combinÃ© FAISS + Contextuel
                                    faiss_score = float(D[0][I[0].tolist().index(idx)]) if idx in I[0] else 0.0
                                    combined_score = faiss_score + (contextual_score * 2.0)  # Poids contextuel DOUBLÃ‰
                                    
                                    if combined_score > best_score:
                                        best_score = combined_score
                                        chosen = str(cand)
                        
                        # ğŸš¨ NOUVEAU: Log de la sÃ©lection contextuelle
                        if chosen and 'get_contextual_broll_score' in globals() and local_keywords:
                            try:
                                asset_name = Path(chosen).stem.lower()
                                asset_tokens = asset_name.split('_')
                                asset_tags = asset_name.split('_')
                                final_contextual_score = get_contextual_broll_score(local_keywords, asset_tokens, asset_tags)
                                print(f"    ğŸ¯ SÃ©lection contextuelle: {Path(chosen).stem} | Score: {best_score:.3f} | Contexte: {final_contextual_score:.2f}")
                            except Exception:
                                pass
                    
                    if chosen is None:
                        # ğŸš¨ NOUVEAU: Fallback contextuel intelligent au lieu d'alÃ©atoire
                        print(f"    ğŸ” Fallback contextuel pour segment: {local[:50]}...")
                        for p in clip_specific_dir.rglob('*'):
                            if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}:
                                if str(p.resolve()) not in used_recent and p.exists():
                                    # ğŸš¨ NOUVEAU: Ã‰valuation contextuelle du fallback
                                    if 'get_contextual_broll_score' in globals() and local_keywords:
                                        try:
                                            asset_name = p.stem.lower()
                                            asset_tokens = asset_name.split('_')
                                            asset_tags = asset_name.split('_')
                                            fallback_score = get_contextual_broll_score(local_keywords, asset_tokens, asset_tags)
                                            if fallback_score > 2.0:  # Seuil contextuel minimum
                                                chosen = str(p.resolve())
                                                print(f"    âœ… Fallback contextuel: {p.stem} | Score: {fallback_score:.2f}")
                                                break
                                        except Exception:
                                            pass
                                    else:
                                        # Fallback sans scoring contextuel
                                        chosen = str(p.resolve())
                                        break
                    
                    if chosen:
                        if isinstance(it, dict):
                            it['asset_path'] = chosen
                        else:
                            try:
                                setattr(it, 'asset_path', chosen)
                            except Exception:
                                pass
            except Exception:
                pass

            # VÃ©rification des asset_path avant normalisation + mini fallback non invasif
            try:
                def _get_ap(x):
                    return (getattr(x, 'asset_path', None) if hasattr(x, 'asset_path') else (x.get('asset_path') if isinstance(x, dict) else None))
                missing = [it for it in (plan or []) if not _get_ap(it)]
                if plan and len(missing) == len(plan):
                    # Aucun asset assignÃ© par FAISS â†’ mini fallback d'assignation sÃ©quentielle
                    # UTILISER LE DOSSIER SPÃ‰CIFIQUE DU CLIP
                    clip_specific_dir = clip_broll_dir if 'clip_specific_dir' in locals() else broll_library
                    lib_assets = [p for p in clip_specific_dir.rglob('*') if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}]
                    if lib_assets:
                        for i, it in enumerate(plan):
                            ap = _get_ap(it)
                            if ap:
                                continue
                            a = lib_assets[i % len(lib_assets)]
                            chosen = str(a.resolve())
                            if isinstance(it, dict):
                                it['asset_path'] = chosen
                            else:
                                try:
                                    setattr(it, 'asset_path', chosen)
                                except Exception:
                                    pass
            except Exception:
                pass
 
             # Normaliser la timeline en Ã©vÃ©nements canonique et rendre
            try:
                with _VFC(str(input_path)) as _fpsprobe:
                    fps_probe = float(_fpsprobe.fps or 25.0)
            except Exception:
                fps_probe = 25.0
            events = normalize_timeline(plan, fps=fps_probe)
            events = enrich_keywords(events)
            

            
            # Hard fail if no valid events
            if not events:
                raise RuntimeError('Aucun B-roll valide aprÃ¨s planification/scoring. VÃ©rifier l\'index FAISS et la librairie. Aucun fallback synthÃ©tique appliquÃ©.')
            # Valider que les mÃ©dias existent
            from pathlib import Path as _Path
            valid_events = []
            for ev in events:
                mp = getattr(ev, 'media_path', '')
                pp = _Path(mp)
                if not pp.exists() and mp and not pp.is_absolute():
                    pp = (broll_library / mp).resolve()
                    if pp.exists():
                        try:
                            setattr(ev, 'media_path', str(pp))
                        except Exception:
                            pass
                if getattr(ev, 'media_path', '') and _Path(getattr(ev, 'media_path')).exists():
                    valid_events.append(ev)
            # Log count and sample
            try:
                print(f"    ğŸ” B-roll events valides: {len(valid_events)}")
                for _ev in valid_events[:3]:
                    print(f"       â€¢ {_ev.start_s:.2f}-{_ev.end_s:.2f} â†’ {getattr(_ev, 'media_path','')}")
            except Exception:
                pass
            if not valid_events:
                # Fallback legacy: construire un plan simple Ã  partir de la librairie existante
                try:
                    _media_exts = {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}
                    assets = [p for p in broll_library.rglob('*') if p.suffix.lower() in _media_exts]
                    assets.sort(key=lambda p: p.stat().st_size if p.exists() else 0, reverse=True)
                    assets = assets[:20]
                    if assets:
                        # Choisir des segments suffisamment longs (>2.0s) et espacÃ©s
                        cands = []
                        for s in segments:
                            dur = float(getattr(s, 'end', 0.0) - getattr(s, 'start', 0.0))
                            if dur >= 2.0 and getattr(s, 'start', 0.0) >= 1.5:  # Plus flexible
                                cands.append(s)
                        plan_simple = []
                        gap = 6.0  # RÃ©duit: 8s â†’ 6s pour plus d'insertions
                        last = -1e9
                        ai = 0
                        for s in cands:
                            st = float(getattr(s,'start',0.0))
                            en = float(getattr(s,'end',0.0))
                            if st - last < gap:
                                continue
                            dur = min(7.0, max(2.5, en - st))  # DurÃ©e min: 2.5s, max: 7s
                            asset = assets[ai % len(assets)]
                            ai += 1
                            plan_simple.append({
                                'start': st,
                                'end': min(en, st + dur),
                                'asset_path': str(asset.resolve()),
                                'crossfade_frames': 2,
                            })
                            last = st
                        # Normaliser et rendre si on a des items
                        if plan_simple:
                            try:
                                with _VFC(str(input_path)) as _fpsprobe:
                                    fps_probe = float(_fpsprobe.fps or 25.0)
                            except Exception:
                                fps_probe = 25.0
                            legacy_events = normalize_timeline(plan_simple, fps=fps_probe)
                            legacy_events = enrich_keywords(legacy_events)
                            print(f"    â™»ï¸ Fallback legacy appliquÃ©: {len(legacy_events)} events")
                            valid_events = legacy_events
                            # Continue vers le rendu unique plus bas
                        else:
                            raise RuntimeError('Librairie B-roll prÃ©sente mais aucun slot valide pour fallback legacy')
                    else:
                        raise RuntimeError('B-rolls planifiÃ©s, aucun media_path valide et aucune ressource en librairie pour fallback')
                except Exception as _e:
                    raise RuntimeError('B-rolls planifiÃ©s, mais aucun media_path valide trouvÃ©. Fallback legacy impossible: ' + str(_e))
            # Rendu unique avec les events valides (incl. fallback le cas Ã©chÃ©ant)
            render_video(cfg, segments, valid_events)
            
            # VÃ‰RIFICATION ET NETTOYAGE INTELLIGENT DES B-ROLLS
            try:
                if getattr(Config, 'BROLL_DELETE_AFTER_USE', False):
                    print("    ğŸ” VÃ©rification des B-rolls avant suppression...")
                    
                    # Importer le systÃ¨me de vÃ©rification
                    try:
                        from broll_verification_system import create_verification_system
                        verifier = create_verification_system()
                        
                        # VÃ©rifier l'insertion des B-rolls
                        verification_result = verifier.verify_broll_insertion(
                            video_path=cfg.output_video,
                            broll_plan=plan or [],
                            broll_library_path=str(clip_broll_dir) if 'clip_broll_dir' in locals() else "AI-B-roll/broll_library"
                        )
                        
                        # ğŸš€ CORRECTION: VÃ©rifier le type du rÃ©sultat de vÃ©rification
                        if not isinstance(verification_result, dict):
                            print(f"    âš ï¸ RÃ©sultat de vÃ©rification invalide (type: {type(verification_result)}) - Fallback vers vÃ©rification basique")
                            verification_result = {
                                "verification_passed": True,  # Par dÃ©faut, autoriser la suppression
                                "issues": [],
                                "recommendations": []
                            }
                        
                        # DÃ©cider si la suppression est autorisÃ©e
                        if verification_result.get("verification_passed", False):
                            print("    âœ… VÃ©rification rÃ©ussie - Suppression autorisÃ©e")
                            
                            # Supprimer seulement les fichiers B-roll utilisÃ©s (pas le dossier)
                            used_files: List[str] = []
                            for item in (plan or []):
                                path = getattr(item, 'asset_path', None) if hasattr(item, 'asset_path') else (item.get('asset_path') if isinstance(item, dict) else None)
                                if path and os.path.exists(path):
                                    used_files.append(path)
                            
                            # Nettoyer les fichiers utilisÃ©s
                            cleaned_count = 0
                            for p in used_files:
                                try:
                                    os.remove(p)
                                    cleaned_count += 1
                                except Exception:
                                    pass
                            
                            # Marquer le dossier comme "utilisÃ©" mais le garder
                            if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                                try:
                                    # CrÃ©er un fichier de statut pour indiquer que le clip est traitÃ©
                                    status_file = clip_broll_dir / "STATUS_COMPLETED.txt"
                                    status_file.write_text(f"Clip traitÃ© le {time.strftime('%Y-%m-%d %H:%M:%S')}\nB-rolls utilisÃ©s: {cleaned_count}\nVÃ©rification: PASSED\n", encoding='utf-8')
                                    print(f"    ğŸ—‚ï¸ Dossier B-roll conservÃ©: {clip_broll_dir.name} (fichiers nettoyÃ©s: {cleaned_count})")
                                except Exception as e:
                                    print(f"    âš ï¸ Erreur crÃ©ation statut: {e}")
                        else:
                            print("    âŒ VÃ©rification Ã©chouÃ©e - Suppression REFUSÃ‰E")
                            print("    ğŸ“‹ ProblÃ¨mes dÃ©tectÃ©s:")
                            for issue in verification_result.get("issues", []):
                                print(f"       â€¢ {issue}")
                            print("    ğŸ’¡ Recommandations:")
                            for rec in verification_result.get("recommendations", []):
                                print(f"       â€¢ {rec}")
                            
                            # CrÃ©er un fichier de statut d'Ã©chec
                            if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                                try:
                                    status_file = clip_broll_dir / "STATUS_FAILED.txt"
                                    status_file.write_text(f"Clip traitÃ© le {time.strftime('%Y-%m-%d %H:%M:%S')}\nVÃ©rification: FAILED\nProblÃ¨mes: {', '.join(verification_result.get('issues', []))}\n", encoding='utf-8')
                                    print(f"    ğŸš¨ Dossier B-roll marquÃ© comme Ã©chec: {clip_broll_dir.name}")
                                except Exception as e:
                                    print(f"    âš ï¸ Erreur crÃ©ation statut d'Ã©chec: {e}")
                    
                    except ImportError:
                        print("    âš ï¸ SystÃ¨me de vÃ©rification non disponible - Suppression sans vÃ©rification")
                        # Fallback vers l'ancien systÃ¨me
                        used_files: List[str] = []
                        for item in (plan or []):
                            path = getattr(item, 'asset_path', None) if hasattr(item, 'asset_path') else (item.get('asset_path') if isinstance(item, dict) else None)
                            if path and os.path.exists(path):
                                used_files.append(path)
                        
                        cleaned_count = 0
                        for p in used_files:
                            try:
                                os.remove(p)
                                cleaned_count += 1
                            except Exception:
                                pass
                        
                        if 'clip_broll_dir' in locals() and clip_broll_dir.exists():
                            try:
                                status_file = clip_broll_dir / "STATUS_COMPLETED_NO_VERIFICATION.txt"
                                status_file.write_text(f"Clip traitÃ© le {time.strftime('%Y-%m-%d %H:%M:%S')}\nB-rolls utilisÃ©s: {cleaned_count}\nVÃ©rification: NON DISPONIBLE\n", encoding='utf-8')
                                print(f"    ğŸ—‚ï¸ Dossier B-roll conservÃ©: {clip_broll_dir.name} (fichiers nettoyÃ©s: {cleaned_count})")
                            except Exception as e:
                                print(f"    âš ï¸ Erreur crÃ©ation statut: {e}")
                    
            except Exception as e:
                print(f"    âš ï¸ Erreur lors de la vÃ©rification/nettoyage: {e}")
                # En cas d'erreur, ne pas supprimer les B-rolls
                pass

            if Path(cfg.output_video).exists():
                print("    âœ… B-roll insÃ©rÃ©s avec succÃ¨s")
                return Path(cfg.output_video)
            else:
                print("    âš ï¸ Sortie B-roll introuvable, retour Ã  la vidÃ©o d'origine")
                return input_path
        except Exception as e:
            print(f"    âŒ Erreur B-roll: {e}")
            return input_path

    # Si densitÃ© trop faible aprÃ¨s planification, injecter quelques B-rolls gÃ©nÃ©riques
    try:
        with _VFC(str(input_path)) as _tmp:
            _total = float(_tmp.duration or 0.0)
        cur_cov = sum(max(0.0, (float(getattr(it,'end', it.get('end',0.0))) - float(getattr(it,'start', it.get('start',0.0))))) for it in (plan or []))
        if _total > 0 and (cur_cov / _total) < 0.20:  # AugmentÃ©: 15% â†’ 20% pour plus de B-rolls
            _generics = []
            bank = [
                "money", "handshake", "meeting", "audience", "lightbulb", "typing", "city", "success"
            ]
            # Chercher quelques mÃ©dias gÃ©nÃ©riques existants
            for p in broll_library.rglob('*'):
                if p.suffix.lower() in {'.mp4','.mov','.mkv','.webm','.jpg','.jpeg','.png'}:
                    name = p.stem.lower()
                    if any(k in name for k in bank):
                        _generics.append(str(p.resolve()))
            if _generics:
                # Injecter 2â€“4 gÃ©nÃ©riques espacÃ©s
                inject_count = min(4, max(2, int(len(_generics)/5)))
                st = 2.0
                while inject_count > 0 and st < (_total - 3.5):
                    plan.append({'start': st, 'end': min(_total, st+3.5), 'asset_path': _generics[inject_count % len(_generics)], 'crossfade_frames': 2})
                    st += 10.0
                    inject_count -= 1
                print("    â• B-rolls gÃ©nÃ©riques injectÃ©s pour densitÃ© minimale")
    except Exception:
        pass

class PremiereProAutomation:
    """
    Classe pour l'automatisation Premiere Pro (optionnelle)
    Utilise ExtendScript pour les utilisateurs avancÃ©s
    """
    
    @staticmethod
    def create_jsx_script(clip_path: str, output_path: str) -> str:
        """GÃ©nÃ¨re un script ExtendScript pour Premiere Pro"""
        jsx_script = f'''
        // Script ExtendScript pour Premiere Pro
        var project = app.project;
        
        // Import du clip
        var importOptions = new ImportOptions();
        importOptions.file = new File("{clip_path}");
        var clip = project.importFiles([importOptions.file]);
        
        // CrÃ©ation d'une sÃ©quence 9:16
        var sequence = project.createNewSequence("Vertical_Clip", "HDV-1080i25");
        sequence.videoTracks[0].insertClip(clip[0], 0);
        
        // Application de l'effet Auto Reframe (si disponible)
        // Note: Ceci nÃ©cessite Premiere Pro 2019 ou plus rÃ©cent
        
        // Export
        var encoder = app.encoder;
        encoder.encodeSequence(sequence, "{output_path}", "H.264", false);
        '''
        return jsx_script
    
    @staticmethod 
    def run_premiere_script(jsx_script_content: str):
        """ExÃ©cute un script ExtendScript dans Premiere Pro"""
        try:
            # Sauvegarde du script temporaire
            script_path = Config.TEMP_FOLDER / "premiere_script.jsx"
            with open(script_path, 'w') as f:
                f.write(jsx_script_content)
            
            import platform
            system = platform.system()
            
            if system == 'Darwin':  # macOS
                subprocess.run([
                    'osascript', '-e',
                    f'tell application "Adobe Premiere Pro" to do script "{script_path}"'
                ], check=True)
            elif system == 'Windows':
                print("âš ï¸ ExÃ©cution ExtendScript automatisÃ©e non supportÃ©e nativement sous Windows dans ce pipeline.")
                print("   Ouvrez Premiere Pro et exÃ©cutez le script manuellement: " + str(script_path))
            else:
                print("âš ï¸ Plateforme non supportÃ©e pour l'exÃ©cution automatique de Premiere Pro.")
            
            logger.info("âœ… Script Premiere Pro traitÃ© (voir message ci-dessus)")
            
        except Exception as e:
            logger.error(f"âŒ Erreur Premiere Pro: {e}")
            raise

# Helper: filter noisy prompt terms
STOP_PROMPT_TERMS = {
    'very','really','clear','stuff','thing','things','some','any','ever','so','much','get','got',
    'will','discuss','this','that','these','those','it','its','im','ive','youve','because'
}

def _filter_prompt_terms(words):
    cleaned = []
    for w in words:
        if not isinstance(w, str):
            continue
        t = w.strip().lower()
        if not t or t in STOP_PROMPT_TERMS or len(t) < 3:
            continue
        cleaned.append(t)
    # de-duplicate preserving order
    seen = set()
    result = []
    for t in cleaned:
        if t not in seen:
            result.append(t)
            seen.add(t)
    return result[:5]

def _prioritize_fresh_assets(broll_candidates, clip_id):
    """Priorise les assets les plus rÃ©cents basÃ©s sur le timestamp du dossier."""
    if not broll_candidates:
        return broll_candidates
    
    try:
        # Extraire le timestamp du dossier pour chaque candidat
        for candidate in broll_candidates:
            if hasattr(candidate, 'file_path') and candidate.file_path:
                path = Path(candidate.file_path)
                # Chercher le pattern clip_*_timestamp dans le chemin
                for part in path.parts:
                    if part.startswith(f"clip_{clip_id}_") and "_" in part:
                        timestamp_str = part.split("_")[-1]
                        if timestamp_str.isdigit():
                            candidate.folder_timestamp = int(timestamp_str)
                            break
                else:
                    candidate.folder_timestamp = 0
            else:
                candidate.folder_timestamp = 0
        
        # Trier par timestamp dÃ©croissant (plus rÃ©cent en premier)
        broll_candidates.sort(key=lambda x: getattr(x, 'folder_timestamp', 0), reverse=True)
        
    except Exception as e:
        print(f"    âš ï¸  Erreur priorisation fraÃ®cheur: {e}")
    
    return broll_candidates

def _score_contextual_relevance(asset_path, domain, keywords):
    """Score de pertinence contextuelle basÃ© sur les tokens et le domaine."""
    try:
        if not asset_path or not domain or not keywords:
            return 0.5
        
        # Extraire les tokens du nom de fichier
        filename = Path(asset_path).stem.lower()
        asset_tokens = set(re.split(r'[^a-z0-9]+', filename))
        
        # Tokens du domaine et mots-clÃ©s
        domain_tokens = set(domain.lower().split())
        keyword_tokens = set()
        for kw in keywords:
            if isinstance(kw, str):
                keyword_tokens.update(kw.lower().split())
        
        # Calculer l'overlap
        relevant_tokens = domain_tokens | keyword_tokens
        if not relevant_tokens:
            return 0.5
        
        overlap = len(asset_tokens & relevant_tokens)
        total_relevant = len(relevant_tokens)
        
        # Score basÃ© sur l'overlap (0.0 Ã  1.0)
        base_score = min(1.0, overlap / max(1, total_relevant * 0.3))
        
        # Bonus pour les tokens de domaine
        domain_overlap = len(asset_tokens & domain_tokens)
        domain_bonus = min(0.3, domain_overlap * 0.1)
        
        final_score = min(1.0, base_score + domain_bonus)
        return final_score
        
    except Exception as e:
        print(f"    âš ï¸  Erreur scoring contextuel: {e}")
        return 0.5

def _get_fallback_neutral_assets(broll_library, count=3):
    """RÃ©cupÃ¨re des assets neutres/gÃ©nÃ©riques comme fallback."""
    try:
        fallback_keywords = ['neutral', 'generic', 'background', 'abstract', 'minimal']
        fallback_assets = []
        
        for keyword in fallback_keywords:
            # Chercher dans la librairie des assets avec ces mots-clÃ©s
            for ext in ['.mp4', '.mov', '.jpg', '.png']:
                for asset_path in broll_library.rglob(f"*{keyword}*{ext}"):
                    if asset_path.exists() and asset_path not in fallback_assets:
                        fallback_assets.append(str(asset_path))
                        if len(fallback_assets) >= count:
                            break
                if len(fallback_assets) >= count:
                    break
            if len(fallback_assets) >= count:
                break
        
        # Si pas assez d'assets spÃ©cifiques, prendre des assets gÃ©nÃ©riques
        if len(fallback_assets) < count:
            for ext in ['.mp4', '.mov', '.jpg', '.png']:
                for asset_path in broll_library.rglob(f"*{ext}"):
                    if asset_path.exists() and asset_path not in fallback_assets:
                        fallback_assets.append(str(asset_path))
                        if len(fallback_assets) >= count:
                            break
                if len(fallback_assets) >= count:
                    break
        
        return fallback_assets[:count]
        
    except Exception as e:
        print(f"    âš ï¸  Erreur fallback neutre: {e}")
        return []

def _debug_broll_selection(plan, domain, keywords, debug_mode=False):
    """Log dÃ©taillÃ© de la sÃ©lection B-roll si debug activÃ©."""
    if not debug_mode:
        return
    
    print(f"    ğŸ” DEBUG B-ROLL SELECTION:")
    print(f"       Domaine: {domain}")
    print(f"       Mots-clÃ©s: {keywords[:5]}")
    print(f"       Plan: {len(plan)} items")
    
    for i, item in enumerate(plan[:3]):  # Afficher les 3 premiers
        if hasattr(item, 'asset_path') and item.asset_path:
            asset_path = item.asset_path
            score = getattr(item, 'score', 'N/A')
            context_score = getattr(item, 'context_score', 'N/A')
            freshness = getattr(item, 'freshness_score', 'N/A')
        elif isinstance(item, dict):
            asset_path = item.get('asset_path', 'N/A')
            score = item.get('score', 'N/A')
            context_score = item.get('context_score', 'N/A')
            freshness = item.get('freshness_score', 'N/A')
        else:
            continue
        
        print(f"       Item {i+1}: {Path(asset_path).name}")
        print(f"         Score: {score}, Context: {context_score}, FraÃ®cheur: {freshness}")

# ğŸš€ NOUVEAU: Fonction de scoring mixte intelligent pour B-rolls
def score_broll_asset_mixed(asset_path: str, asset_tags: List[str], query_keywords: List[str], 
                           domain: Optional[str] = None, asset_metadata: Optional[Dict] = None) -> float:
    """
    Score un asset B-roll avec le systÃ¨me mixte intelligent.
    
    Args:
        asset_path: Chemin vers l'asset
        asset_tags: Tags de l'asset
        query_keywords: Mots-clÃ©s de la requÃªte
        domain: Domaine dÃ©tectÃ© (optionnel)
        asset_metadata: MÃ©tadonnÃ©es supplÃ©mentaires (optionnel)
    
    Returns:
        Score final entre 0.0 et 1.0
    """
    try:
        if not BROLL_SELECTOR_AVAILABLE:
            # Fallback vers scoring basique
            return _score_broll_asset_basic(asset_path, asset_tags, query_keywords)
        
        # Utiliser le nouveau sÃ©lecteur si disponible
        from broll_selector import Asset, ScoringFeatures
        
        # CrÃ©er un asset simulÃ© pour le scoring
        asset = Asset(
            id=f"asset_{hash(asset_path)}",
            file_path=asset_path,
            tags=asset_tags,
            title=Path(asset_path).stem,
            description="",
            source="local",
            fetched_at=datetime.now(),
            duration=asset_metadata.get('duration', 2.0) if asset_metadata else 2.0,
            resolution=asset_metadata.get('resolution', '1920x1080') if asset_metadata else '1920x1080'
        )
        
        # Normaliser les mots-clÃ©s de la requÃªte
        normalized_keywords = set()
        for kw in query_keywords:
            if kw and isinstance(kw, str):
                clean = kw.lower().strip()
                if len(clean) > 2:
                    normalized_keywords.add(clean)
        
        # Calculer les features de scoring
        features = ScoringFeatures()
        
        # 1. Token overlap (Jaccard)
        if asset_tags and normalized_keywords:
            intersection = len(set(asset_tags) & normalized_keywords)
            union = len(set(asset_tags) | normalized_keywords)
            features.token_overlap = intersection / union if union > 0 else 0.0
        
        # 2. Domain match
        if domain and asset_tags:
            domain_keywords = _get_domain_keywords(domain)
            domain_overlap = len(set(asset_tags) & set(domain_keywords))
            features.domain_match = min(1.0, domain_overlap / max(len(domain_keywords), 1))
        
        # 3. Freshness (basÃ© sur la date de crÃ©ation du fichier)
        try:
            file_path = Path(asset_path)
            if file_path.exists():
                mtime = file_path.stat().st_mtime
                days_old = (time.time() - mtime) / (24 * 3600)
                features.freshness = 1.0 / (1.0 + days_old / 60)  # Demi-vie de 60 jours
        except:
            features.freshness = 0.5  # Valeur par dÃ©faut
        
        # 4. Quality score (basÃ© sur la rÃ©solution et l'extension)
        features.quality_score = _calculate_quality_score(asset_path, asset_metadata)
        
        # 5. Embedding similarity (placeholder - Ã  implÃ©menter avec FAISS)
        features.embedding_similarity = 0.5  # Valeur par dÃ©faut
        
        # Calculer le score final pondÃ©rÃ©
        weights = {
            'embedding': 0.4,
            'token': 0.2,
            'domain': 0.15,
            'freshness': 0.1,
            'quality': 0.1,
            'diversity': 0.05
        }
        
        final_score = (
            weights['embedding'] * features.embedding_similarity +
            weights['token'] * features.token_overlap +
            weights['domain'] * features.domain_match +
            weights['freshness'] * features.freshness +
            weights['quality'] * features.quality_score
        )
        
        return max(0.0, min(1.0, final_score))
        
    except Exception as e:
        print(f"âš ï¸ Erreur scoring mixte: {e}")
        # Fallback vers scoring basique
        return _score_broll_asset_basic(asset_path, asset_tags, query_keywords)

def _score_broll_asset_basic(asset_path: str, asset_tags: List[str], query_keywords: List[str]) -> float:
    """Scoring basique de fallback"""
    try:
        # Score simple basÃ© sur l'overlap de tags
        if not asset_tags or not query_keywords:
            return 0.5
        
        asset_tag_set = set(tag.lower() for tag in asset_tags)
        query_set = set(kw.lower() for kw in query_keywords if kw)
        
        if not query_set:
            return 0.5
        
        intersection = len(asset_tag_set & query_set)
        union = len(asset_tag_set | query_set)
        
        return intersection / union if union > 0 else 0.0
        
    except Exception as e:
        print(f"âš ï¸ Erreur scoring basique: {e}")
        return 0.5

def _get_domain_keywords(domain: str) -> List[str]:
    """Retourne les mots-clÃ©s spÃ©cifiques au domaine"""
    domain_keywords = {
        'health': ['medical', 'healthcare', 'wellness', 'fitness', 'medicine', 'hospital', 'doctor'],
        'technology': ['tech', 'digital', 'innovation', 'computer', 'ai', 'software', 'data'],
        'business': ['business', 'entrepreneur', 'success', 'growth', 'strategy', 'office', 'professional'],
        'education': ['learning', 'education', 'knowledge', 'study', 'teaching', 'school', 'university'],
        'finance': ['money', 'finance', 'investment', 'wealth', 'business', 'success', 'growth']
    }
    
    return domain_keywords.get(domain.lower(), [domain])

def _calculate_quality_score(asset_path: str, metadata: Optional[Dict] = None) -> float:
    """Calcule un score de qualitÃ© basÃ© sur les mÃ©tadonnÃ©es"""
    try:
        score = 0.5  # Score de base
        
        # Bonus pour la rÃ©solution
        if metadata and 'resolution' in metadata:
            res = metadata['resolution']
            if '4k' in res or '3840' in res:
                score += 0.2
            elif '1080' in res or '1920' in res:
                score += 0.1
        
        # Bonus pour la durÃ©e
        if metadata and 'duration' in metadata:
            duration = metadata['duration']
            if 2.0 <= duration <= 6.0:  # DurÃ©e optimale
                score += 0.1
        
        # Bonus pour l'extension (prÃ©fÃ©rer MP4)
        if asset_path.lower().endswith('.mp4'):
            score += 0.1
        
        return min(1.0, score)
        
    except Exception:
        return 0.5

    def _load_broll_selector_config(self):
        """Charge la configuration du sÃ©lecteur B-roll depuis le fichier YAML"""
        try:
            import yaml
            if Config.BROLL_SELECTOR_CONFIG_PATH.exists():
                with open(Config.BROLL_SELECTOR_CONFIG_PATH, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f) or {}
            else:
                print(f"    âš ï¸ Fichier de configuration introuvable: {Config.BROLL_SELECTOR_CONFIG_PATH}")
                return {}
        except Exception as e:
            print(f"    âš ï¸ Erreur chargement configuration: {e}")
            return {}

    def _calculate_asset_hash(self, asset_path: Path) -> str:
        """Calcule un hash unique pour un asset B-roll basÃ© sur son contenu et mÃ©tadonnÃ©es"""
        try:
            import hashlib
            import os
            from datetime import datetime
            
            # Hash basÃ© sur le nom, la taille et la date de modification
            stat = asset_path.stat()
            hash_data = f"{asset_path.name}_{stat.st_size}_{stat.st_mtime}"
            return hashlib.md5(hash_data.encode()).hexdigest()
        except Exception:
            # Fallback sur le nom du fichier
            return str(asset_path.name)