#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ SYSTÃˆME LLM MINIMALISTE - PROMPTS GÃ‰NÃ‰RIQUES + SPÃ‰CIALISATION PIPELINE
BasÃ© sur l'analyse brillante de l'utilisateur : prompts simples + spÃ©cialisation intelligente
"""

import requests
import json
import time
import logging
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OptimizedLLM:
    """SystÃ¨me LLM avec prompts minimalistes et spÃ©cialisation via pipeline"""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "gemma3:4b"):
        self.base_url = base_url.rstrip("/")
        self.model = model
        self.timeout = 120  # 2 minutes par dÃ©faut
        
    def _call_llm(self, prompt: str, temperature: float = 0.1, max_tokens: int = 100) -> Tuple[bool, str]:
        """Appel LLM simple avec gestion d'erreur"""
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "temperature": temperature,
                "stream": False
            }
            
            start_time = time.time()
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=self.timeout
            )
            end_time = time.time()
            
            if response.status_code == 200:
                result = response.json()
                response_text = result.get('response', '').strip()
                duration = end_time - start_time
                
                logger.info(f"âœ… LLM rÃ©ussi en {duration:.1f}s - {len(response_text)} caractÃ¨res")
                return True, response_text
            else:
                logger.error(f"âŒ Erreur HTTP: {response.status_code}")
                return False, ""
                
        except requests.exceptions.Timeout:
            logger.error(f"â±ï¸ Timeout aprÃ¨s {self.timeout}s")
            return False, ""
        except Exception as e:
            logger.error(f"âŒ Erreur LLM: {str(e)}")
            return False, ""
    
    def _extract_json(self, text: str) -> Optional[Dict[str, Any]]:
        """Extraction robuste du JSON depuis la rÃ©ponse LLM"""
        try:
            # Nettoyer et extraire le JSON
            text = text.strip()
            start_idx = text.find("{")
            end_idx = text.rfind("}")
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_str = text[start_idx:end_idx + 1]
                return json.loads(json_str)
            else:
                logger.warning("âš ï¸ Aucun JSON trouvÃ© dans la rÃ©ponse")
                return None
                
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Erreur parsing JSON: {e}")
            return None
    
    def generate_keywords(self, transcript: str, max_keywords: int = 15) -> Tuple[bool, List[str]]:
        """GÃ©nÃ©ration de mots-clÃ©s avec prompt minimaliste gÃ©nÃ©rique"""
        
        # ğŸ¯ PROMPT MINIMALISTE (votre approche parfaite)
        prompt = f"""Extract {max_keywords} to {max_keywords + 5} relevant single-word keywords from the transcript.
Do not invent unrelated terms.
Output JSON only: {{"keywords":["word1","word2", "..."]}}

Transcript: {transcript}

JSON:"""
        
        logger.info(f"ğŸ¯ GÃ©nÃ©ration mots-clÃ©s avec prompt minimaliste ({len(prompt)} caractÃ¨res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, []
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, []
        
        keywords = json_data.get("keywords", [])
        if not keywords or not isinstance(keywords, list):
            logger.warning("âš ï¸ Aucun mot-clÃ© valide trouvÃ©")
            return False, []
        
        # Nettoyage et validation
        clean_keywords = []
        seen = set()
        generic = {"what","over","your","look","when","learn","about","thing","things","people","really","going","want","need","make","take","time","back","good","best","more","most","very","that","this","those","these"}
        for kw in keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) <= 2:
                    continue
                if clean_kw in generic:
                    continue
                if not clean_kw.isalpha():
                    continue
                if clean_kw in seen:
                    continue
                seen.add(clean_kw)
                clean_keywords.append(clean_kw)
        
        # Prioritize specificity by length and uniqueness
        clean_keywords.sort(key=lambda k: (-len(k), k))
        
        logger.info(f"âœ… {len(clean_keywords)} mots-clÃ©s gÃ©nÃ©rÃ©s avec succÃ¨s")
        return True, clean_keywords[:max_keywords]
    
    def generate_title_hashtags(self, transcript: str) -> Tuple[bool, Dict[str, Any]]:
        """GÃ©nÃ©ration titre + hashtags avec prompt minimaliste"""
        
        # ğŸ¯ PROMPT MINIMALISTE pour titre + hashtags
        prompt = f"""Generate a title and hashtags from this transcript.
Output JSON only: {{"title": "Title here", "hashtags": ["#tag1", "#tag2", "..."]}}

Transcript: {transcript}

JSON:"""
        
        logger.info(f"ğŸ¯ GÃ©nÃ©ration titre + hashtags avec prompt minimaliste ({len(prompt)} caractÃ¨res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        title = json_data.get("title", "").strip()
        hashtags = json_data.get("hashtags", [])
        
        if not title:
            logger.warning("âš ï¸ Aucun titre valide trouvÃ©")
            return False, {}
        
        # Nettoyage des hashtags
        clean_hashtags = []
        for tag in hashtags:
            if isinstance(tag, str) and tag.strip():
                clean_tag = tag.strip()
                if not clean_tag.startswith("#"):
                    clean_tag = f"#{clean_tag}"
                clean_hashtags.append(clean_tag)
        
        result = {
            "title": title,
            "hashtags": clean_hashtags
        }
        
        logger.info(f"âœ… Titre et {len(clean_hashtags)} hashtags gÃ©nÃ©rÃ©s avec succÃ¨s")
        return True, result
    
    def generate_complete_metadata(self, transcript: str) -> Tuple[bool, Dict[str, Any]]:
        """GÃ©nÃ©ration complÃ¨te : titre, description, hashtags, mots-clÃ©s"""
        
        # ğŸ¯ PROMPT MINIMALISTE pour mÃ©tadonnÃ©es complÃ¨tes
        prompt = f"""Generate title, description, hashtags, and keywords from this transcript.
Output JSON only: {{"title": "Title", "description": "Description", "hashtags": ["#tag1"], "keywords": ["word1"]}}

Transcript: {transcript}

JSON:"""
        
        logger.info(f"ğŸ¯ GÃ©nÃ©ration mÃ©tadonnÃ©es complÃ¨tes avec prompt minimaliste ({len(prompt)} caractÃ¨res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        # Extraction des champs
        title = json_data.get("title", "").strip()
        description = json_data.get("description", "").strip()
        hashtags = json_data.get("hashtags", [])
        keywords = json_data.get("keywords", [])
        
        # Validation des champs obligatoires
        if not title:
            logger.warning("âš ï¸ Aucun titre valide trouvÃ©")
            return False, {}
        
        # Nettoyage des hashtags
        clean_hashtags = []
        for tag in hashtags:
            if isinstance(tag, str) and tag.strip():
                clean_tag = tag.strip()
                if not clean_tag.startswith("#"):
                    clean_tag = f"#{clean_tag}"
                clean_hashtags.append(clean_tag)
        
        # Nettoyage des mots-clÃ©s
        clean_keywords = []
        for kw in keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_keywords.append(clean_kw)
        
        result = {
            "title": title,
            "description": description,
            "hashtags": clean_hashtags,
            "keywords": clean_keywords
        }
        
        logger.info(f"âœ… MÃ©tadonnÃ©es complÃ¨tes gÃ©nÃ©rÃ©es : titre, description, {len(clean_hashtags)} hashtags, {len(clean_keywords)} mots-clÃ©s")
        return True, result
    
    def generate_broll_keywords_and_queries(self, transcript: str, max_keywords: int = 15) -> Tuple[bool, Dict[str, Any]]:
        """
        ğŸ¯ NOUVEAU: GÃ©nÃ©ration spÃ©cialisÃ©e pour B-roll
        Produit explicitement broll_keywords + search_queries
        """
        
        # ğŸ¯ PROMPT MINIMALISTE spÃ©cialisÃ© B-roll OPTIMISÃ‰ pour spÃ©cificitÃ© visuelle
        prompt = f"""Extract {max_keywords} visually-specific B-roll keywords and {max_keywords} search queries from the transcript.
Output JSON only: {{"broll_keywords":["..."], "search_queries":["..."]}}

ğŸ¯ B-roll keywords: Generate VISUALLY-SPECIFIC terms that represent actual visual elements.
Focus on concrete, searchable terms for stock footage APIs.

Examples of GOOD B-roll keywords:
- "doctor_office" (not just "office")
- "therapy_session" (not just "therapy")
- "brain_scan" (not just "brain")
- "patient_consultation" (not just "patient")
- "medical_charts" (not just "charts")
- "stethoscope_examination" (not just "examination")

Examples of BAD B-roll keywords (too generic):
- "therapy", "healing", "treatment" (too abstract)
- "office", "room", "building" (too generic)
- "person", "people", "man" (not specific enough)

ğŸ” Search queries: Generate ready-to-use search phrases (2-4 words each) for Pexels/Pixabay:
- "doctor office consultation"
- "therapy session closeup"
- "brain scan medical"
- "patient therapist interaction"

Transcript: {transcript}

JSON:"""
        
        logger.info(f"ğŸ¯ GÃ©nÃ©ration B-roll avec prompt minimaliste ({len(prompt)} caractÃ¨res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        # Extraction des champs B-roll
        broll_keywords = json_data.get("broll_keywords", [])
        search_queries = json_data.get("search_queries", [])
        
        # Validation des champs
        if not broll_keywords or not search_queries:
            logger.warning("âš ï¸ Champs B-roll manquants dans la rÃ©ponse")
            return False, {}
        
        # Nettoyage des mots-clÃ©s B-roll
        clean_broll_keywords = []
        for kw in broll_keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_broll_keywords.append(clean_kw)
        
        # Nettoyage des requÃªtes de recherche
        clean_search_queries = []
        for query in search_queries:
            if isinstance(query, str) and query.strip():
                clean_query = query.strip()
                if len(clean_query) <= 25:  # Limite pour les APIs
                    clean_search_queries.append(clean_query)
        
        result = {
            "broll_keywords": clean_broll_keywords[:max_keywords],
            "search_queries": clean_search_queries[:max_keywords]
        }
        
        logger.info(f"âœ… B-roll gÃ©nÃ©rÃ© : {len(clean_broll_keywords)} mots-clÃ©s, {len(clean_search_queries)} requÃªtes")
        return True, result
    
    def generate_metadata_with_broll(self, transcript: str) -> Tuple[bool, Dict[str, Any]]:
        """
        ğŸ¯ NOUVEAU: GÃ©nÃ©ration complÃ¨te avec mÃ©tadonnÃ©es + B-roll
        Combine toutes les informations nÃ©cessaires
        """
        
        # ğŸ¯ PROMPT MINIMALISTE complet avec B-roll OPTIMISÃ‰
        prompt = f"""Generate complete metadata and B-roll information from this transcript.
Output JSON only: {{
    "title": "Title",
    "description": "Description", 
    "hashtags": ["#tag1"],
    "keywords": ["word1"],
    "broll_keywords": ["visual_word1"],
    "search_queries": ["2-4 word query1"]
}}

B-roll keywords: single visual words for stock footage search.
Search queries: 2-4 word phrases ready for Pexels/Pixabay APIs.

Transcript: {transcript}

JSON:"""
        
        logger.info(f"ğŸ¯ GÃ©nÃ©ration complÃ¨te avec B-roll ({len(prompt)} caractÃ¨res)")
        
        success, response = self._call_llm(prompt)
        if not success:
            return False, {}
        
        # Extraction et validation
        json_data = self._extract_json(response)
        if not json_data:
            return False, {}
        
        # Extraction de tous les champs
        title = json_data.get("title", "").strip()
        description = json_data.get("description", "").strip()
        hashtags = json_data.get("hashtags", [])
        keywords = json_data.get("keywords", [])
        broll_keywords = json_data.get("broll_keywords", [])
        search_queries = json_data.get("search_queries", [])
        
        # Validation des champs obligatoires
        if not title:
            logger.warning("âš ï¸ Aucun titre valide trouvÃ©")
            return False, {}
        
        # Nettoyage des hashtags
        clean_hashtags = []
        for tag in hashtags:
            if isinstance(tag, str) and tag.strip():
                clean_tag = tag.strip()
                if not clean_tag.startswith("#"):
                    clean_tag = f"#{clean_tag}"
                clean_hashtags.append(clean_tag)
        
        # Nettoyage des mots-clÃ©s
        clean_keywords = []
        for kw in keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_keywords.append(clean_kw)
        
        # Nettoyage des mots-clÃ©s B-roll
        clean_broll_keywords = []
        for kw in broll_keywords:
            if isinstance(kw, str) and kw.strip():
                clean_kw = kw.strip().lower()
                if len(clean_kw) > 2:
                    clean_broll_keywords.append(clean_kw)
        
        # Nettoyage des requÃªtes de recherche
        clean_search_queries = []
        for query in search_queries:
            if isinstance(query, str) and query.strip():
                clean_query = query.strip()
                if len(clean_query) <= 25:
                    clean_search_queries.append(clean_query)
        
        result = {
            "title": title,
            "description": description,
            "hashtags": clean_hashtags,
            "keywords": clean_keywords,
            "broll_keywords": clean_broll_keywords,
            "search_queries": clean_search_queries
        }
        
        logger.info(f"âœ… MÃ©tadonnÃ©es complÃ¨tes avec B-roll : titre, description, {len(clean_hashtags)} hashtags, {len(clean_keywords)} mots-clÃ©s, {len(clean_broll_keywords)} B-roll, {len(clean_search_queries)} requÃªtes")
        return True, result

# === FONCTIONS UTILITAIRES POUR L'INTÃ‰GRATION ===

def create_optimized_llm(base_url: str = None, model: str = None) -> OptimizedLLM:
    """Factory pour crÃ©er une instance LLM optimisÃ©e"""
    
    # DÃ©tection automatique de l'URL et du modÃ¨le
    if not base_url:
        # Essayer Ollama en premier
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            if response.status_code == 200:
                base_url = "http://localhost:11434"
                logger.info("âœ… Ollama dÃ©tectÃ© sur localhost:11434")
            else:
                base_url = "http://localhost:1234"  # LM Studio par dÃ©faut
                logger.info("âš ï¸ Ollama non disponible, utilisation LM Studio par dÃ©faut")
        except:
            base_url = "http://localhost:1234"
            logger.info("âš ï¸ Aucun LLM local dÃ©tectÃ©, utilisation LM Studio par dÃ©faut")
    
    if not model:
        # ModÃ¨le par dÃ©faut selon la disponibilitÃ©
        if "11434" in base_url:  # Ollama
            model = "gemma3:4b"  # ModÃ¨le recommandÃ©
        else:  # LM Studio
            model = "default"
    
    return OptimizedLLM(base_url, model)

def generate_keywords_for_pipeline(transcript: str, max_keywords: int = 15) -> Tuple[bool, List[str]]:
    """Fonction utilitaire pour intÃ©gration directe dans le pipeline"""
    llm = create_optimized_llm()
    return llm.generate_keywords(transcript, max_keywords)

def generate_metadata_for_pipeline(transcript: str) -> Tuple[bool, Dict[str, Any]]:
    """Fonction utilitaire pour intÃ©gration directe dans le pipeline"""
    llm = create_optimized_llm()
    return llm.generate_complete_metadata(transcript)

def generate_broll_for_pipeline(transcript: str, max_keywords: int = 15) -> Tuple[bool, Dict[str, Any]]:
    """ğŸ¯ NOUVEAU: Fonction utilitaire pour B-roll"""
    llm = create_optimized_llm()
    return llm.generate_broll_keywords_and_queries(transcript, max_keywords)

def generate_complete_with_broll(transcript: str) -> Tuple[bool, Dict[str, Any]]:
    """ğŸ¯ NOUVEAU: Fonction utilitaire pour mÃ©tadonnÃ©es complÃ¨tes avec B-roll"""
    llm = create_optimized_llm()
    return llm.generate_metadata_with_broll(transcript)

# === TEST RAPIDE ===
if __name__ == "__main__":
    print("ğŸ§  Test du systÃ¨me LLM optimisÃ©...")
    
    # Test avec un transcript simple
    test_transcript = "EMDR therapy utilizes bilateral stimulation to process traumatic memories. The therapist guides the patient through eye movements while recalling distressing events."
    
    llm = create_optimized_llm()
    
    # Test mots-clÃ©s
    print("\nğŸ¯ Test gÃ©nÃ©ration mots-clÃ©s...")
    success, keywords = llm.generate_keywords(test_transcript, 10)
    if success:
        print(f"âœ… Mots-clÃ©s gÃ©nÃ©rÃ©s: {keywords}")
    else:
        print("âŒ Ã‰chec gÃ©nÃ©ration mots-clÃ©s")
    
    # Test mÃ©tadonnÃ©es complÃ¨tes
    print("\nğŸ¯ Test gÃ©nÃ©ration mÃ©tadonnÃ©es complÃ¨tes...")
    success, metadata = llm.generate_complete_metadata(test_transcript)
    if success:
        print(f"âœ… MÃ©tadonnÃ©es gÃ©nÃ©rÃ©es:")
        for key, value in metadata.items():
            print(f"   {key}: {value}")
    else:
        print("âŒ Ã‰chec gÃ©nÃ©ration mÃ©tadonnÃ©es")
    
    # ğŸ¯ NOUVEAU: Test B-roll
    print("\nğŸ¯ Test gÃ©nÃ©ration B-roll...")
    success, broll_data = llm.generate_broll_keywords_and_queries(test_transcript, 8)
    if success:
        print(f"âœ… B-roll gÃ©nÃ©rÃ©:")
        print(f"   Mots-clÃ©s: {broll_data['broll_keywords']}")
        print(f"   RequÃªtes: {broll_data['search_queries']}")
    else:
        print("âŒ Ã‰chec gÃ©nÃ©ration B-roll")
    
    # ğŸ¯ NOUVEAU: Test complet avec B-roll
    print("\nğŸ¯ Test gÃ©nÃ©ration complÃ¨te avec B-roll...")
    success, complete_data = llm.generate_metadata_with_broll(test_transcript)
    if success:
        print(f"âœ… DonnÃ©es complÃ¨tes gÃ©nÃ©rÃ©es:")
        for key, value in complete_data.items():
            print(f"   {key}: {value}")
    else:
        print("âŒ Ã‰chec gÃ©nÃ©ration complÃ¨te") 