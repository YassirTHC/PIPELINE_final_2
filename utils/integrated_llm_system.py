# ğŸš€ SYSTÃˆME LLM INTÃ‰GRÃ‰ COMPLET - PROMPTS MINIMALISTES + SPÃ‰CIALISATION PIPELINE
# Architecture basÃ©e sur l'analyse brillante de l'utilisateur

import logging
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# Import des modules locaux
from optimized_llm import OptimizedLLM, create_optimized_llm
from pipeline_specialization import (
    detect_content_domain, 
    enhance_metadata_with_domain, 
    analyze_content_complexity,
    optimize_for_platform
)

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class IntegratedLLMSystem:
    """
    SystÃ¨me LLM intÃ©grÃ© complet :
    - Prompts minimalistes gÃ©nÃ©riques
    - SpÃ©cialisation intelligente via pipeline
    - GÃ©nÃ©ration de mÃ©tadonnÃ©es complÃ¨tes
    """
    
    def __init__(self, base_url: str = None, model: str = None):
        self.llm = create_optimized_llm(base_url, model)
        logger.info(f"ğŸš€ SystÃ¨me LLM intÃ©grÃ© initialisÃ© avec {self.llm.model}")
    
    def generate_complete_metadata(self, transcript: str, platform: str = 'tiktok') -> Tuple[bool, Dict[str, Any]]:
        """
        GÃ©nÃ©ration complÃ¨te de mÃ©tadonnÃ©es avec spÃ©cialisation via pipeline
        
        Args:
            transcript: Transcription du contenu
            platform: Plateforme cible (tiktok, instagram, youtube)
            
        Returns:
            (success, metadata_dict)
        """
        logger.info("ğŸ¯ DÃ©marrage gÃ©nÃ©ration mÃ©tadonnÃ©es complÃ¨tes...")
        
        # 1. Analyse de la complexitÃ© du contenu
        complexity_analysis = analyze_content_complexity(transcript)
        recommended_keywords = complexity_analysis['recommended_keywords']
        
        logger.info(f"ğŸ“Š ComplexitÃ© dÃ©tectÃ©e: {complexity_analysis['complexity_level']}")
        logger.info(f"ğŸ¯ Mots-clÃ©s recommandÃ©s: {recommended_keywords}")
        
        # 2. GÃ©nÃ©ration des mÃ©tadonnÃ©es de base avec prompt minimaliste
        logger.info("ğŸ¤– GÃ©nÃ©ration mÃ©tadonnÃ©es de base avec LLM...")
        success, base_metadata = self.llm.generate_complete_metadata(transcript)
        
        if not success:
            logger.error("âŒ Ã‰chec gÃ©nÃ©ration mÃ©tadonnÃ©es de base")
            return False, {}
        
        # 3. DÃ©tection automatique du domaine
        logger.info("ğŸ¯ DÃ©tection automatique du domaine...")
        domain, confidence = detect_content_domain(transcript)
        
        # 4. Enrichissement avec la spÃ©cialisation du domaine
        logger.info(f"ğŸš€ Enrichissement pour le domaine: {domain} (confiance: {confidence:.2f})")
        enhanced_metadata = enhance_metadata_with_domain(base_metadata, transcript)
        
        # 5. Optimisation pour la plateforme cible
        logger.info(f"ğŸ¯ Optimisation pour {platform}...")
        final_metadata = optimize_for_platform(enhanced_metadata, platform)
        
        # 6. Ajout des informations d'analyse
        final_metadata['analysis'] = {
            'complexity': complexity_analysis,
            'domain_detection': {
                'domain': domain,
                'confidence': confidence
            },
            'generation_method': 'minimalist_prompt + pipeline_specialization'
        }
        
        logger.info("âœ… GÃ©nÃ©ration mÃ©tadonnÃ©es complÃ¨tes terminÃ©e avec succÃ¨s")
        return True, final_metadata
    
    def generate_keywords_only(self, transcript: str) -> Tuple[bool, List[str]]:
        """
        GÃ©nÃ©ration de mots-clÃ©s uniquement avec spÃ©cialisation via pipeline
        """
        logger.info("ğŸ¯ GÃ©nÃ©ration mots-clÃ©s avec spÃ©cialisation pipeline...")
        
        # 1. Analyse de la complexitÃ©
        complexity_analysis = analyze_content_complexity(transcript)
        recommended_count = complexity_analysis['recommended_keywords']
        
        # 2. GÃ©nÃ©ration de base avec prompt minimaliste
        success, keywords = self.llm.generate_keywords(transcript, recommended_count)
        
        if not success:
            logger.error("âŒ Ã‰chec gÃ©nÃ©ration mots-clÃ©s de base")
            return False, []
        
        # 3. Enrichissement via pipeline
        domain, confidence = detect_content_domain(transcript)
        
        # CrÃ©er un dictionnaire temporaire pour l'enrichissement
        temp_metadata = {'keywords': keywords}
        enhanced_metadata = enhance_metadata_with_domain(temp_metadata, transcript)
        
        final_keywords = enhanced_metadata['keywords']
        
        logger.info(f"âœ… {len(final_keywords)} mots-clÃ©s gÃ©nÃ©rÃ©s avec spÃ©cialisation {domain}")
        return True, final_keywords
    
    def generate_title_hashtags_only(self, transcript: str, platform: str = 'tiktok') -> Tuple[bool, Dict[str, Any]]:
        """
        GÃ©nÃ©ration titre + hashtags uniquement avec spÃ©cialisation via pipeline
        """
        logger.info("ğŸ¯ GÃ©nÃ©ration titre + hashtags avec spÃ©cialisation pipeline...")
        
        # 1. GÃ©nÃ©ration de base avec prompt minimaliste
        success, base_metadata = self.llm.generate_title_hashtags(transcript)
        
        if not success:
            logger.error("âŒ Ã‰chec gÃ©nÃ©ration titre + hashtags de base")
            return False, {}
        
        # 2. Enrichissement via pipeline
        domain, confidence = detect_content_domain(transcript)
        
        enhanced_metadata = enhance_metadata_with_domain(base_metadata, transcript)
        
        # 3. Optimisation pour la plateforme
        final_metadata = optimize_for_platform(enhanced_metadata, platform)
        
        # 4. Ajout des informations d'analyse
        final_metadata['analysis'] = {
            'domain_detection': {
                'domain': domain,
                'confidence': confidence
            },
            'generation_method': 'minimalist_prompt + pipeline_specialization'
        }
        
        logger.info(f"âœ… Titre et {len(final_metadata['hashtags'])} hashtags gÃ©nÃ©rÃ©s avec spÃ©cialisation {domain}")
        return True, final_metadata
    
    def batch_generate_metadata(self, transcripts: List[str], platform: str = 'tiktok') -> List[Tuple[bool, Dict[str, Any]]]:
        """
        GÃ©nÃ©ration en lot de mÃ©tadonnÃ©es pour plusieurs transcripts
        """
        logger.info(f"ğŸš€ GÃ©nÃ©ration en lot pour {len(transcripts)} transcripts...")
        
        results = []
        for i, transcript in enumerate(transcripts):
            logger.info(f"ğŸ“ Traitement transcript {i+1}/{len(transcripts)}...")
            
            success, metadata = self.generate_complete_metadata(transcript, platform)
            results.append((success, metadata))
            
            if success:
                logger.info(f"âœ… Transcript {i+1} traitÃ© avec succÃ¨s")
            else:
                logger.warning(f"âš ï¸ Transcript {i+1} en Ã©chec")
        
        logger.info(f"ğŸ¯ Traitement en lot terminÃ©: {sum(1 for s, _ in results if s)}/{len(transcripts)} succÃ¨s")
        return results
    
    def health_check(self) -> bool:
        """
        VÃ©rification de la santÃ© du systÃ¨me
        """
        try:
            # Test simple avec un transcript court
            test_transcript = "Test content for health check."
            success, _ = self.llm.generate_keywords(test_transcript, 3)
            return success
        except Exception as e:
            logger.error(f"âŒ Ã‰chec health check: {e}")
            return False

# === FONCTIONS UTILITAIRES POUR INTÃ‰GRATION DIRECTE ===

def create_integrated_system(base_url: str = None, model: str = None) -> IntegratedLLMSystem:
    """Factory pour crÃ©er le systÃ¨me intÃ©grÃ©"""
    return IntegratedLLMSystem(base_url, model)

def generate_metadata_complete(transcript: str, platform: str = 'tiktok') -> Tuple[bool, Dict[str, Any]]:
    """Fonction utilitaire pour gÃ©nÃ©ration complÃ¨te"""
    system = create_integrated_system()
    return system.generate_complete_metadata(transcript, platform)

def generate_keywords_enhanced(transcript: str) -> Tuple[bool, List[str]]:
    """Fonction utilitaire pour mots-clÃ©s enrichis"""
    system = create_integrated_system()
    return system.generate_keywords_only(transcript)

def generate_title_hashtags_enhanced(transcript: str, platform: str = 'tiktok') -> Tuple[bool, Dict[str, Any]]:
    """Fonction utilitaire pour titre + hashtags enrichis"""
    system = create_integrated_system()
    return system.generate_title_hashtags_only(transcript, platform)

# === TEST COMPLET DU SYSTÃˆME ===

if __name__ == "__main__":
    print("ğŸš€ Test complet du systÃ¨me LLM intÃ©grÃ©...")
    
    # Test avec diffÃ©rents types de contenu
    test_cases = [
        {
            'transcript': "EMDR therapy utilizes bilateral stimulation to process traumatic memories. The therapist guides the patient through eye movements while recalling distressing events.",
            'expected_domain': 'medical_psychology',
            'description': 'Contenu mÃ©dical/psychologique'
        },
        {
            'transcript': "Start your own business and become a successful entrepreneur. Learn the strategies that top performers use to grow their companies and increase revenue.",
            'expected_domain': 'business_entrepreneurship',
            'description': 'Contenu business/entrepreneuriat'
        },
        {
            'transcript': "Artificial intelligence is transforming the future of technology. Machine learning algorithms are automating complex tasks and creating new opportunities.",
            'expected_domain': 'technology_ai',
            'description': 'Contenu technologie/IA'
        }
    ]
    
    system = create_integrated_system()
    
    for i, test_case in enumerate(test_cases):
        print(f"\n{'='*60}")
        print(f"ğŸ§ª TEST {i+1}: {test_case['description']}")
        print(f"{'='*60}")
        
        transcript = test_case['transcript']
        expected_domain = test_case['expected_domain']
        
        print(f"ğŸ“ Transcript: {transcript[:80]}...")
        print(f"ğŸ¯ Domaine attendu: {expected_domain}")
        
        # Test 1: Mots-clÃ©s uniquement
        print(f"\nğŸ¯ Test 1: GÃ©nÃ©ration mots-clÃ©s...")
        success, keywords = system.generate_keywords_only(transcript)
        if success:
            print(f"âœ… Mots-clÃ©s gÃ©nÃ©rÃ©s ({len(keywords)}): {keywords[:5]}...")
        else:
            print("âŒ Ã‰chec gÃ©nÃ©ration mots-clÃ©s")
        
        # Test 2: Titre + hashtags
        print(f"\nğŸ¯ Test 2: GÃ©nÃ©ration titre + hashtags...")
        success, title_data = system.generate_title_hashtags_only(transcript, 'tiktok')
        if success:
            print(f"âœ… Titre: {title_data['title']}")
            print(f"âœ… Hashtags ({len(title_data['hashtags'])}): {title_data['hashtags'][:5]}...")
        else:
            print("âŒ Ã‰chec gÃ©nÃ©ration titre + hashtags")
        
        # Test 3: MÃ©tadonnÃ©es complÃ¨tes
        print(f"\nğŸ¯ Test 3: GÃ©nÃ©ration mÃ©tadonnÃ©es complÃ¨tes...")
        success, complete_metadata = system.generate_complete_metadata(transcript, 'tiktok')
        if success:
            print(f"âœ… Titre: {complete_metadata['title']}")
            print(f"âœ… Description: {complete_metadata['description'][:50]}...")
            print(f"âœ… Mots-clÃ©s: {len(complete_metadata['keywords'])}")
            print(f"âœ… Hashtags: {len(complete_metadata['hashtags'])}")
            print(f"ğŸ¯ Domaine dÃ©tectÃ©: {complete_metadata['analysis']['domain_detection']['domain']}")
            print(f"ğŸ“Š ComplexitÃ©: {complete_metadata['analysis']['complexity']['complexity_level']}")
        else:
            print("âŒ Ã‰chec gÃ©nÃ©ration mÃ©tadonnÃ©es complÃ¨tes")
    
    # Test de santÃ©
    print(f"\n{'='*60}")
    print("ğŸ¥ Test de santÃ© du systÃ¨me...")
    health_ok = system.health_check()
    if health_ok:
        print("âœ… SystÃ¨me en bonne santÃ©")
    else:
        print("âŒ ProblÃ¨me de santÃ© dÃ©tectÃ©")
    
    print(f"\nğŸš€ Test complet terminÃ© !") 