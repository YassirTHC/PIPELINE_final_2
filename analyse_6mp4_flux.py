#!/usr/bin/env python3
"""
Analyse du Flux LLM â†’ Fetchers â†’ Scoring pour 6.mp4
VÃ©rification de ce qui s'est passÃ© lors du traitement
"""

import json
import os
from pathlib import Path

def analyser_flux_6mp4():
    """Analyse du flux LLM â†’ Fetchers â†’ Scoring pour 6.mp4"""
    print("ğŸ” ANALYSE DU FLUX LLM â†’ FETCHERS â†’ SCORING POUR 6.MP4")
    print("=" * 80)
    
    # Dossier de sortie de 6.mp4
    output_6_dir = Path("output/clips/6")
    
    if not output_6_dir.exists():
        print("âŒ Dossier output/clips/6 non trouvÃ©")
        return
    
    print(f"ğŸ“ Dossier analysÃ©: {output_6_dir}")
    
    # 1. VÃ©rifier les fichiers gÃ©nÃ©rÃ©s
    print("\nğŸ” 1. FICHIERS GÃ‰NÃ‰RÃ‰S:")
    files = list(output_6_dir.iterdir())
    for file in files:
        if file.is_file():
            size_mb = file.stat().st_size / (1024*1024)
            print(f"   ğŸ“„ {file.name}: {size_mb:.1f} MB")
    
    # 2. Analyser les mÃ©tadonnÃ©es
    print("\nğŸ” 2. MÃ‰TADONNÃ‰ES:")
    meta_file = output_6_dir / "meta.txt"
    if meta_file.exists():
        with open(meta_file, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"   ğŸ“ Contenu meta.txt:")
        for line in content.split('\n'):
            if line.strip():
                print(f"      {line}")
    else:
        print("   âŒ meta.txt non trouvÃ©")
    
    # 3. Analyser la transcription
    print("\nğŸ” 3. TRANSCRIPTION:")
    segments_file = output_6_dir / "6_segments.json"
    if segments_file.exists():
        with open(segments_file, 'r', encoding='utf-8') as f:
            segments = json.load(f)
        
        print(f"   ğŸ“Š {len(segments)} segments de transcription")
        
        # Extraire les mots-clÃ©s potentiels
        all_text = " ".join([seg.get('text', '') for seg in segments])
        words = [word.lower().strip() for word in all_text.split() if len(word) > 3]
        
        # Mots-clÃ©s liÃ©s Ã  la santÃ©
        health_keywords = ['healthcare', 'medical', 'doctor', 'hospital', 'operation', 'medicare', 'medicaid']
        found_health = [word for word in words if any(health in word for health in health_keywords)]
        
        print(f"   ğŸ¥ Mots-clÃ©s santÃ© trouvÃ©s: {len(found_health)}")
        if found_health:
            print(f"      Exemples: {', '.join(set(found_health[:10]))}")
    
    # 4. Analyser les tokens avec couleurs
    print("\nğŸ” 4. TOKENS AVEC COULEURS:")
    tokens_file = output_6_dir / "final_subtitled.tokens.json"
    if tokens_file.exists():
        with open(tokens_file, 'r', encoding='utf-8') as f:
            tokens_data = json.load(f)
        
        print(f"   ğŸ¨ {len(tokens_data)} segments avec tokens")
        
        # Compter les mots-clÃ©s colorÃ©s
        colored_keywords = []
        for segment in tokens_data:
            for token in segment.get('tokens', []):
                if token.get('is_keyword', False):
                    colored_keywords.append(token.get('text', ''))
        
        print(f"   ğŸ¯ Mots-clÃ©s colorÃ©s: {len(colored_keywords)}")
        if colored_keywords:
            unique_colored = list(set(colored_keywords))
            print(f"      Exemples: {', '.join(unique_colored[:15])}")
    
    # 5. VÃ©rifier le log du pipeline
    print("\nğŸ” 5. LOG DU PIPELINE:")
    pipeline_log = Path("output/pipeline.log.jsonl")
    if pipeline_log.exists():
        with open(pipeline_log, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        print(f"   ğŸ“‹ {len(lines)} lignes dans le log")
        
        # Chercher des informations sur 6.mp4
        lines_6mp4 = [line for line in lines if "6" in line]
        print(f"   ğŸ¬ Lignes contenant '6': {len(lines_6mp4)}")
        
        # Analyser les derniers Ã©vÃ©nements
        recent_events = lines[-20:] if len(lines) > 20 else lines
        print(f"   â° 20 derniers Ã©vÃ©nements:")
        
        for i, line in enumerate(recent_events[-5:], 1):
            try:
                event = json.loads(line.strip())
                event_type = event.get('type', 'N/A')
                media_path = event.get('media_path', 'N/A')
                start_s = event.get('start_s', 'N/A')
                end_s = event.get('end_s', 'N/A')
                
                print(f"      {i}. [{start_s}s-{end_s}s] {event_type}")
                if '6' in media_path:
                    print(f"         ğŸ¬ 6.mp4: {os.path.basename(media_path)}")
                else:
                    print(f"         ğŸ“¹ B-roll: {os.path.basename(media_path)}")
                    
            except:
                print(f"      {i}. âš ï¸ Ligne non-JSON")
    
    # 6. VÃ©rifier la bibliothÃ¨que B-roll
    print("\nğŸ” 6. BIBLIOTHÃˆQUE B-ROLL:")
    broll_library = Path("AI-B-roll/broll_library")
    if broll_library.exists():
        clip_dirs = [d for d in broll_library.iterdir() if d.is_dir() and d.name.startswith('clip_reframed_')]
        print(f"   ğŸ“š {len(clip_dirs)} dossiers de clips reframÃ©s")
        
        # VÃ©rifier les clips rÃ©cents
        recent_clips = sorted(clip_dirs, key=lambda x: x.stat().st_mtime, reverse=True)[:5]
        print(f"   ğŸ†• 5 clips les plus rÃ©cents:")
        
        for clip_dir in recent_clips:
            clip_name = clip_dir.name
            mtime = clip_dir.stat().st_mtime
            print(f"      ğŸ“ {clip_name}")
            
            # VÃ©rifier le contenu
            fetched_dir = clip_dir / "fetched"
            if fetched_dir.exists():
                sources = [d.name for d in fetched_dir.iterdir() if d.is_dir()]
                print(f"         ğŸ“¥ Sources: {', '.join(sources)}")
    
    # 7. Analyse du flux LLM â†’ Fetchers â†’ Scoring
    print("\nğŸ” 7. ANALYSE DU FLUX LLM â†’ FETCHERS â†’ SCORING:")
    
    # VÃ©rifier si les mots-clÃ©s B-roll ont Ã©tÃ© gÃ©nÃ©rÃ©s
    if meta_file.exists():
        meta_content = open(meta_file, 'r', encoding='utf-8').read()
        
        # VÃ©rifier la prÃ©sence de mots-clÃ©s B-roll
        if 'broll_keywords' in meta_content.lower() or 'keywords' in meta_content.lower():
            print("   âœ… Mots-clÃ©s B-roll dÃ©tectÃ©s dans les mÃ©tadonnÃ©es")
        else:
            print("   âš ï¸ Aucun mot-clÃ© B-roll dÃ©tectÃ© dans les mÃ©tadonnÃ©es")
            print("   ğŸ” VÃ©rification du fichier tokens.json...")
            
            # VÃ©rifier dans tokens.json
            if tokens_file.exists():
                with open(tokens_file, 'r', encoding='utf-8') as f:
                    tokens_content = f.read()
                
                if 'broll_keywords' in tokens_content.lower():
                    print("      âœ… Mots-clÃ©s B-roll trouvÃ©s dans tokens.json")
                else:
                    print("      âŒ Aucun mot-clÃ© B-roll trouvÃ©")
    
    # VÃ©rifier l'utilisation des B-rolls
    if pipeline_log.exists():
        with open(pipeline_log, 'r', encoding='utf-8') as f:
            log_content = f.read()
        
        # Compter les B-rolls utilisÃ©s
        broll_events = log_content.count('"type": "event_applied"')
        print(f"   ğŸ¬ Ã‰vÃ©nements B-roll dans le log: {broll_events}")
        
        if broll_events > 0:
            print("   âœ… B-rolls ont Ã©tÃ© appliquÃ©s")
        else:
            print("   âŒ Aucun B-roll appliquÃ©")
    
    # 8. Conclusion
    print("\nğŸ” 8. CONCLUSION:")
    
    # VÃ©rifier les composants du flux
    components_status = {
        "LLM": "â“ Ã€ vÃ©rifier",
        "Fetchers": "â“ Ã€ vÃ©rifier", 
        "Scoring": "â“ Ã€ vÃ©rifier",
        "SÃ©lection": "â“ Ã€ vÃ©rifier"
    }
    
    # Mettre Ã  jour le statut basÃ© sur l'analyse
    if meta_file.exists() and "healthcare" in open(meta_file, 'r', encoding='utf-8').read().lower():
        components_status["LLM"] = "âœ… Actif (mots-clÃ©s gÃ©nÃ©rÃ©s)"
    
    if broll_library.exists() and len(list(broll_library.iterdir())) > 0:
        components_status["Fetchers"] = "âœ… Actif (bibliothÃ¨que B-roll)"
    
    if pipeline_log.exists() and broll_events > 0:
        components_status["Scoring"] = "âœ… Actif (B-rolls appliquÃ©s)"
        components_status["SÃ©lection"] = "âœ… Actif (B-rolls sÃ©lectionnÃ©s)"
    
    for component, status in components_status.items():
        print(f"   {component}: {status}")
    
    # Recommandations
    print("\nğŸ” 9. RECOMMANDATIONS:")
    
    if components_status["LLM"] == "â“ Ã€ vÃ©rifier":
        print("   ğŸ§  VÃ©rifier la gÃ©nÃ©ration LLM des mots-clÃ©s B-roll")
    
    if components_status["Fetchers"] == "â“ Ã€ vÃ©rifier":
        print("   ğŸ“¥ VÃ©rifier le tÃ©lÃ©chargement des B-rolls")
    
    if components_status["Scoring"] == "â“ Ã€ vÃ©rifier":
        print("   ğŸ¯ VÃ©rifier le systÃ¨me de scoring")
    
    if components_status["SÃ©lection"] == "â“ Ã€ vÃ©rifier":
        print("   ğŸ¬ VÃ©rifier la sÃ©lection finale des B-rolls")
    
    if all("âœ…" in status for status in components_status.values()):
        print("   ğŸ‰ Tous les composants du flux sont actifs !")
        print("   ğŸš€ Le pipeline LLM â†’ Fetchers â†’ Scoring fonctionne parfaitement")

def main():
    """Fonction principale"""
    print("ğŸ¯ Analyse du flux LLM â†’ Fetchers â†’ Scoring pour 6.mp4")
    
    analyser_flux_6mp4()

if __name__ == "__main__":
    main() 